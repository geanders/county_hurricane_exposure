---
title: "Response to reviewers' comments for *\"Assessing United States county-level exposure for research on tropical cyclones and human health\"*"
output: bookdown::pdf_document2
toc: false
bibliography: writing/hurr_exposure.bib
header-includes:
- \usepackage{xcolor}
- \usepackage{framed}
- \usepackage{bm}
- \usepackage{subcaption}
- \usepackage{gensymb}
- \renewcommand\familydefault{\sfdefault}
- \usepackage{sansmath}
- \usepackage{bm}
- \usepackage{soul}
- \sansmath
- \usepackage{booktabs}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{pdflscape}
- \usepackage{float}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{fullpage}
- \usepackage{pdflscape}
- \usepackage{tcolorbox}
- \tcbuselibrary{skins,breakable}
- \usepackage{amsmath}
- \usepackage{xtab}
- \usepackage{rotating}
- \allowdisplaybreaks
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r}
library(knitr)
```


# Overall comments {-#overall-comments}

\colorlet{shadecolor}{blue!8}
\begin{shaded}
\textbf{Associate Editor's Overview:}
Developing a consistent and comparable metric for exposure to tropical cyclones
would be a valuable addition to the literature. All reviewers had questions
about the exposure metric, including the challenges of using county-level data
where not everyone in a county would have been exposed and the difficulties of
going from country-level to individual -level risks. Further the comparison of
different storm hazards could be clarified. The reviewers identified several
issues where further explanation would increase the accessibility of the
manuscript.
\end{shaded}

Thank you for the opportunity to revise and resubmit this manuscript. We
appreciate the helpful suggestions from the reviewers for clarifying and
deepening the discussion in the paper.

Broadly, we have: 

1. Added discussion on the question of county-level versus individual-level
data. 
2. Added explanations for how our comparisons among different storm hazards
can help epidemiologists in designing studies and statistical analysis.
3. Added a small analysis of the correlation in rainfall metrics specifically
in cases of high rainfall ($\ge75$ mm of cumulative rainfall in the county
associated with the storm), to deepen the discussion of potential disagreement
in continuous measures of rainfall during extreme conditions. 
4. Changed labeling, axis range, and other presentation details for some
figures, as well as confirmed that the color scales will be accessible.
5. Corrected typos and improved wording throughout based on suggestions of the
reviewers.

# Reviewer 1: {-#reviewer-1:}

## Overall comments {-#overall-comments}
\colorlet{shadecolor}{blue!8}
\begin{shaded}
\textbf{Reviewer 1 Overview:}
I applaud the authors for this work, and their efforts to develop standardized
ways to measure exposure to tropical cyclones. As a disaster scientist, I very
much appreciate efforts that promote our collective ability to learn from and
across disasters to build cumulative science. 
\end{shaded}

**Response:** 

\begin{shaded}
\textbf{Reviewer 1 (R1) Comment 1:}
I very much appreciate the rationale for authors' decision to focus at the
county level, especially given the available health-related data. But, since
tropical cyclones don't necessarily have consistent impacts across an entire
county, I think the limitations of this decision are worthy of further
discussion in the discussion section.
\end{shaded}

**Response:** 

- Ecological fallacy vs individual fallacy, especially in the disaster context
- Spatial misalignment / ecological effects of aggregating data at the county
(or other geopolitical) level. 
- Could be particularly problematic in some high-risk areas, because of the 
"long and narrow" characteristics of island counties. Dare County, Key West. 

We think this is a very interesting question for disaster epidemiology, as
while there remains potential for ecological bias, the potential pathways for
health effects may also pass through damage in the individual's community beyond
their residence. For example, damage to major roads in the community might make
it harder for many residents to reach medical care in the aftermath of the
storm, even if their home did not experience extensive destruction. Similarly,
since power is provided over a network, conditions in an individual's community
can be important in determining risk of long-term outages (does Seth have
something on this?). As another example, if hospitals in the community are 
over capacity or have to evacuate, this could increase health risk for people in 
a fairly large "catchment" area for that hospital. 

Therefore, while we agree that individual-level data would in many cases be
helpful for tropical cyclone epidemiology, the ideal might be to design studies
that integrate both community-level and individual-level metrics of exposure.
This could help in determining if there are risks introduced to individuals
based on storm-related hazards in their broader community, after controlling for
the hazards experienced directly at their homes.

There is already some discussion on this topic in the Discussion [exposure 
measurement error / misclassification].

There are two interrelated mechanisms at play regarding this question. The
first is the potential for ecological bias. This bias results from inferring
individual-level associations from data that is available at an aggregated level. 
In the case of epidemiological research, these data include health outcomes, 
exposure, and covariates if the model is adjusting for confounding from them.
For example, in tropical cyclone epidemiology, an ecological study might 
compare county-wide rates of COPD hospitalizations to county-wide measures
of tropical cyclone exposure while controlling for county-level smoking 
rates and age distribution. The model in this case is fit at the county level, 
and so the relevant inference is at that level. If this county-level estimate
is inferred to represent the individual-level association between tropical 
cyclone exposure and risk of COPD hospitalization, controlled for smoking and
age, then the possibility of ecological bias arises. Given that this bias
results from inferring from a model with data at one level of aggregation
to another, this bias is also called cross-level bias. 

There are some subtleties that arise regarding this question for disaster
epidemiology. First, it has been argued that, for some ambient exposures
like weather and air pollution, contextual effects (that is, at the community
level) are helpful to estimate in their own right, not just as a potential 
surrogate for individual-level associations. This is because regulations
(in the case of pollutants), interventions, and planning often happen at
this level. 

Second, for a disaster, the relevant exposure might be not just at the
individual level (e.g., winds or flooding at the individual's residence), but
also throughout a broader area surrounding the individual. If storm damage
closes roads in a county, for example, or damages the power grid, then these
could create pathways for health risks for individuals throughout the county,
whether damage was high at their residence or not. The causal pathways for
tropical cyclones to affect human health differ from those for a dangerous
substance, like air pollutants, in which the substance itself must enter the
body to cause harm. While some health risk comes directly from the storm (e.g.,
deaths and injuries from trees falling on homes or drowning from flooding),
there are many more pathways that are indirect. These include pathways that go
through the way that the storm's damage affects community infrastructure and
access to medical care. Several papers have discussed the potential for 
"individualistic fallacy", as a counterpoint to "ecological fallacy", when 
such contextual-level exposure pathways are ignored. 

There are study designs that can be used to leverage ecological data while
minimizing risk from ecological bias. For example, potential confounders like
age distribution and smoking rates vary much less within a county over time than
comparing between counties. The mechanism for ecological bias depends on the
joint distribution between individual exposure, outcome, and covariates, if any
are included in the model. Time series-style study designs, which compare a
county to itself over time, allow for very similar covariate distributions
between exposure and non-exposure. Other studies add to this design by
stabilizing for temporal confounding through the addition of counties that were
never exposed, allowing for a differences-in-differences style approach to
calibrate for seasonal or longer-term trends that might otherwise create
confounding. For example, many health outcomes have a strong seasonal trend,
with peak rates in the winter and lows in the summer. Since the hurricane season
stretches from summer into fall, a study design that compares the rate of a
health outcome in an exposed county to the rate two weeks before the exposure
might be biased away from the null, since baseline rates of the health outcome
will typically be moving up over most of the hurricane season.

Also, there may be confounders that are relevant at the contextual, rather than
individual level, as well as modifiers. Example: whether the county is coastal
could be a contextual-level confounder and effect modifier. This will influence
whether the county is exposed to that storm or not, since storms usually weaken
rapidly when the center is over land. In terms of counfounding pathways, coastal
communities might tend to have lower levels of air pollution, because sea
breezes clear the pollution regularly. They might also be wealthier on average,
since property on or near the beach is desirable. Finally, they might be better
prepared for or more hardened against tropical cyclones at the community-wide
level (e.g., through hardier power infrastructure, more rigorous building codes,
higher likelihood of evacuating in advance of a threatening storm) compared to
nearby inland counties. 

Other approaches have also been suggested to reduce ecological bias while
leveraging ecological data, which might be available at a much larger
scale---and so provide more power---than is practical in collecting individual
data. These include multi-level approaches in which individual-level data from a
sample of individuals in each community is incorporated.

The second issue is exposure measurement error/misclassification. When the
exposure (e.g., binary exposure or continuous measure of intensity of exposure)
is only measured at the county level, all the individuals in that county are
assigned that same exposure. However, the hazards included in this study will
vary across each county. For some hazards, this variation will be more stark.
For example, tornadoes can be very local, causing extreme damage to a row of
homes and none to the homes across the street. Some types of floods can also be
very localized, rather than creating widespread flooding throughout the county.
In both cases, when a county-level exposure assessment is made based on an event
in the county in association with the storm, there may be many individuals in
the county who did not experience that hazard at their residence. The other
hazards we included---storm-associated winds and rainfall---will also have some
variation across counties, but this will often not be as stark. The rainfields
for tropical cyclones are very large, and while there are rainbands within the
storm that might have particularly high rates of precipitation, these progess
over the course of the storm, and it is unlikely that a county will have one
area that experienced very extreme precipitation while another experienced very
little. Winds might have more variation, especially in coastal counties and
counties near the storm's central track, since winds decay quickly as you move
from the storm's center, and storms typically weaken rapidly once they make
landfall and can no longer draw on warm ocean waters for energy.

This exposure data is provided at the county level, and this can lead to
exposure measurement error / exposure misclassification in studies that infer to
the individual level. In this case, there will be several processes at play.
First, the hazards of the storm will not be uniform across the county. The
degree of this within-county spatial heterogeneity will usually vary by hazard.
The within-county heterogeneity is likely lowest for rain and for wind at lower
levels. For rain, there can be particularly severe rain bands, but often a
storm's rainfield will bring high precipitation to a large area. Wind can have a
high heterogeneity close to the storm's center (storm winds decay most quickly
with distance near the storm's center) and near landfall (winds decay rapidly
after landfall). Other hazards can be very local within the county, only
affecting a small proportion of the total county area. A tornado is a clear
example---while it causes severe destruction in its track, areas just off the
track can be unharmed, creating a dramatic spatial gradient in damage within a
county. Floods can follow both. Some hurricanes have caused widespread flooding
(e.g., Floyd, Katrina) while some have caused flooding that is more spatially
focused (inland, with flashfloods? coast flooding just near the coast?). For
tidewater/coastal areas, there is often a dense network of waterway. When rains
occur further up the watershed, these all become flooded.

Second is the question of whether exposure measured at the resident's location
would be ideal. This is the case typically when studying an exposure that is a
chemical substance. In this case, the pathway depends on the substance entering
the body. For tropical cyclones, health risk could result from stress, problems
accessing medical care, or repercussions of power outages (higher exposure to
outdoor hazards like heat and air pollution, problems storing food and using
some medical equipment). For these, high levels of wind and other hazards in the
person's community may be as or more important than at their precise location.

Measurement error can be either random or systematic. Systematic error can often
be corrected with adjustment if the direction and typical size of the error is
understood. Random error cannot in the same way. Either type of measurement
error can be either differential (associated with the probability of the
outcome) or non-differential (independent of the distribution / probability of
the outcome). In simpler models, this characteristic might help in predicting
whether the resulting bias is likely toward the null; however, more complex
models (e.g., statistical models with adjustment for potential confounders) are
trickier to diagnose in terms of the likely implications of differential versus
non-differential measurement error [?].

Not only can the exposure be measured with error, but so too can potential
confounders and potential effect modifiers.

We provide exposure assessments at the county level. This spatial scale allows
for easy integration with health outcome data aggregated at the county level.
However, there are also some things to consider when modeling associations
at an ecological rather than individual level. The considerations are 
particularly nuanced when investigating the health risks associated with a 
disaster. 

Often in epidemiology, a study aims to estimate how an exposure changes the
risk of a health outcome for an individual. The data might be collected for
lots of people, but the key question is this---if a person is exposed, how 
does his or her risk of the outcome change. If you are exposed to this hazard, 
how much more likely are you to have the outcome? To get sick, or injured, or
to die? This inference is at the individual level. 

Even when individual-level inference is the goal, sometimes data is only 
available at an aggregated level. For example, privacy concerns might
mean that health outcomes are only made available as a county-wide daily 
count. You can fit a mode with this aggregated data, which will estimate the
association between exposure and health risk at the ecological level. This
contextual effect estimate is sometimes used as an estimate of individual-level
association, but doing so can introduce ecological/multi-level bias. The 
individual-level effect estimate can be very biased from the true association, 
even to the point of reversing the effect estimate---estimating a protective
effect when the true effect is detrimental, for example.

This ecological fallacy plays out in two ways. First, if you use a single 
exposure measurement for everyone in an area, some people will be misclassified
(or have exposure measured with error, for a continuous metric) unless the 
exposure is perfectly homogeneous across the area. This will typically not
be the case. This exposure misclassification can bias estimates of the 
association between exposure and outcome in the same way exposure 
misclassification through any other mechanism would.

Next, ecological bias could result from confounding, even if the confounders
are controlled in the ecological-level model. When you aggregate data, you 
lose information about how both the exposure and potential confounders vary
across individuals within the area of aggregation. As a result, a factor
could still confound the inference of an individual-level association, even 
if it is controlled for at a population level in an ecological model. For 
example, a study of the association between risk of pre-term birth and 
tropical cyclone exposure could control for county-level smoking when 
modeling county-level storm exposure and county-level rates of pre-term births.
Even with this control, an observed association could result from differences
in individual smoking status, if there is within-county variation in 
smoking and if this has a different pattern across people in the county than
variation in exposure from the county-wide exposure estimate.

For disasters, there are added nuances. First, for exposure it may not just 
matter what the level of exposure is in a person's immediate scope. Disasters
bring physical hazards that can harm people directly, but also through indirect
pathways. For example, a tropical cyclone can bring high winds that cause 
power outages, and as a result those affected could be exposed to more outdoor
hazards (outdoor air pollution, heat), struggle to safely store perishable
food and medications, and lose means to power medical equipment. While extreme
winds at a person's residence would increase their risk of a power outage, 
outages could also be caused by damage to the grid in another part of the 
community. In some cases, then, the level of exposure in a person's community
may be as important in opening a pathway of risk as exposure at the person's
immediate location. 

What's more, if the disaster has a large health impact, the health outcome of
one person in the community could affect the risk of the outcome (or other
adverse outcomes) for others. This situation is often only the case for 
infectious diseases, where one person with the disease can spread it to others.
However, if the community-wide impact is large enough, it can affect access
to and effectiveness of medical care for everyone in the community. This
effect has been seen recently with Covid 19---attempts to "flatten the curve"
aim to avoid moving into a state where a community's health system becomes
overwhelmed and can no longer deliver a typical level of care to those in the
community. This effect could happen with either infectious or non-infectious
diseases.

When a proxy exposure estimates is used for many people covered by a study, this
can result in a type of exposure measurement error called *Berkson error*. In
this case, the true exposure of each individual is randomly distributed around
this proxy/aggregate-level exposure estimate, with a mean exposure level among
the subjects that is equal to the proxy/aggregate-level measure. In other words,
the group as a whole is assigned a common exposure level, when in fact this is
the average exposure level across members of that group, but the individuals'
true exposure levels are randomly distributed around this mean group level to
which they are all assigned for modeling.

Berkson: 

$$
T = X + E
$$
where: 

- $T$: true individual exposure
- $X$: proxy exposure, assigned to everyone in the group
- $E$: error, with mean of 0, independent of $X$

The dataset provides exposure by group/area (county), not by individual. These
ecological exposure estimates require us to assume that the exposure level is
the same for all individuals in that county. It ignores/smooths over
within-county variability in exposure.

For wind and rain, we're essentially basing exposure assessment on modeling of
exposure. For rain, this is a based on a re-analysis model that
incorporates/integrates observed data from the area and time, using a model to
integrate data from diverse sources. For wind, the exposure estimates are based
on a model, with a core based on the Willoughby wind model. For flooding and
tornadoes, the exposure is based on records of events anywhere in the county,
and in many cases may be based, essentially, on exposure assessment, as in many
cases someone like someone at a NOAA [?] center have determined whether the
event should be reported in the database.

Even exposure at each person's residence would not suffice, since people move 
around during the day (although perhaps less for most people during a severe
storm).

Data that is aggregated across a population---for example, the total number of
deaths in a geographic area in a certain time period---is known as *ecological
data*, and studies that base inference on this type of data are known as
*ecological studies*. Terms include *ecological*, *aggregate*, *contextual
level*.

> "In an ecological study the unit of analysis is a group of people rather than 
the individual." [@sedgwick2014ecological]

> "In his seminal paper, Robinson (1950) distinguished between two types of
correlation---ecological and individual. The former is obtained for a group of
people, while the latter is estimated for indivisible units, such as
individuals." [@portnov2007ecological]

Here is one challenge when working with aggregated data. If you use aggregated
data to infer individual-level associations, this can lead to *ecological fallacy*. 
This results from cross-level inference---the data used to model the association
is at the contextual level (e.g., county-level), while the inference is for the
individual association between exposure and outcome. 

One definition of the ecological fallacy: 

> "This spurious result provides an example of the ecological fallacy, in 
which conclusions ... based on ecologic data are opposite of those drawn 
on the basis of individual-level data." [@wakefield2008overcoming]

> "It is a bias produced when analyses realised in an ecological (group level)
analysis are used to make inferences at the individual level."
[@delgado2004bias]

> "Results from ecological studies are prone to the ecological fallacy. The 
ecological fallacy is a term used when collected data are analysed at a 
group level and the results are assumed to apply to associations at the 
individual level." [@sedgwick2014ecological]

Importantly, aggregated data can be used both to infer a contextual effect
(e.g., the association between county-wide rates of a health outcome and 
exposure) as well as an individual-level effect (e.g., how a person's
risk of the outcome is associated with that person's exposure to the hazard). 
The first inference will *not* be prone to ecological bias, as the inference
is at the same level as the data. The second inference (individual-level) 
will be susceptible to bias when aggregated data is used to fit the model. 
In this case, the association estimated based on aggregated data can be 
different, and even reversed, compared to the true individual-level effect. 

> "I propose three criteria for the identification of ecological fallacy; all
three of these should be present to confirm its existence: (1) Results must be
obtrained with ecological (population) data; (2) Data must be inferred to
individuals. One use of ecological studies is to explore individual-level
association when individual data are not available. When the focus of the study
was contextual or based on population effects and there is no inference to
individuals, ecological fallacy is not possible. When only the first two
criteria are present---which is insufficient to affirm ecological fallacy---it
is appropriate to acknowledge that there is a possible relationship and that
further study is required; (3) Results obtained with individual data are
contradictory." [@idrovo2011three]

> "One important breakdown in the analogy between ecologic-bias and
individual-level confounding occurs because in etiologic research, the target of
inference for both ecologic and individual-level studies is the same: Both study
effects at the individual level. For an individual-level study, these target
effects are at the same level as the units of analysis. But, for an ecologic
study, these target effects are at a finer level than the units of analysis. As
a result, an ecologic study can be unbiased for ecologic effects (in particular,
ecologic confounding may be absent) and yet still be biased for individual-level
effects. Many of the classic social science examples of ecologic bias are of
this form." [@greenland1994invited]

> "We refer to an incorrect extrapolation from unbiased estimates of ecologic
effects to unobserved individual-level effects as 'cross-level bias' (although
the latter term is sometimes used to refer to any ecologic bias). As the
examples suggest, it is possible to detect cross-level bias if one can identify
and observe homogeneously exposed regions." [@greenland1994invited]

> "assuming that associations observed at the level of the area hold for the 
individuals within the areas can lead to the so-called ecological fallacy 
(Selvin, 1958)." [@wakefield2006health]

> "A broad definition of ecological fallacy is that certain data (e.g.,
illiteracy rates by foreign-born) are unavailable, leading to the use of proxies
and erroneous estimates. However, we advocate a more narrow definition of this
phenomenon, according to which 'ecological fallacy' refers solely to differences
in conclusions which may be drawn from group-level data (e.g., average
illiteracy rates by foreign-born), as opposed to data obtained for individuals."
[@portnov2007ecological]

> "If different conclusions are drawn from the analysis of data upon their
aggregations into units of different sizes (e.g., from individuals to townships
and regions), these differences are commonly referred to as 'ecological
fallacy'. In epidemiology, these differences are also known as ecological or
cross-level bias [refs]. The ecological bias is difficult to control and may
lead, under certain circumstances, to spurious effects [refs]. If
epidemiological study does not consider the possibility of ecological bias,
misguided policy decisions may follow [refs]." [@portnov2007ecological]

Ecological bias can *only* happen if there is, indeed, an individual-level
effect:

> "If exposure has no effect on any individual, there will be
no individual-level or ecologic effects, and so cross-level bias cannot occur. 
Thus, cross-level bias will not affect the validity of an ecologic test of the 
null hypothesis, although it still must be considered in interpreting a 
significant effect." [@greenland1994invited]

In some cases, the ecologic-level effect (contextual effect) will be directly 
of interest, and so we may be interested in inferring at that level (in which 
case use of ecologic-level data is appropriate and will not be prone to 
ecological bias):

> "The bias phenomenon in example 7 may be ascribed to the fact that an 
ecologic (regional) variable (percent Protestant) had effects on individual 
risk, in addition to effects of the corresponding individual-level variable
(religion) that the ecological variable summarized. In both social and 
infectious disease epidemiology, as well as in community intervention studies, 
ecologic effects may be of direct interest; a classic example is the 
phenomenon of 'herd immunity', in which the overall prevalence of 
immunity in a region, as well as individual immune status, determines the 
risk of individuals within the region (16). For noncontagious diseases, 
however, ecologic effects may not be of direct interest, and may in fact
obscure the individual-level effect of interest." [@greenland1994invited]

In some cases, the estimated association based on ecological data will be very 
different from the association that exists at the individual level: 

> "We see that the ecological relative risk associated with low birth 
weight is completely incomparable with the individual-level coefficient."
[@wakefield2008overcoming]

Ecological bias can also complicate estimation of effect modification, which 
otherwise could help in identifying vulnerabilities and susceptibilities among
certain subpopulations: 

> "Furthermore, non-White race now appears protective, rather than detrimental
as the individual-level analysis suggests." [@wakefield2008overcoming]

Ecologic bias crops up because the aggregated data fails to capture variation
within each aggregation level (county, for example) for both the exposure 
and potential confounders. For example, during a tropical cyclone, different
parts of a county will experience different peak wind speeds. If the county 
is coastal, the most severe winds will likely be near the coast, as the 
storm will weaken once it makes landfall and moves inland, as the storm 
generates its power from the water. When we assign the entire county a
single estimate of intensity, it smooths over the fact that locations in 
some parts of the county were subject to higher peak winds while locations
in other parts of the county had lower winds. At the least, this smoothing
of variation in exposure levels across the county could lower the power of 
the study to detect a clear association between exposure and health risk, as
this smoothing drops information inherent in the variation within the county
in exposure levels. 

This, however, would not result in ecological fallacy unless another factor
comes into play---variation within each aggregation level in confounders. 
Just as aggregation smooths over within-area variation in exposure levels, it
also smooths over within-area variation in levels of potential confounders. 
Depending on the patterns of this within-area variation, a result could be
that ecological-level control of the confounders does not, in fact, control
for their role at the individual level, and so the association inferred at
the ecologic level continues to be confounded by them when inferred to the
individual level. 

Essentially, this comes down to a question of the joint distribution, at the
individual level, of exposure, outcome, and covariates [?].

> "As various discussants have pointed out (3--6, 8, 9), ecologic relative-risk
estimates can be subject to biases not present in estimates from individual-level
observational studies of the same populations (case-control and cohort studies).
Unlike an individual-level study, an ecologic study does not link individual
outcome events to individual exposure or covariate histories, nor does it
link individual exposure and covariate histories to one another. It is these
linkage failures that are the source of the special biases of ecologic studies
(1, 2, 6)." [@greenland1994invited]

> "In the extreme, ecologic bias in comparisons limited to homogeneously exposed
regions (as in examples 3--6) can be viewed as purely an issue of confounding,
albeit with special complexities of measurement and control of confounders."
[@greenland1994invited]

> "More generally, one may show that cross-level bias will not occur if the 
individual-level effects of all variables (including unmeasured background
factors) follow a multiple linear-regression model with no regional effects and
no interactions (17). Nevertheless, given the usual inappropriateness of the 
multiple-linear model and the absence of homogeneously exposed regions, the 
possibility of cross-level bias adds a dimension to ecologic bias beyond
that of simple confounding." [@greenland1994invited]

> "Covariate control in ecologic studies requires attention to details not 
ordinarily of concern in individual-level studies. When, as is usually the
case, important nonlinearity or nonadditivity can be expected among 
exposure and covariate effects, it may be necessary to obtain and 
control for multiple summaries of joint covariate distributions in order
to insure that control is adequate." [@greenland1994invited]

> "Ecological fallacy can be produced by within group (individual level)
biases, such as confounding, selection bias, or misclassification, and
by confounding by group or effect modification by group." [@delgado2004bias]

> "**Confounding by group**: it is produced in an ecological study, when 
the exposure prevalence of each community (group) is correlated with 
the disease risk in non-exposed of the same community. It can be 
a mechanism for producing ecological fallacy." [@delgado2004bias]

If individual-level inference is the aim, and population-level data is
available, there are some methods for using it while still aiming to avoid
ecological bias. Indeed, it can be helpful to use population-level data, as it
is often available for a large population, improving the power and precision of
the study. Further, the level of exposure might vary a lot more over the
population captured with population-level data compared to the variation that
captured in a smaller sample of individual-level data. This can contribute both 
to statistical power and improve external validity (as the study data will cover
more of the range of exposure that might ever be expected). However, if
individual-level inference is the goal, then there are ways to supplement
population-level data with samples of individual-level data through two-level, 
semi-ecologic study designs.

> "It is generally well recognized that in order for ecologic data to provide
reliable inferences, they need to be supplemented with individual-level data."
[@wakefield2008overcoming]

> "For this example, we have access to complete individual-level data,
permitting a 'gold standard' individual-level analysis."
[@wakefield2008overcoming]

> "The only reliable way to characterize within-area variation in exposures
and confounders, and hence control ecologic bias, is to collect and incorporate
individual-level data. To help epidemiologists achieve this goal, in this paper
we describe the use of the two-phase design in an ecologic setting."
[@wakefield2008overcoming]

> "The only reliable way to characterize within-area variation in exposures
and confounders, and hence control ecologic bias, is to collect and incorporate
individual-level data. To help epidemiologists achieve this goal, in this 
paper we describe the use of the two-phase design in an ecologic setting."
[@wakefield2008overcoming]

> "In a semi-ecologic study, an ecologic exposure is combined with
individual-level outcomes and confounders. A two-phase approach is particularly
useful for such a study, with the phase 2 data corresponding to stratified
sampling of individual exposures." [@wakefield2008overcoming]

> "To implement a two-phase design, an initial phase 1 cross-classification by
the binary disease outcome and stratification variables is required; in phase 2,
samples of individuals are drawn from each of the cross-classification cells,
with data on additional variables being drawn from the subsamples of
individuals. Intuitively, the stratified sampling is focused on informative
cells, and estimation methods use both phases of data for efficiency and to
acknowledge the outcome-dependent sampling. In the simplest ecologic setting,
the cross-classification is by outcome and area only, and if area is a surrogate
for important risk factors this design will be efficient. We are particularly
interested in situations where an initial classification is available by
outcome, area, and confounders such as age and gender---this is the case in a
semi-ecologic study. Phase 2 may then provide detailed exposure information on a
subset of the phase 1 individuals." [@wakefield2008overcoming]

> "Two-phase study designs are a generalization of matched case-control designs
in which, initially, the entire sample population is cross-classified according
to case/control status and some stratification variable, S. The latter depends
on covariates observed in all individuals and may include exposures of interest, 
proxy exposure measures, or potential confounders. In settings like those we
are considering, such as environmental epidemiology, S may also depend on geographic
area, which can act as a surrogate for the totality of confounders associated
with each area, as well as provide a well-defined sampling frame for the controls."
[@wakefield2008overcoming]

> "The results of our simulation study point to the benefits associated with
combining the two sources of data, in terms of both bias and efficiency. Rather
than supplement an ecologic study with individual-level data, it may be of
interest to combine existing individual-level data with external group-level
data. Strategies that combine both types of data have been shown to alleviate
participation bias and improve efficiency in case-control studies with missing
data (31)." [@wakefield2008overcoming]

> "As with other observational studies, ecologic studies can give useful results
if biases such as those discussed here can be ruled out or quantified.
Nevertheless, bias evaluation can be especially difficult in ecologic studies of
geographic regions because of the many potentially interacting covariates that
may differ across regions. When biases cannot be ruled out with available data,
further exploration will require individual-level studies."
[@greenland1994invited]

Why we might sometimes use (and want to use) population-level data: 

> "Because of the unavailability of individual-level data, ecological data may
be resorted to and may come in a variety of forms." [@wakefield2008overcoming]

> "Epidemiologists continue to use ecologic and aggregate data. Despite their 
known drawbacks, these data, often aggregated across geographic areas, offer the
advantages of widespread availability and gains in statistical power from large
populations and increased exposure ranges." [@wakefield2008overcoming] 

> "Population and health data are often routinely available in ecological, that
is group, form while the exposure data typically consist of a set of values
recorded at monitor sites, or via one-off sampling." [@wakefield2006health]

It can be important to think about the scale that the process happens at. For
something very local, you might lose a lot more with aggregated data. 

> "Data availability and exposure variability often determine the scale of
examination and the suitability of a study. Exposures arising from a point or
line source offer exposure contrasts on small scales, requiring small-area data;
in constrast, dietary variables show little variation across small scales, and
consequently international studies are used." [@wakefield2008overcoming]

There can also be an *individualistic fallacy*, if emphasis is limited to the
association between individual-level factors, without considering the potential
role of contextual factors in an individual's risk of a health outcome. In other
words, cross-level bias can go in both directions [@idrovo2011three]. While the
fallacy of inferring individual-level associations from ecologic-level data is
called *ecological fallacy*, the fallacy of inferring ecologic-level
(contextual) effects from individual-level data is known as the *atomistic
fallacy* [@idrovo2011three]. There are also fallacies that can come in, it
seems, from inferring at the same level as the data but failing to consider
influences from factors at the other level. When inferring individual-level
associations from individual-level data, without considering an additional role
of ecological-level factors, this is known as the *psychologistic* or
*individualistic fallacy* [@idrovo2011three]. When inferring contextual effects
from ecologic data without considering individual-level factors, this is known
as the *sociologistic fallacy* [@idrovo2011three].

> "Although ecological studies are important to epidemiology (especially in
environmental and social epidemiology), public health practitioners seem afraid
of ecological studies. It is a common practice to assume the presence of
ecological fallacy (Robinson 1950) and low-level validity when analyzing an
ecological study. Most epidemiologists prefer an exclusive individualistic
approach, although the importance of a multilevel causal approach is widely
recognized (Diez-Roux 2002). In this sense, some authors suggest that it is as
important to recognize the presence of ecological fallacy as to recognize
psychologistic or individualistic fallacy (Subramanian et al. 2009)."
[@idrovo2011three]

Confounding in general: 

> "A confounder ... is associated with an exposure or risk factor for the
outcome and with the outcome independent of the exposure, but is not on the
causal pathway between the exposure and the outcome. Confounding occurs when the
relationship between an exposure variable and the outcome variable is
contaminated, so that the measure of association between these two variables is
actually also capturing the effects of a third variable, the confounding
variable. For example, many factors are associated with income (exposure) and
health (outcome), such as education, employment or wealth? It may be that these
factors explain part of the observed assocation." [@gunasekara2008glossary]

Measurement error in general:

> "Measurement error: The different between an observed variable and the
variable that belongs in a multiple regression equation. Measurement error is
the random or systematic error arising during data collection of variables. The
measured variable x is measured with error eta, which is the distance from x to
the 'true' value of x. Measurement error can produce bias such as attenuating
the estimators of exposure variables, but may also have more complex effects.
Longitudinal data analyses such as fixed effects models can actually augment the
problem of measurement error in mis-measured explanatory variables that change
little over time." [@gunasekara2008glossary]

Study validity: 

> "Study validity refers to the degree to which the inferences drawn from a
study are warranted when account is taken of the study methods; the
representativeness of the study sample; and the nature of the population from
which it is drawn.[5] There are two types of study validity. *Internal validity*
is the degree to which the results of a study are correct for the sample of
people being studied. *External validity* (generalisability) is the degree to
which the study results hold true for a population beyond the subjects in the
study or other settings.[20]"

\begin{shaded}
\textbf{R1 Comment 2:}
Are there opportunities to expand this approach internationally? Some decisions
(e.g., county-level) data may restrict cross-country comparisons. Can the
authors discuss this? 
\end{shaded}

**Response:** 

- Differs by exposure metric. Easier for some (wind, rain) than for others
(flood, tornado)
- For rain, we use a re-analysis product only available for the continental US
(right?). However, there are similar gridded re-analysis products available for
other regions worldwide that could be used in a similar way.
- For tornadoes, there may be national databases in other spots similar to the
tornado database that we use, but as far as we're aware, no international one.
- Same for floods. 
- For wind, the wind model could be generalizable with some tweaks. These
include:
  + More landmasks
  + Direction of storm movement for Northern vs Southern Hemispheres
  + Different wind averaging periods for the recorded best tracks data in
  different storm basins.
  + Our wind model was derived with US data and so may need bias-correction or a
  shift to a West Pacific--based model

> "Tornadoes long have been recognized as a global phenomenon (e.g., Wegener
1917; Feuerstein et al. 2005), having been recorded in every continent except
Antarctica. As such, numerous nationas share an interest in improving assessment
of their damage. International research and involvement in tornado survey work
and damage and intensity scales is well underway." [@edwards2013tornado]

For flood and tornado events, we used a database of severe weather events that
is specific to the United States (the US NOAA's Storm Events database). To
expand our exposure data for these hazards internationally, we would need to
find similar databases for other affected countries. [international flood and
tornado databases? EM-DAT? Others?]

The wind exposure data is based on modeling wind fields based on records of the
storm's track and central intensity throughout the tracking period. These values
are tracked for tropical cyclones around the world, and so it would be possible
to expand the dataset to encompass other countries for wind exposure
measurements. However, there are some practical issues that would need to be
addressed to do so with the approach we've taken.

The software we are using to model wind [@stormwindmodel] has several features
that make it specific to Atlantic basin storms. First, some steps in the model
depend on whether the storm's center or the location being modeled is over land
or water. These steps use a landmask---a grid with a binary indicator of land or
sea by latitude and longitude. Currently, the software only provides a landmask
that covers the United States, the Gulf of Mexico, and areas of the Atlantic
Ocean near the US. Second, the model assumes that cyclonic winds are
counterclockwise, and so is valid only for the Northern Hemisphere. Third, the
model assumes that the central intensity of the storm is based on [wind
averaging period], which is the standard used in the tracking data for
Atlantic-basin storms, but is not a common standard around the world. Instead,
some basins record central intensity measurements using averaging periods of
....

Therefore, it would be relatively straightforward to expand the wind exposure
data to cover other countries affected by Atlantic-basin storms, although this
would require some expansion of the area covered by our current landmask. More
modifications would need to be made to the wind model software before it could
be extended to storms in other basins, particularly basins that use different
wind averaging periods for their main tracking data and basins in the Southern
Hemisphere. Alternatively, other wind modeling software could be used for this
exposure assessment, as other groups have developed software that is more
extensible to multiple storm basins [Australian group's software].

The rain exposure data would also be fairly easy to extend to cover other
countries, although again there would be a few practical limitations to extend
the approach we've taken in developing the dataset covered in this manuscript.
For this exposure, we've used a re-analysis dataset. We've taken some steps to
translate this gridded data to the county scale, so it can be integrated with
the scale for many human impacts measurements. However, these steps have been
well documents [ref] and would be easy to reproduce. The re-analysis dataset
that we use is specific to the contiguous US [ref on NLDAS], but other similar
re-analysis datasets exist for other locations [example of one with global
coverage?].

For all of these, we have provided exposure assessments at the county scale. Any
of the steps we have taken could be done for other countries at a similar
geopolitical scale, although the name of that areal unit will vary by country
(e.g., municipalities in Mexico, districts in India). For wind and rain
exposures, the approach we take here could be used with any areal unit, as long
as there are geographical shape files available for the area boundaries
(although the modeling for wind may be to the area's geographic mean center
rather than population mean center).

> "We initially developed software to model exclusively Atlantic-basin storms
[@stormwindmodel]. There are two characteristics of Northwestern Pacific Ocean
basin storm data that prevent direct use of the current version of the software.
First, the software currently requires Western Hemisphere longitude inputs.
Second, the ``Best Tracks'' data from the China Meteorological Administration
include central tropical cyclone intensity using a 2-minute averaging period,
while the software currently assumes that central intensities are given for a
1-minute averaging period, as is the case for storm track data from the US
National Hurricane Center. With the assistance of Ms. Schumacher, we will update
our tropical cyclone wind model software to appropriately handle 'Best Tracks'
data from the China Meteorological Administration, incorporating conversion
factors [@harper2010guidelines] to convert central storm maximum sustained wind
measurements to a common averaging period prior to applying further steps of the
wind model."


\begin{shaded}
\textbf{R1 Comment 3:}
In non-health fields, a county's inclusion in a FEMA major disaster declaration
or eligibility for public/individual assistance (all of which are somewhat
reflective of level of damage) is sometimes used as an "exposure" proxy. Have
you considered if/how your exposure assessments relate to inclusion in a FEMA
disaster declaration? In other words, does exposure to any of the hazards align
with the level of damage required for a county to be considered a "disaster
area" and/or worthy of federal assistance by current federal policy? Does this
matter?
\end{shaded}

**Response:** 

This is a great question, and we are aware of a number of studies on the
societal impacts of tropical cyclones that have used FEMA disaster declarations
to assess county-level exposure to tropical cyclones [refs]. 

However, evidence from prior tropical cyclone epidemiology that doing so is
problematic and should be avoided [@grabich2015measuring]. FEMA's disaster
declarations are issued to provide assistance, based on damage assessment, to
individuals or the entire public in certain locations where catastrophes
overwhelm the state or local government [@mccarthy2014fema], and any use of them
for exposure assessment is secondary. Due to the political nature of disaster
declaration process, these declarations are often subject to many political and
economic factors [@mccarthy2014fema; @logue1981research]. One epidemiological
study specifically focused on exposure assessment for tropical cyclone
epidemiology and compared use of FEMA declarations with other methods of
exposure assessment, including one based directly on the storm hazard of wind
[@grabich2015measuring]. They found that exposure assessment based on FEMA
declarations tended to overassign counties to be "exposed," resulting in false
positives [@grabich2015measuring]. A further concern is that, given the
political and economic nature of these declarations, there is likely variation
across time and geography in the likelihood of a given exposure resulting in a
disaster declaration. This is particularly worrisome for a study that seeks to
explore risk across multiple years and affected communities.

We have added some discussion of this point... 

- Future research could expand the work by [@grabich2015measuring] to determine
the extent of these issues with use of FEMA disaster declarations for
epidemiological exposure assessment. This would need to go beyond the comparison
with exposure assessment based on storm hazards, because sometimes the
characteristics of the affected community modifies the amount of disaster that
results from hazards of a certain severity. For example, a community that it
exposed often might be more "hardened" against damage from the storm (any work
from Seth on this) and so might experience less infrastructure damage from a
tropical cyclone with certain characteristics compared to a community that is
rarely exposed to tropical cyclones. One interesting direction would be to
investigate if there is evidence of differences in probablity of disaster
declarations at geopolitical boundaries, like when comparing counties on either
side of a state border.

There are some cases where damage reports are directly used to infer the
intensity of the weather event. For example, damage surveying is used following
a tornado to assign the tornado's class on the [enhanced] Fujita scale. However,
this is not the intent of FEMA damage reports, which instead are used to
determine post-disaster aid [?] and are influenced by a number of political
factors.

> "Because of the historic lack of direct measurements and remotely sensed
tornado wind speeds at or near group level, damage surveying has remained the
most common form for indicating tornado strength. ... The occurrence of a direct
tornado strict upon a fixed, sufficiently sturdy, and well-calibrated wind
measuring station is quite rare. Only 31 direct in situ tornado observations are
evident between 1894 and 2011." [@edwards2013tornado]

\begin{shaded}
\textbf{R1 Comment 4:}
Line 95---wondering if there is a better word for "hits" here. Maybe "exposed?"

\textit{Lines 92--95 in the original manuscript:}

\begin{quotation}
\noindent
\textit{"In many cases, these studies analyze multi-year, multi-community data,
allowing them to estimate average associations over many disasters and to
explore how a disaster's characteristics, or the characteristics of the
community it hits, modify associated health risks (e.g., Anderson and Bell 2010;
Son et al. 2012; Liu et al. 2017)."}
\end{quotation}
\end{shaded}

**Response:** 

Thank you for this suggestion. We have changed the wording in this sentence: 

> **Text in revised manuscript (relevant change in bold):**
"In many cases, these studies analyze multi-year, multi-community data, allowing
them to estimate average associations over many disasters and to explore how a
disaster's characteristics, or the characteristics ofthe **affected
communities**, modify associated health risks (e.g., Anderson and Bell 2010; Son
et al. 2012; Liu et al. 2017)."

We also used the word "Hits per county per decade" in the legend for Figure 5 in
the main text and Figure S3 of the Supplemental Material. We have revised the
wording in these figures to "Exposures per county per decade".

```{r fig5, fig.cap="Reproduction of Figure 5 from the original manuscript (left) and revised version in the resubmitted manuscript (right). In the revised version, the figure legend was changed from '\\textbf{Hits} per county per decade' to '\\textbf{Exposures} per county per decade' (bold used to highlight change). Figure caption in the revised manuscript: \\textit{Figure caption.}", fig.show = "hold", out.width="40%", fig.align = "center"}
include_graphics("../figures/averageexposureonly.pdf")
include_graphics("figures/averageexposureonly.pdf")
```

\begin{shaded}
\textbf{R1 Comment 5:}
Lines 137--139, suggest breaking into two sentences

\textit{Lines 137--141 from original manuscript:}

\begin{quotation}
\noindent
\textit{"While other approaches have been developed to incorporate storm
hazards, particularly wind, into exposure assessment (e.g., Grabich et al.
2015a; Zandbergen 2009; Czajkowski et al. 2011), there is not yet a standard
approach, and when different studies use different datasets or storm hazards
when assessing storm exposure, it becomes difficult to compare and aggregate
findings."}
\end{quotation}
\end{shaded}

**Response:** 

This is a great suggestion. We have split the cited sentence into two sentences:

> **Text in revised manuscript:**
"While other approaches have been developed to incorporate storm
hazards, particularly wind, into exposure assessment (e.g., Grabich et al.
2015a; Zandbergen 2009; Czajkowski et al. 2011), there is not yet a standard
approach. When different studies use different datasets or storm hazards
when assessing storm exposure, it becomes difficult to compare and aggregate
findings."

\begin{shaded}
\textbf{R1 Comment 6:}
This is not a comment on the paper, but the authors may also want to consider
publishing their work in DesignSafe, which is "the web-based research platform
of the NHERI  [NSF-Funded Natural Hazards Engineering Research Infrastructure]
Network that provides the computational tools needed to manage, analyze, and
understand critical data for natural hazards research." It is the data
repository widely used by interdisciplinary hazards and disaster researchers.
\end{shaded}

**Response:** 

Great idea!

We have investigated this. DesignSafe is ...

As part of its platform, DesignSafe allows users to work in a number of 
programming languages, including R (through Jupyter Notebooks). Therefore, 
DesignSafe users already have access to any data shared through an R package, 
including the data we present in this manuscript, without the data needing 
to be separately loaded and published through DesignSafe's Data Depot. 

We have added a note in the manuscript to let readers know that, because the
data is shared through an R package, and because DesignSafe's [Workspace] allows
users to work in R, the data can be fully accessed and used for those working on
the DesignSafe platform by using the same code in a DesignSafe Jupyter notebook
that would otherwise be used on a local computer.

This is good, because otherwise there would be a good deal of overlap between
the data on DesignSafe and that in the R package. R packages already created a
citable source, comparable to the DOI assigned to data by DesignSafe when it is
published. Further, R packages include licensing information, as does DesignSafe
for published data. Finally, if the data were shared through both platforms, it
would be critical to make sure that it was clear that the two datasets are
analogous and also to keep them up to date with each other, which would add an
extra layer of work with each update to the R package (we have been updating
several hazards as new data becomes available). It is wonderful that
DesignSafe's interface with R avoids this problem by allowing its users direct
access to our package and its data through that path, as it allows for a single,
citable, licensed version of the data stored and shared from a single location,
with no question of syncing separate versions of the data or clarifying
licensing and citation practices across two storage locations.

*What is DesignSafe:*

> "DesignSafe is the cyberinfrastructure platform that has been developed as
part of NHERI to support natural hazards engineering research, and
it succeeds the NEEShub cyberinfrastructure that was developed for the
earthquake engineering community through the Network for Earthquake
Engineering Simulation (NEES) program." [@rathje2017designsafe]

> "DesignSafe plays an important role in integrating the various NHERI
components and the research taking place at NHERI facilities, but also has the
broader goal of enabling transformative research in natural hazards and
engineering across the numerous technical disciplines engaged in this field."
[@rathje2017designsafe]

> "DesignSafe has been developed as a flexible, extensible, community-driven
cyberinfrastructure, and it embraces a cloud strategy for the big data generated
in natural hazards engineering. DesignSafe provides a comprehensive CI that
supports the full research lifecycle from planning to execution to analysis to
publication and curation." [@rathje2017designsafe]

> "The future of natural hazards engineering research requires the integration
of diverse data sets from a variety of sources including experiments,
computational simulation, and field reconnaissance, as well as a variety of
research disciplines including earth science, social science, building science,
and architecture. The DesignSafe cyberinfrastructure has been designed to
provide the functionalities that will enable transformative research in natural
hazards engineering. By adopting a cloud strategy, DesignSafe allows for a
fundamental change in the way that research is performed. It provides a
comprehensive cyberinfrastructure that supports research workflows, data
analysis, and visualization, as well as the full lifecycle of experimental,
field, and computational research required by engineers and scientists to
effectively address the threats posed to civil infrastructure by natural
hazards. The integration of data and computation in the cloud will enable new
research discoveries in natural hazards engineering, which in turn can lead to
more hazard-resilient civil infrastructure." [@rathje2017designsafe]

*Access to R:*

> "The real revolution takes place downstream of data generation. Here, data 
analytics and visualization are performed in the cloud within the *Discovery
Workspace* while accessing any data within the *Data Depot*. Researchers can 
invoke common analysis programs, such as MATLAB, as well as other analysis/
visualization tools, such as Jupyter notebooks. A Jupyter notebook is an 
electronic notebook that allows users to embed rich text elements as well
as computer code, graphs, and visualizations within a single notebook that
can be shared through the web. Over 40 different programming languages are 
supported in Jupyter, including Python and R, and MATLAB code can be easily 
converted, making Jupyter a versatile tool for research. Performing analysis in 
the cloud allows researchers to integrate and explore various data without
tedious downloads. Additionally, using a seamless cyberinfrastructure to 
complete all research tasks enables tracking and relating of the processes 
applied to data." [@rathje2017designsafe]

*Data Depot:*

> "the Data Depot, a flexible data repository with streamlined data management
tools." [@rathje2017designsafe]

> "As data progresses towards publication the requirements for metadata 
increase as metadata provides users with search and discovery functions. At
the end of the research project the user may edit the information for 
publication and complete the process of assigning digital object identifiers
(DOIs) and applying the appropriate license. On-demand assistance from a 
curator is available to provide training and guide users through their data
curation and publication needs." [@rathje2017designsafe]

# Reviewer 2: {-#reviewer-2}

\begin{shaded}
\textbf{Reviewer 2 overview:}
Exposure assessment is essential to study health impacts from disasters, but it
is also a great source of biases due to a lack of a good and fine measure of
exposures during the chaos. Often, epidemiologists use existing data at large
population level such as county level weather data which provide no individual
level exposures but give average exposure at the population level. So it is very
challenging to draw a good causal inference to health outcomes that measured at
the individual level. This manuscript is a well-written report with generously
shared data and programs on US tropical cyclones. This will contribute
significantly to disaster epidemiology which is still a new area and suffering
from good exposure ascertainment.

While I enjoyed reading the manuscript very much, I have one question I could
not figure out clearly.

One objective is to investigate patterns and agreement between different
exposure measures. I do not clearly understand the value of studying agreement
between exposures, while each exposure should be measured separately, so both
individual and overall effects can be assessed.  I do understand using "distance
from the storm" as exposure is only proxy measure and highly sensitive to
misclassification, but because direct storm hazards such as rainfall, flood,
storm surge, and tornado are publicly accessible as authors indicated, authors
could just simply guide readers to use the best exposure data rather than
conducting a quite intense analysis. This may be due to my limited knowledge, so
it would be appreciated if the authors provide explicit explanations on the
purpose and benefit of the analysis.

\end{shaded}

Thank you for this suggestion, and we can see that we could have more clearly 
articulated in the original manuscript how our assessment of patterns in and 
among exposures to specific hazards can help epidemiologists to design their
studies and the statistical methods to analyze the resulting data. 

1. If exposure to the different hazards strongly agrees (i.e., when a county is
exposed to one hazard, they are typically also exposed to a second), this would
have several implications for epidemiological research, especially for
multi-year studies:
  + From a statistical modeling point of view, if you tried to include each
  hazard as a separate independent variable, you would run into problems with
  collinearity if fitting the study data with a generalized linear model or
  other regression model. One implication of this is that the confidence
  intervals on effect estimates for the two variables would be very inflated,
  because the model would struggle to figure out which of the two variables the
  weight should be placed on, and so this uncertainty would be reflected in the
  size of the associated confidence intervals.
  + If you see an effect, it would be very hard to try to determine if the
  causal pathway goes through the first hazard or the second. To mitigate
  effects, it is important to understand the pathway through which they happen,
  and it might be easier to get clues towards pathways if the hazards are better
  separated. (Analogy: if you were able to conduct a controlled experiment to
  look at the effects of each hazard, jointly and in combination, you would
  design separation in the assignment of these treatments, so you could
  distinguish. We can't do that because we are limited to an observational
  analysis, but the area of causal inference is doing a lot to explore how we
  can design observational studies and analyze data to come closer to what we
  might be able to see with a randomized control study, and which of those
  methods we might be able to use for tropical cyclone epidemiology will depend
  on the interplay of these patterns of exposures.)
2. These results will not be surprising to an atmospheric scientist / disaster
researcher, but there are environmental epidemiologists who have done research
on other exposures and are now starting to study tropical cyclones (session at
ISEE, for example). It is useful for epidemiologists entering into tropical
cyclone research to understand these facets of tropical cyclone exposure,
including the distinction between the very coastal wind exposures and other
hazards that tend to reach further inland.
3. There are epidemiological studies that have used only one hazard for exposure
assessment. This has most often been the case for wind. If this exposure
assessment is meant to capture "tropical cyclone exposure" in general, with all
the hazards that are related to tropical cyclones, then there is the chance for
exposure misclassification if this single hazard is used.
4. In the past, it was a very complex issue to try to pull together data on all
these hazards. We agree that now that we have provided a dataset with all of
them, epidemiologists should be thinking about multi-hazard analyses. However,
there still will be some barriers to that. [Recent work on multi-pollutant
exposures and the complexities associated with that.] If one of the hazards
dominates in explaining associated health risk, then in some cases it might be
reasonable to focus on that hazard, but in that case it is critical, based on
our results, to remember that the exposure assessment is not capturing all
hazards of the storms.

We have moved other suggestions that you sent in "Track Changes" of the Word 
document for the original manuscript and address each in detail below.

**Response:** 

\begin{shaded}
\textbf{Reviewer 2 (R2) Comment 1:}
Line 164: Isn't it obvious to use better exposure measures than proxies? Wind,
rainfall, tornado, and flood are direct products of storms while distance is
only proxy of those exposures. Rather than calculating agreement among the
exposures, it would be important to note that these are independent hazards that
can come together or come with different intensity and at different time
windows.

\textit{Lines 164--166 from original manuscript:}

\begin{quotation}
\noindent
\textit{"They found important differences, concluding that a study may be prone
to bias from exposure misclassification if distance to the storm track is used
as a proxy for exposure (Grabich et al. 2015a)."}
\end{quotation}
\end{shaded}

**Response:** 

It is obvious that it is typically better, but in cases where the proxy is much
more practical to measure, it may need to be more than just a bit better, but
instead substantially better. Also, there could be some cases where the proxy
might actually be better---for example, if the proxy can be measured with very
low level, while the direct exposure measure might only be measurable with high
error. In that case, the proxy could be the better metric and might provide a
more precise estimate of the association with health risk.

[Env. Epi. book---advantages and disadvantages of different types of measures]

We agree that it is helpful to clarify for readers that these independent
hazards can come together in a storm event at different intensities and at
different time windows. We have added some text on this:

[Added text]

However, we disagree that this should be down as an alternative to calculating
agreement. Epidemiologists need to understand how these exposure measurements
agree to help in planning studies and statistical approaches to interpreting the
resulting data. In this sense, "agreement" is providing a measure similar to
correlation for continuous variables; our choice of agreement with the binary
exposure classifications reflects the more common use of binary classifications
for most tropical cyclone epidemiology to date.

Epidemiological studies might focus on tropical cyclone exposures at two levels.
First, they might wish to focus on a specific hazard. For example, a study might
hypothesize that mold growth following flooding from a tropical storm might
increase risk of respiratory health outcomes in the months after a storm. In
this case, the clear causal pathway recommends a focus on one of the storm
hazards, rather than all storm hazards. However, other storm hazards could
confound the association between flood exposure and respiratory health risk if
the other hazards are ignored *and* if they are associated with both the
exposure of interest (storm-associated flooding) and the health outcome. For
example, if wind exposure assessments are in high agreement with flood exposure
assessments for storms, and if wind affects risk of respiratory outcomes by
causing extensive property damage and creating extreme psychological stress,
which can have repercussions on respiratory health, then the wind hazard could
confound the estimated association between storm-related flood exposure and the
health outcome.

This bias would be higher when the confounder and exposure of interest are more
strongly correlated (for continuous variables) or in higher agreement (for
categorical variables). Conversely, if the exposure and the potential confounder
are, in practice, only weakly associated, then the potential for confounding is
low. The Jaccard index is one measure of similarities between categorical
(including binary) coefficients.

Another consideration is collinearity. If one hazard is the exposure of interest
and another hazard is a potential confounder, then the model should adjust the
confounder or it will be misspecified and be prone to bias. However, if the
exposure of interest and the potential confounder are very strongly
correlated/in agreement, then including both as independent variables in a
regression model often causes numerical problems in fitting the regression
model, including instability in the estimated coefficients and inflated
variance. In very extreme cases, the statistical software may not be able to
invert the matrix [? only for linear regression?].

Therefore, it is helpful for epidemiologists to understand if these independent
storm-associated hazards tend to be strongly associated (in high agreement),
both within specific storms (for single-storm studies) and on average across
most large storms (for multi-storm studies). This knowledge will help them in
identifying potential confounders if they are interested in studying the effects
of a single hazard of the storm and also in determining if control for these
potential confounders among other storm hazards might cause numerical problems
or other collinearity-associated problems when fitting a regression model.

If a researcher wishes to study the storm as a whole, then the researcher 
could either seek a single measure to capture exposure to the storm as a whole
or investigate more complex models that model the influence of the storm through
pathways of several different hazards. 

If a researcher wants a single measure for the storm as a whole, then it is
helpful to know how well exposure assessments based on the hazard components of
the storm agree with each other. If there is strong agreement, then any of those
hazards could be used as a primary marker of exposure assessment. This is
conceptually similar to checking for observer / rater agreement.

> "When the row and column variable srepresent different observers' rating the
same subjects or objects, interest is focused on *observer agreement* rather
than mere association. In this case, measures and tests of agreement provide a
method of assessing the reliability of a subjective classification or assessment
procedure." [@friendly2015discrete]

> "In assessing the strength of *agreement* we usually have a more stringent
criterion than in measuring the strength of *association*, because observers
ratings can be strongly associated without strong agreement. For example, one
rater could use a more stringent criterion and thus consistently rate subjects
one category lower (on an ordinal scale) than another rater. More generally,
measures of agreement must take account of the marginal frequencies with which
two raters use the categories. If observers tend to use the categories with
different frequency, this will affect measures of agreement."
[@friendly2015discrete]

When you have an array of two or more exposures that are strongly correlated,
including them together in a regression model can cause problems from
collinearity [@schisterman2017collinearity].

> "Environmental exposures ... often consist of an array of related individual
factors that may be highly correlated with each other, causing concern about the
impact of collinearity when attempting to identify individual effects."
[@schisterman2017collinearity]

**Commonly have multiple factors of interest, correlated**

In some areas of epidemiology, researchers have moved toward the idea of a 
"web of causality": 

> "'Multiple causation' is the canon of contemporary epidemiology, and its
metaphor and model is the 'web of causation'. Expressed through the notion
of 'multifactorial etiology' and embedded in the statistical techniques
of 'multivariate analysis', the belief that population patterns of health 
and disease can be explained by a complex web of numerous interconnected 
risk and protective factors has become one of this discipline's central 
concepts. Equally entrenched is the corrolary that epidemiology's power
to improve the public's health rests upon its ability to identify---and predict
the results of breaking---selected strands of this causal web." [@krieger1994epidemiology]

This is in contrast to focusing on single factors: 

> "Expressly challenging the still-pervasive tendency of epidemiologists to
think in terms of single 'agents' causing discrete diseases, the provocative
metaphor and model of the 'web' invited epidemiologists to embrace a more
sophisticated view of causality." [@krieger1994epidemiology]

In this framework, epidemiology helps by identifying where it would help to
break strands of the web: 

> "Using this model, MacMahon et al. drew several important inferences about
prevention and research that remain part of epidemiologic thinking to this day.
Arguing that 'to effect preventative measures, it is not necessary to understand
causal mechanisms in their entirity', they stated that 'even knowledge of one
small component may allow some degree of prevention' since 'wherever the chain
is broken the disease will be prevented'." [@krieger1994epidemiology]

In other words, if you can identify *necessary* causes, you can craft 
*practical* interventions. 

In some fields of epidemiology (e.g., nutritional epidemiology), it is common 
to study cases where there are multiple potential risk factors, and these 
factors are often strongly correlated [@schisterman2017collinearity].

> "The dynamics of many important ecological and evolutionary processes are 
often influenced by multiple interacting factors, and attempting to understand 
the dynamics of such systems presents difficult technical and philosophical 
problems." [@petraitis1996inferring]

> "Often in practice, investigators are faced with decisions of how to handle
highly correlated variables." [@schisterman2017collinearity]

**Methods to tackle multiple causality**

When the aim is to explore the influences of multiple associated factors, there
are some different strategies that can be used. These include multiple
regression and path analysis:

> "Evolutionary ecologists have recently turned to path analysis, multiple
regression, and related techniques to analyse systems of multiple causality.
While these techniques are often seen as competitors, they are, in fact,
related, and as a result the problems of these techniques are similar."
[@petraitis1996inferring]

**Implications of collinearity**

> "Two variables are defined as collinear if one can be expressed as an exact
or near linear combination of the other. ... In general, collinearity between
variables is described by the magnitude of their correlation." 
[@schisterman2017collinearity]

It can complicate inference of model coefficients. This is always a concern for 
inferential models. For predictive models, it can be a problem if you later use
the model to predict in a case where the correlation structure is different than
in the training data. 

> "The dependence of regression and path coefficients on the correlation
structure is often glossed over. Yet this dependence means that inferences about
the strengths of path coefficients are conditional upon the correlational
structure among the predictor variables. If the correlation structure of the
sample does not match the correlational structure of the population then
regression and path coefficients will not estimate relative strengths
accurately. This can occur if sampling is not random or if analysis is based on
data from experiments with factorial designs, which break the correlational
structure amnog the predictor variables." [@petraitis1996inferring]

These implications can depend on whether the modeling goal is predictive or 
inferential. 

> "When the goal is to choose covariates based on their predictive value, 
concerns about collinearity stem from the desire to improve parameter estimates'
precision, which can be inflated when highly correlated covariates are included
in the model." [@schisterman2017collinearity]

> "In a causal framework, on the other hand, interest is often centered on a
specific effect from a correctly specified causal model, even in the presence of
highly correlated data, despite a potential loss of statistical efficiency.
Under such a viewpoint, bias due to misspecification of the causal associations
is a more devastating result than reduced precision of parameter estimates
correctly estimated. Furthermore, a precisely but incorrectly estimated
parameter may lead to invalid inferences. ... Relying on conventional
variable-selection algorithms and standard analyses can ignore important
confounders and even produce extremely imprecise confidence intervals."
[@schisterman2017collinearity]

The amount of bias in the unadjusted model (in terms of bias from an unadjusted
confounder) depends on the strength of association between the exposure of
interest and the potential confounder [@schisterman2017collinearity].

> "This is especially important for the confounding variable scenario, where 
correctly specifying the model may result in adjusting for a nearly 
collinear variable." [@schisterman2017collinearity]

The degree of agreement will influence the degree of confounding in an 
unadjusted model, for either one or two confounders: 

> "In this confounding scenario, increasing correlation exacerbates the bias
due to misspecification, similar to results for a single confounder."
[@schisterman2017collinearity]

Extreme collinearity can create numerical problems
[@schisterman2017collinearity].

> "Under the extremely unlikely scenario of extreme collinearity [(abs. rho of
0.999 or higher)], the numerical matrix inversion required for estimation fails,
resulting in unstable and biased predictors." [@schisterman2017collinearity]

> "Only for extreme values of rho cloes to 1 or -1 is beta-squareed
nonidentifiable due to numerical instability; otherwise, the correctly specified
model produces the most desirable (e.g., unbiased) estimates of the total effect
of the exposure on the outcome." [@schisterman2017collinearity]

Collinearity can cause imprecision in coefficient estimates, even if those
estimates are unbiased [@schisterman2017collinearity].

> "Multicollinearity: A term that refers to correlation among the independent
variables in a multiple regression model; it is usually invoked when some 
correlations are 'large', but an actual magnitude test is not well defined.[1]"
[@gunasekara2008glossary]

> "Collinearity occurs in multiple regression models when two (or
more---multicollinearity) exposure variables are included in the model but are
so similar to each other that they are essentially measuring at least part of
the same thing. Collinearity creates problems with interpreting the analysis by
affecting the standard errors of the variables (as it increases variance)[24]
and by causing biased estimates for one or both of the collinear terms
(sometimes dramatically so) [25]. If there is perfect collinearity between two
variables then one should be dropped from the model. However, dropping exposure
variables to reduce multicollinearity may lead to bias in the model from
dropping useful information." [@gunasekara2008glossary]

> "It might be argued in some cases that it is appropriate to include
(collinear) variables in a model even when they are highly correlated, because
the theoretical basis for including the variables is strong and the results of
the model are consistent with expectations [10]. In such cases, models with and
without the variables would be tested and compared. Such consideraion of
alternative models tends to be described as an issue of (mis)-specification in
econometrics. However, in epidemiology this tends to be described in terms of
mediating and *intermediary variables*. Thus, an epidemiologist might argue for
including an intermediate variable in a model (and testing it against a model
without the variable) because including that variable might elucidate direct and
indirect pathways between the exposure and outcome variables. An econometrician
might do the same thing but describe this in terms of finding the correct model
specification." [@gunasekara2008glossary]

**Techniques to address collinearity**

There are study designs that might help to separate different effects. For
example, some matching designs might help in creating a subset of data in which
the association that exists in the full dataset is broken (e.g.,
@leal2012multicollinearity).

> "Matching is typically employed to reduce model dependence and estimate 
associations in a more empirical way than would be necessary without 
matching. In line with this practice, matching was employed as a diagnostic
tool to verify whether the effects of environmental variables that are highly 
correlated with each other could be disentangled." [@leal2012multicollinearity]

You could also explore techniques of dimension reduction, to create a smaller
subset of independent variables for which the correlation is broken. For
example, you could use PCA [@leal2012multicollinearity].

There are other techniques that allow some bias in estimates in an attempt to
reduce problems from collinearity, like ridge regression
[@petraitis1996inferring].

> "Several biased estimation techniquest ahve been proposed as a way to combat
collinearity (Myers 1990). These are controversial methods. Ridge regression,
for example, biases the regression coefficients in order to improve the model's
ability to predict the criterion variable. The estimates of the individual
regression coefficients may be very biased even though when taken together they
provide a very good prediction of the criterion variable."
[@petraitis1996inferring]

> "When correct specification of the models still leads to 
problems for conventional regression methods, one can apply modern techniques
such as Bayesian hierarchical models with shrinkage estimators."
[@schisterman2017collinearity]

**Are effects of different factors 'separable'?**

Epidemiology often aims to inform policy decisions. In this case, it can be
important to characterize the separate effects of different associated factors
that contribute to the health risk [@leal2012multicollinearity].

> "To develop efficient public health interventions addressing the obesity 
epidemic, it is important to identify exactly which aspects of the
environment influence obesity risk. For example, demonstrating that the density 
of fast-food restaurants was associated with obesity risk and demnstrating that
the density of sports facilities was associated with obesity risk would lead to 
different interventions." [@leal2012multicollinearity]

However, it can be very difficult to separate the effects of different factors
if those factors are strongly correlated [@leal2012multicollinearity]: 

> "However, many neighborhood characteristics, especially those related to the
densities of physical features and services, are strongly correlated with each
other. Therefore, it is not clear whether it is even possible to disentangle the
effects of these different environmental dimensions, even if they are
hypothesized to influence obesity risk through distinct causal pathways."
[@leal2012multicollinearity]



\begin{shaded}
\textbf{R2 Comment 2:}
Line 354: I am not sure why different exposures should be compared and measured
the agreement. I would just treat each exposure as single independent exposure
and give a summary score by summing all the exposure with some weighting for
multiple exposures.

I may not understand the importance of this approach. If so, adding the
explanation would help readers not to questioning.

\textit{Line 354 from original manuscript:}

\begin{quotation}
\noindent
\textit{"Finally, we investigated how well exposure assessment agreed across
these metrics."}
\end{quotation}
\end{shaded}

**Response:** 

As we note in our general response to your comments, we agree in general with
your instinct here. However, there are some subtle points to note.

First, we understand the potential appeal of creating a single exposure summary
score based on a summation of exposures. This simplifies some of the statistical
modeling, for example, and also provides a single exposure estimate to provide
as the key study conclusion. However, in many areas of tropical cyclone
epidemiology, it is unlikely that exposure to each type of hazard should be
given equal weight. For example, an analysis of respiratory health in the months
after the storm might hypothesize a strong connection with flooding, and smaller
connections with rainfall and winds (through the pathway of property damage).
Use of a pre-defined summation of exposure to each hazard would mask some of the
potential association.

While a summary statistic could be defined that adds a weight to each exposure,
it would often be unclear *a priori* what weight each hazard exposure should be
given. A better method might be to use a regression framework, where each hazard
exposure is included as a separate explanatory variable, and the model uses the
observed data to determine the appropriate weight for each hazard in terms of
modifying risk to the outcome of interest. To explore the influence of multiple
concurrent hazards, interaction terms could be added.

However, if our analysis had found that hazard exposures follow very similar
patterns, in terms of the counties exposed during a storm, then this strong
agreement would result in a number of problems in fitting and interpreting these
types of models. First, strong agreement in two or more of the explanatory
variables in a regression model leads to collinearity, which among other
implications often leads to a large inflation of confidence intervals for the
effect estimates of the correlated explanatory variables. Further, if the hazard
exposures were in strong agreement, then it would be difficult or impossible to
disentagle the effects of the separate hazards, as a strong effect for one would
be impossible to interpret with confidence, since the strong agreement in the
data (and resulting low co-variability in the variables in the data) could cause
the model to mistakenly attribute the effect of one hazard to the other.
Further, it may become impossible in this case to estimate synergistic effects
between the two, as an indicator of an interaction between the two exposures
would be almost collinear with the two main effects.

In our analysis, we find that this is usually not the case for the four tropical
cyclone hazards that we consider. Instead, we find that for most storms, the
hazards are fairly well-separated in terms of the counties they effect. There is
a particularly strong pattern where inland counties can be exposed to extreme
rain and flooding, but not wind. This separation opens the door for some
interesting study designs and statistical modeling. For example, these patterns
suggest that a study could investigate whether storm-associated rains alone
create a health risk, as there are many exposures with only rain in inland
counties, and so health associations could be explored here and contrasted with
coastal areas that experienced both wind and extreme rain.


\begin{shaded}
\textbf{R2 Comment 3:}
Line 394: It looks like the correlation coefficients can be very low if measured
from 75mm or somewhere around.  This seems to be a significant issue for
analyzing storms with heavier rainfall using NLDAS-2 data.

\textit{Line 392--394 from original manuscript:}

\begin{quotation}
\noindent
\textit{"Within these counties, storm-related rainfall measurements were
well-correlated between the two data sources, with rank correlations (bottom
right of each graph in Figure 2) between 0.87 and 0.98. "}
\end{quotation}
\end{shaded}

**Response:** 

This is a great idea. In the original manuscript, we describe this lower
correlation at higher precipitation values through the use of examples from
specific storms, and discuss the potential reasons for it, but measuring the
correlation specifically within these higher-precipitation events would add more
quantitative evidence to this discussion.

Here is the text where we discuss this point in the original manuscript:

> **Text in original manuscript:**
"There was some evidence that our primary rainfall metric may tend to
underestimate rainfall totals in storms with extremely high rainfall, based on
a few heavy-rainfall storms in Harris County, TX, Mobile County, AL, Charleston
County, SC, and Wake County, NC (Figure 2)."

> **Text in original manuscript:**
"The rainfall data are generally well-correlated with ground-based observations,
but may sometimes underestimate very high rainfall values (Figure 2). When
rainfall data is used to create binary exposure classifications, this
disagreement is unlikely to influence results, as both data sources agree in
identifying these as storms with high rainfall, but would be important to
consider for cases that include rainfall as a continuous measurement."

We have added estimates of these correlations specifically for
high-precipitation events in a new table in the Supplemental Material (Table S1,
reproduced as Table \@ref(tab:highprecipcorr) of this response document).

\input{tables/precip_high_corr.tex}

\begin{shaded}
\textbf{R2 Comment 4:}
Figure 4: I would add Y-axis label "NOAA classification."
\end{shaded}

**Response:** 

This is a great suggestion. We have made this change, as well as several changes
in response to EHP's Request 4 later in this response.

The original and revised versions of Figure 4 of the paper are reproduced in
Figure \@ref(fig:fig4) of this response.

```{r fig4, fig.cap="Reproduction of Figure 4 from the original manuscript (top) and revised version in the resubmitted manuscript (bottom). In the revised version, we have added a title to the y-axis ('Classification based on NOAA Storm Events Data'), binned the values shown by each point's fill, so these colors are easier to distinguish, increased the size of the points, and changed the algorithm for jittering, so none of the points overlap.", fig.show = "hold", fig.align = "center", out.width="100%"}
include_graphics("../figures/floodcomparison.pdf")
include_graphics("figures/floodcomparison.pdf")
```

\begin{shaded}
\textbf{R2 Comment 5:}
Table 2: This is another confusing table. Not sure what compared here. The
second column is a mean \# of exposed counties over years and the third column
seems like showing single storm with the max \# of exposed counties. Not sure
what info I should digest from this table.
\end{shaded}

> **Text from Results of original manuscript:**
"Across the four storm hazards considered, there was wide variation in the
average number of county exposures per year (Table 2). For tropical cyclone
tornadoes, there were on average about 40 county exposures per year within our
study. County exposures were more frequent for tropical cyclone wind exposures
(>160/year on average), even more frequent for tropical cyclone flood exposures
(>190/year on average), and most frequent for tropical cyclone rain exposure
(>290/year on average). For every hazard except tornadoes, we identified at
least one tropical cyclone that exposed over 250 counties (Table 2). However,
the largest-extent tropical cyclone varied across hazards: Frances in 2004
exposed the most counties based on rain, Michael in 2018 based on wind, and Ivan
in 2004 based on flooding and tornadoes (Table 2)."

**Response:** 

\begin{shaded}
\textbf{R2 Comment 6:}
Subsection of Results on \textit{Agreement across exposure metrics}: 
As stated below, storms bring different hazards to different locations with
different time. What would be new learning by comparing these different pairs of
exposure metrics. Somewhat apple and orange comparison. Maybe providing more
explanation can help what the important learning from this is. I may not catch
it. Similar comment was added earlier.
\end{shaded}

**Response:** 

\begin{shaded}
\textbf{R2 Comment 7:}
Lines 494--495: Why this agreement is important? Same questions added above
already, but still wonder what I missed. It seems like the authors try to
develop an exposure matrix that is common in occupational epidemiology, but it
is only valid method when the exposures are similar and lead to the same health
outcomes.  Rain, wind, flood, and tornado should be treated separately, maybe
except rain and flood. It is possible to be an extreme storm with only severe
wind without major impacts from other exposures. Tornado is a good example.

\textit{Line 491--495 from original manuscript:}

\begin{quotation}
\noindent
\textit{"For another set of tropical cyclones (e.g., Ernesto in 2006, and Bertha
in 1996, Isabel in 2003), there was moderate to good agreement for pairwise
combinations of distance, rain, and wind, but poor agreement for other
combinations of metrics, while for another set of storms (e.g., Matthew in 2004
and Katrina in 2005), there was moderate to good agreement between distance and
rain."}
\end{quotation}
\end{shaded}

**Response:** 

> "A job exposure matrix (JEM) may be defined as a cross classification of jobs
and occupational exposures. Some matrices are based on tasks, instead of jobs. 
... Usually there is a group of experts who build the matrix based on their 
own knowledge and experience on occupational exopsures. The experts should 
assess exposure to an open or fixed list of occupational exposures (that can 
include chemical, physical, biological, and/or psychosocial agents) for an
open or fixed list of jobs (or tasks) usually coded according to some established
national or international classification system. Some JEMs also include 
information for different calendar time periods." [@garcia2003glossary]

[New advances in multi-pollutant analysis.]

[Some of the hazards could create similar risks, if they converge on a common
pathway of risk. For example, if pathway is through stress from property damage,
individually and in the county, then several hazards could indeed lead to the
same health outcomes (e.g., PTSD, other psychological markers, risk of acute
cardiovascular outcomes, etc.). One example is extreme level of destruction both
from wind (Hurricane Andrew, Hurricane Hugo), from river flooding associated
with among of precipitation (Hurricane Floyd, Hurricane Florence), and from
flash flooding associated with the rate of precipitation (Virginia storms).]

[A better future direction might be through regression models with multiple
explanatory pathways. This allows the model to fit different weights to each.
Other models can also be explored, like regression trees, which might have an
easier time capturing non-linearity (if exposure is included as a continuous
value, as with wind and rain) and interactions when there are co-exposures to
two or more hazards. Both of these are able (and will) either exclude or give a
very low weight to an explanatory variable that does not help much in explaining
variation in the health outcome.]

\begin{shaded}
\textbf{R2 Comment 8:}
Line 515: It would be informative to provide correlation coefficient for only
above 75 mm measures.

\textit{Line 514--515 from original manuscript:}

\begin{quotation}
\noindent
\textit{"The rainfall data are generally well-correlated with ground-based
observations, but may sometimes underestimate very high rainfall values (Figure
2)."}
\end{quotation}
\end{shaded}

**Response:** 
This is a great suggestion and helps provided quantitative support to the text
in the paper that the reviewer highlighted when making this comment. We have
added a table in the Supplemental Material that provides the Spearman
correlation coefficients for both all tropical cyclones to come near the sample
counties (replicating the analysis shown in Figure 2 of the main text) and
then when the analysis is limited to only those events with cumulative
precipitation of 75 mm or higher based on either data source.

In several cases, the correlation was much weaker when limiting analysis to
these severe rainfall events. For example, in Miami-Dade County, FL, the
Spearman correlation coefficient was 0.94 for all 64 tropical cyclones that came
near the county over the analysis period, while it was only 0.49 among the 18
storms with cumulative precipitation of 75 mm or more. There was a similar
reduction in Mobile County, AL. However, for some counties, the correlation
remained high (e.g., Harris County, TX; Orleans Parish, LA), although in all
cases there are small numbers of extreme precipitation events (5--20 across
these sample counties), and so there is likely substantial random variation in
these correlation estimates, since they are based on small numbers of 
observations.

[Include copy of table here.]

Finally, we have added a bit to the text that the reviewer cited to mention 
this point and to direct readers to the added supplemental table: 

> Text in revised manuscript (relevant addition in bold):
"The rainfall data are generally well-correlated with ground-based
observations, but may sometimes underestimate very high rainfall values (Figure
2), **and in some counties the correlation was substantially lower when 
considering only tropical cyclones with cumulative local rainfall of 75 mm
or more (Supplemental Table 1)**."

\begin{shaded}
\textbf{R2 Comment 9:}
Line 602: This is not a new finding, but how much misclassified would be a good
question to answer.

\textit{Line 600--602 from original manuscript:}

\begin{quotation}
\noindent
\textit{"Based on our results, the use of a distance-based metric to assess
exposure to any of these hazards, or the use of measurements from one hazard as
a proxy for exposure to any of the other hazards considered, would often
introduce exposure misclassification."}
\end{quotation}
\end{shaded}

**Response:** 
[Add new analysis of what percent of counties misclassified if distance 
is used as proxy for each hazard?]

\begin{shaded}
\textbf{R2 Comment 10:}
Lines 626--627: It would still be beneficial to treat each exposure as a single
variable first and then consider overall impact. Only if each exposure data are
available.

\textit{Line 626--628 from original manuscript:}

\begin{quotation}
\noindent
\textit{"For these storms, it may be possible to assess exposure to multiple
hazards of the storm using a single metric, perhaps even a proxy like the
distance between the county and the storms track."}
\end{quotation}
\end{shaded}

**Response:** 
We agree. This type of approach has not always been easy in the past, but can
be easily implemented with the dataset we publish here. We have added to the
text on this point: 

> Text in revised manuscript (relevant addition in bold):
"For these storms, it may be possible to assess exposure to multiple
hazards of the storm using a single metric, perhaps even a proxy like the
distance between the county and the storms track. **With the dataset we 
describe in this paper, however, there is little need to limit analysis
based on exposure to a single hazard or proxy, although multi-hazard studies
of storms with high agreement among hazard exposures should look out for 
modeling issues from multicollinearity.**"


# Reviewer 3: {-#reviewer-3}

\begin{shaded}
\textbf{Reviewer 3 overview:}
This paper describes the development of a dataset and R package that can be used
to assess exposure to tropical cyclone-related hazards (e.g., wind,
precipitation, flooding) at the county level in the eastern United States, as
well as a descriptive analysis of county-level exposure to these hazards. This R
package is novel and I believe of high interest to researchers interested in the
health effects of tropical cyclones.  I have a few minor suggestions to further
improve the clarity of the manuscript.
\end{shaded}

**Response:** 

\begin{shaded}
\textbf{Reviewer 3 (R3) Comment 1:}
Starting on line 128, the authors write "Extreme winds are more common to the
track's right, where counterclockwise cyclonic winds move in concert with the
tropical cyclone's forward motion". I think this statement may be specific to
tropical cyclones in the Northern hemisphere (i.e., those relevant to exposure
in the US). Would be good to clarify this.
\end{shaded}

**Response:** 

You are right, the opposite would be true in the Southern hemisphere. This
difference is driven by the Coriolis effect on cyclonic rotation, in which the
rotation of the earth diverts winds as they move toward the low pressure center
of the cyclone. We have edited the text to specify that this statement is
specific to the Northern Hemisphere:

> **Text in revised manuscript (relevant addition in bold):**
"**In the Northern Hemisphere, cyclonic winds are counterclockwise,** so
extreme winds are more common to the track's right where cyclonic winds move in
concert with the tropical cyclone's forward motion."

\begin{shaded}
\textbf{R3 Comment 2:}
Line 186: What is meant by the phrase "synoptic times"?

\textit{Lines 185--187 from original manuscript:}

\begin{quotation}
\noindent
\textit{"We used tracking data from HURDAT2, which records the storm centers
position at the synoptic times of 6:00 am, 12:00 pm, 6:00 pm, and 12:00 am
Coordinated Universal Time (UTC)."}
\end{quotation}
\end{shaded}

**Response:** 

"Synoptic meteorology" refers to ...
A key idea is that observations from a widespread geographical area can be
integrate to provide a picture of large-scale weather [features?], including
large areas of high or low pressure [?].

> "In meteorology, the term synoptic denotes simultaneous observations taken
globally, or at least over a large area." [@willoughby2007hurricane]

> "Nearly 20 years ago [from 1937] [Bjerknes] declared that numerous and 
important problems might be solved with the aid of observations already 
assembled in the archives of different bureaus, but that the difficulties
in making these observations serve a special purpose were unsurmountable
for the individual scholar. He added that, in particular, the synoptic 
charts representing the momentary states of the atmosphere over large
areas of the earth, in all the necessary details and exactitude, were 
excessively difficult to assemble. His proposal was that there be entered
at the central bureau of each country, on the appropriate maps, all the available
observations taken in that country and that there be employed, by the different
bureaus, maps that may be superimposed or juxtaposed." [@gregg1937international]

However, to integrate data from many sources to provide inputs for broadscale,
synoptic analysis, it is helpful to use some standards in collecting these data
at different locations. To facilitate numerical weather forecasting and other
synoptic meteorology, weather data are regularly collected at standardized
times, so that the data can be more easily integrated as an input to models.
This practice extends back over 100 years, when data were collected from many
[offices?] in the US by telegram [?] at regular times during the day and used to
create synoptic weather maps that captured major weather systems in the country.

> "In order to allow comparison of surface conditions at the same time
throughout the world, the groups regulating the collection of
hydrometeorological data have established a standard time for taking
observations. These observations will have times observed within the 10 minutes
preceding the UTC standard time. Hence surface observations for meteorological
use have timestamps reflecting 0000, 0300, 0600, 0900, 1200, 1500, 1800, 2100
UTC." [@usnwstime]

> "Since the end of World War II, observers have launched rawinsonde observation
worldwide at 00 and 12 UTC (coordinated universal time). High-threat situations,
such as impending TC landfall, may dictate observations at 6-h or even 3-h
intervals. Interpolating rawinsonde observations to the model's mesh and
starting the calculation at a synoptic time is the simplest way to prepare a
model initial condition." [@willoughby2007hurricane]

> "Because simple interpolation in space and time is a less-than-optimum way to
use observations, nonsynoptic data require elaborate four-dimensional
variational data assimilation schemes." [@willoughby2007hurricane]

> "By 1941, charts for the 750, 500, and 250 mbar surfaces were being prepared
daily for 0400, 1200, and 2000 GMT." [@grahame2000development]

> "During the period considered here, NHC issued advisories 3 h after the
standard synoptic time (0300, 0900, 1500, and 2100 UTC)." [@torn2012uncertainty]

> "The operation data assimilation and forecast cycle interval is 6 h"
[@aberson201010]

> "Dan Petersen asked whether a data deficiency really exists with all the
observational sources in the Atlantic region, or are the data not being properly
used in the numerical models? ... Steve Lord emphasized the difficulty of the
task because many of these observations are not obtained at the synoptic
times..." [@elsberry1992there]

> "In the modern era, forecasters rely on purely dynamical models that integrate
the Navier-Stokes equations for atmospheric motions to represent both the storm
itself and its surroundings. Numerical models are structured on a computational
grid with temperature, moisture, and wind tabulated in more-or-less rectangular
cells." [@willoughby2007hurricane]

> "Predicting the weather required a widespread but highly coordinated team of
observers and forecasters. Organization was key... They transmitted data from
the field using forms and protocols adapted from those that Abbe had developed
while forecasting the weather from Cincinnati, Ohio. The information arrived by
telegraph coded to maximize accuracy and minimize the word count and changes.
The reports piled up in a rush at the appointed hours." [@willis2006cleveland]

> "Three times daily the duty forecaster broadcast a synopsis of prevailing
weather conditions nationwide..." [@willis2006cleveland]

> "The requirement of synoptic data collection is easily met by the
'conventional' observing system now serving as the main source of meteorological 
data throughout the world, since it is based on human observations which could 
be scheduled at convenient synoptic times." [@morel1971initialization]

Since large-scale weather features are very larger, relevant data for a synoptic
map often comes from locations with different local times. The need for
synchronized weather data collection therefore actually played an important role
in establishing standardized time zones in the United States in [year]. Synoptic
weather times are typically set based on the Universal Time Constant, with times
recorded in Coordinated Universal Time (i.e., Greenwich ...), and time stamps on
weather maps and data based on this time zone often is given a "Z" (for "Zulu",
an earlier name for this timezone) after the time.

> "Accuracy in forecasting depended on the accurate timing of observations. At
first weather observers used local time because no system of standard time
existed, either in the United States or abroad. Local time often meant railroad
time, and that could vary as much as 20 minutes from the time proper to the
local meridian. Abbe called for change, emphasizing the need for simultaneous
readings by Signal Service observers in order to construct accurate charts and
weather maps. In 1875, he recommended to the president of the American
Meteorological Society the establishment of a committee on standard time. ...
Abbe's report in 1879 recommended the system of meridians that is now in general
use ... a system of time meridians one hour apart across the country, anchored
on the Greenwich prime meridian." [@willis2006cleveland]

> "From Abbe's perspective, however, the full potential for dynamic weather
prediction would not be achieved without standard time worldwide."
[@willis2006cleveland]

> "The time in all hydrometeorological products is expressed according to 
a single standard, which is the Universal Coordinated Time (UTC) 
(formerly known as Greenwich Mean Time [GMT] or Zulu (zero) Time [Z])."
[@usnwstime]

> "The U.S. National Weather Service base all data and product times on the 
UTC standard. ... A common practice is to include a time of the observation 
or event denoting the time with a following capital letter 'Z' to indicate the 
time as UTC." [@usnwstime]

> "The extent and the hour of the observations changed over time. Originally the
observers took the readings at 0735, 1635, and 2335, Washington time, but the
last reading was soon changed to 2300 so that the information could be included
in the morning newspapers. Before the introduction of standard time and time
zones within the United States, a confusing multiplicity of local times existed.
In 1870 there were over 100 such regional times. For the purposes of the
meteorological observations, observers used Washington time until 1885.
Thereafter the observers took their readings according to eastern time, or that
at the 75th meridian west of Greenwich, England. Observers also made local-time
readings from 1876 to 1881.[30]" [@raines1996getting]

> "Once the observers had gathered the weather data, the means of reporting and
disseminating it became most important. Like the Smithsonian, the chief signal
officer made arrangements with the leading commercial telegraph companies to
carry the tri-daily reports. Civilian telegraph experts established special
circuits routed to the Signal Office. The initial arrangement with Western Union
regarding transmission was only temporary, and at the end of the trial period
the company refused to continue service. The House Appropriations Committee held
hearings over the dispute and ruled that the company had a mandate to transmit
the weather information as government business. The Signal Corps compensated the
company, however, at rates determined by the postmaster general.[34]" [@raines1996getting]

> "When making the daily telegraphic reports, the weather observers used special
codes to reduce their length to twenty words in the morning and ten in each of
the other two reports, thereby saving the government both time and money.[35]
Regular transmission of the reports began at 0735 on 1 November 1870 from
twenty-four stations stretching from Boston, Massachusetts, south to Key West,
Florida, and west to Cheyenne in the Wyoming Territory. In addition to the
station atop Mount Washington (opened in December 1870), the Signal Corps soon
reached new heights in weather reporting with the station on Pikes Peak that
began reporting in November 1873.[36]" [@raines1996getting]

> "To provide a picture of weather conditions across the country, the observers
made their reports as nearly simultaneous as possible. The weather service did
not initially make forecasts, and the enabling legislation did not specifically
call for it to do so. Eventually general forecasts, referred to as
probabilities, emanated from the Signal Office in Washington. Locally, the
observers posted bulletins and maps in the offices of boards of trade and
chambers of commerce to provide weather information to the public. Post offices
also displayed daily bulletins, and observers supplied local newspapers with
data. Some communities appointed meteorological committees to confer with the
chief signal officer and to serve as a check upon the operations of the local
weather station. On the national level, the Signal Office in Washington issued
daily weather maps compiled from the reports received from all the stations. It
also published the Daily Weather Bulletin, Weekly Weather Chronicle, and the
Monthly Weather Review. All were available for sale to the public. Myer
estimated that through these various means at least one third of American
households received the Signal Corps' weather information in some form. A
railway bulletin service, initiated in 1879, enabled stations along many major
railroads to display weather information.[37]" [@raines1996getting]

> "The Signal Corps' telegraph network soon expanded beyond the eastern
seaboard. In 1874 Congress enacted legislation directing the War Department to
build lines to connect military posts and protect frontier settlements in Texas
against Indians and Mexicans. Other acts authorized lines in Arizona and New
Mexico and, somewhat later, the Northwest. These lines were intended to serve
sparsely settled areas where commercial lines were not yet available. For the
most part, soldiers maintained and operated the lines, but the Corps employed
some civilians. As the telegraph extended its reach, the weather system also
grew, because the operators doubled as weather observers." [@raines1996getting]

> "Until 1934 the Weather Bureau offices operated 12--15 hours a day with two
basic observations taken at 8 a.m. and 8 p.m. The observations were transmitted
via telegraph. There were no satellite images and few upper air observations."
\url{https://www.weather.gov/dvn/armistice_day_blizzard}


We have added text to clarify the meaning of "synoptic times" in the text:

> **Text in revised manuscript (relevant change in bold):**
"We used tracking data from HURDAT2, which records the storm centers position
at **four standardized times for weather data collection (synoptic times),**
6:00 am, 12:00 pm, 6:00 pm, and 12:00 am Coordinated Universal Time (UTC)."

\begin{shaded}
\textbf{R3 Comment 3:}
Several of the exposures are calculated for the population mean center of each
county. From the reference list, it looks like the authors consistently used
population centers from 2010 throughout the years included in the dataset/R
package. If so, I suggest clarifying this in the text. 
\end{shaded}

**Response:** 

This is correct---the population centers from the US 2010 Decennial Census were 
used throughout. We have added text to the manuscript to clarify this: 

> **Text in revised manuscript (relevant addition in bold):**
"At each 15- interval, we measured the distance between the storm's
center and each county's population mean center, **as of the 2010 US Decennial
Census** (US Census Bureau 2020)."

\begin{shaded}
\textbf{R3 Comment 4:}
In the methods section starting on line 276, the authors describe the flooding
and tornado data from the NOAA storm events database. I'd suggest providing some
information about where the events in this database come from (e.g., that they
are reported events) here in addition to covering it in the discussion.

\textit{Lines 276--281 from original manuscript:}

\begin{quotation}
\noindent
\textit{"To identify flood- and tornado-based tropical cyclone exposures in US
counties, we matched storm tracks with event listings from the National Oceanic
and Atmospheric Administration (NOAA)s Storm Event Database (NOAA NCEI 2020).
While this database has recorded storm data, particularly tornadoes, since 1950,
its coverage changed substantially in 1996 to cover more types of storm events,
including flood events (NOAA NCEI 2020). We therefore only considered flood
metrics of tropical cyclone exposure for storms in 1996 and later."}
\end{quotation}
\end{shaded}

**Response:** 

\begin{shaded}
\textbf{R3 Comment 5:}
Line 294: What is meant by the phrase "traditional tornado event database"?

\textit{Lines 294--295 from original manuscript:}

\begin{quotation}
\noindent
\textit{"The tornado observations from this dataset form a traditional tornado
event database for the US, and so we did not further validate the tornado event
data."}
\end{quotation}
\end{shaded}

**Response:** 

The NOAA Storm Events database originated as a database for recording tornadoes
[? anything else] in the US in 195[x], and was originally called ... . The
database has gone through a number of expansions to cover more events, and it
now includes reports of other types of [hydrometeorological?] disaster events,
including floods, extreme heat and cold, wildfires, frost, hail, ... . However,
it has maintained its status as the database of record [?] for tornadoes in the
United States.

Examples of research papers that leverage this database as a record of tornado
events, or the version of it shared by the [Severe Storm ...] through their
website [ref], include ... .

[Is this database used to validate tornado forecasts / warnings?]

This database has evolved through several stages but has, since its earliest
iteration in the 1950s, served as the National Weather Service's [?] data of
record on tornado events. While there is also a database maintained by the 
[Severe Storm ...], the two databases have different names but almost 
identical information once data are aggregated to a daily, county-level 
measure of whether there was a tornado recorded in that county on that date. 
[Difference between the two and why there are two.]

There is no other tornado base at the same temporal and spatial scale that
we could use for validation.

This database serves as the basis for much of the large-scale (e.g., assessing
patterns over the US over long time periods) tornado-based research for the US. 
It does have some well-documented limitations. One is a notable increase over 
time in the number of tornadoes reported, particularly for the weakest, F0 [?]
tornadoes. [This stabilizes some in the age of radar?]

> "Weather events listed in the publication Storm Data are considered to be
the official database for tornadoes by the National Weather Service." 
[written by someone at the NWS Storm Prediction Center] [@mccarthy2003nws]

The US National Weather Service's Storm Prediction Center has a tornado database
called the "National Tornado Database" [@center2020storm]. This uses the NOAA
Storm Events database as its primary source [@center2020storm]. They note on their
website: 

> "The tables below provide the links to comma separated values (.csv) files for
tornadoes, hail, and damaging winds, as compiled from *NWS Storm Data*. Tornado 
reports exist back to 1950 while hail and damaging wind events date from 1955.

The NOAA Storm Events database, or the Storm Prediction Center's version of the
tornado database have been used in a number of studies, including in a number of
studies of tornado climatology [@tippett2016more; @brooks2003climatological;
@strader2015climatology].

> "The dataset we will use is the so-called smooth log of severe-weather reports
collected by the SPC and archived in the National Oceanic and Atmospheric 
Administration publication *Storm Data*." [@brooks2003climatological]

> "Data such as tornado magnitude, path length, path width, and so on are
recorded by the National Climatic Data Center (NCDC) as a public service and for
use in meteorological, climatological, and engineering studies (Edwards et al.
2013)." [@strader2015climatology]

Sometimes used in conjunction with other NWS data products: 

> "Initially, tornado cases available in the NWS's Damage Assessment Toolkit
(NOAA, 2014) were employed, which is a GIS-based framework for collecting,
storing, and retrieving damage survey data (Camp et al., 2014). This toolkit
provides a variety of tornado event filtering (tornado survey point, track,
footprint, and/or swath) and download options [key mark-up language (.kml) or
shapefile (.shp)], supplying an initial sample of georeferenced damage
assessments. In this study, a tornado footprint is defined as the maximum areal
extent of tornado intensity inferred by the damage, wind speed measured directly
by mobile Doppler radar, or assessed theoretically as the recorded length
multiplied with the maximum width as reported in Storm Data."
[@strader2015climatology]

> "To serve the public interest and the National Climatic Data Center (NCDC)
storm data record, the National Weather Service (NWS) documents the path length,
width, and maximum damage rating for every tornado county segment (NOAA
2007).[Footnote in manuscript: County segments of tornado paths are then
combined at the NWS Storm Prediction Center to yield a unified one-tornado
(ONETOR) dataset of whole-tornado records (Schaefer and Edwards 1999).] Such
data are used in meteorological and climatological research, as well as in
determining construction standard for critical infrastructure such as
high-tension electric lines and nuclear power plants (e.g., Ramsdell et al.
2007)." [@edwards2013tornado]

Sometimes used in conjunction with other datasets: 

> "The contiguous U.S. tornado fatality dataset utilized in this study was 
transcribed and compiled from two primary sources: (1) a long-term study of 
U.S. tornados by Grazulis (1993, 1997, hereafter Grazulis dataset) and 
(2) the National Climatic Data Center's Storm Data (NCDC 1959--2005) and 
'Storm Events' datavase. The Grazulis dataset included 'significant' tornado
events, including all events that are known to have produced a fatality, 
from 1680 to 1995. Storm Data reports from 1959 to 2005 were utilized to 
supplement the existing record of killer tornado events documented by 
Frazulis." [in a study of tornado fatalities] [@Ashley2007]

History: 

> "During the early 1950s, the US Weather Bureau began a concerted effort to
count all US tornadoes. In 1950, a list of tornadoes was provided in the
*Climatological Data National Summary*, but it was not until 1953, the first
full year of the issuance of Weather Bureau tornado watches, that the agency
began to formally count all tornadoes. The *Climaticalogical Data National
Summary* document evolved into *Storm Data* by 1959, which, in addition to
tornado data, included information on other storm perils, such as severe hail,
high winds, and floods (Grazulis 1993). Over the years, the tornado dataset has
been formatted and adjusted by the National Severe Storms Forecast Center and
Storm Prediction Center (SPC), and currently the National Tornado Database is
administered by the NWS Headquarters, SPC, and NCDC (McCarthy 2003)."
[@Ashley2007]

\begin{shaded}
\textbf{R3 Comment 6:}
Table 1: I suggest providing the rationale for picking the thresholds for
classifying continuous exposures into binary ones within the table. 
\end{shaded}

**Response:** 

Wind: gale force?

Precipitation: 

Distance: 

\begin{shaded}
\textbf{R3 Comment 7:}
Figure 3: The x-axis refers to one of the two wind data sources as "Extended
Best Tracks." Is this the same thing as the wind radii dataset described in the
text? Is so, I suggest clarifying this in the figure label.
\end{shaded}

**Response:** 

We have revised the x-axis on the figure to clarify that the comparison is based
on the wind radii dataset described in the text, as requested. The original and
revised versions of this paper are reproduced in this response document as
Figure \@ref(fig:fig3).

[Also revise figure legend?]

```{r fig3, fig.cap="Reproduction of Figure 3 from the original manuscript (left) and revised version in the resubmitted manuscript (right). In the revised version, the x-axis has been labelled to clarify that this axis is showing results based on the wind radii dataset described in the text, in response to Reviewer 3's Comment 7. The revised version also uses a more focused range for the x axis, as requested in EHP's Request 1. Figure caption in the revised manuscript: \\textit{Figure caption.}", fig.show = "hold", out.width="50%"}
include_graphics("../figures/windcomparison.pdf")
include_graphics("figures/windcomparison.pdf")
```

# Requests from EHP: {-#requests-from-ehp}

\begin{shaded}
\textbf{EHP Request 1:}
Figure 3: Please truncate x-axis scale as you do for Figure S7. Since smallest
value is $\sim75\%$, this would make the data in the relevant range much easier to
appreciate.
\end{shaded}

**Response:** 

[Typo here? I don't think there's a Figure S7.]

We have revised this figure to show an x-axis truncated at the minimum observed
value ($\sim75\%$), as requested. The original and revised versions of this
paper are reproduced in this response document as Figure \@ref(fig:fig3).

\begin{shaded}
\textbf{EHP Request 2:}
Main text figures (general)
To ensure that figures are accessible to readers with impaired color vision, do not use color as the sole means of conveying information in a figure unless absolutely necessary. Use different symbols, shading/textures, and line patterns instead of (or in addition to) color to distinguish among different data points. Use contrasting colors that can be easily distinguished from each other when the figure is printed in black and white. For details, see: \url{https://ehp.niehs.nih.gov/authors/figures}.
\end{shaded}

**Response:** 

In all these figures, we have used colormaps that are both accessible to readers
with several forms of color vision deficiency, including the most common type
(deuteranomaly, a type of red-green color vision deficiency), and can be easily
distinguished when the figure is printed in black and white [@viridis;
@van2015mpl].

For these figures, we selected colormaps that were created to meet both these
criteria. These colormaps are all multi-hue sequential maps that avoid red-green
contrasts, while maximizing dynamic range in comparison to something
single-hued, like grayscale [@nunez2018optimizing; @viridis]. They are all
perceptually uniform across the scale for those with normal color vision
[@liu2018somewhere] and are close to perceptually uniform for those with common
forms of color deficiency [@nunez2018optimizing]. They reproduce their original
sequential gradient when printed in grayscale and so are perceptable when
printed on a black-and-white printer [@van2015mpl; @nunez2018optimizing].
Previous research has found that colormaps in this family allow viewers to more
quickly and accurately judge relative distances in scientific figures
[@liu2018somewhere]. The family of colormaps we used in the figures is currently
considered the gold standard for scientific figures [@nunez2018optimizing].

For example, in Figures \@ref(fig:fig5check1) and \@ref(fig:fig5check2) (left)
of this response document, we have reproduced the current version of Figure 5 as
it would appear to someone with three common types of color vision deficiencies:
deuteranomaly (defective green cone cells, the most common type), as well as
protanopia (defective red cone cells) and tritanopia (defective blue cone
cells). We have also shown how the Figure would appear in grayscale in
\@ref(fig:fig5check2) (right). We have included similar versions of other
figures from the manuscript in response to later requests from EHP in this
response.

```{r fig5check1, fig.cap="Reproduction of revised version of Figure 5 to check accessibility to readers with two types of color vision deficiency, deuteranopia (left) and protanopia (right).", out.width="90%", fig.align = "center"}
include_graphics("figures/averageexposureonly_check1.pdf")
```

```{r fig5check2, fig.cap="Reproduction of revised version of Figure 5 to check accessibility to readers with a third type of color vision deficiency, tritanopia (left) and for printing the figure in grayscale (right).", out.width="90%", fig.align = "center"}
include_graphics("figures/averageexposureonly_check2.pdf")
```


\begin{shaded}
\textbf{EHP Request 3:}
Figure 3: Please check the contrast between the colors used to indicate numbers
of counties. If you can see the gradient when printed in black and white it
should be ok, but some of the differences are very subtle. Truncating the x-axis
might help with this (if possible.)
\end{shaded}

**Response:** 

As we note in our response to EHP Request 2, we used colormaps for all
figures that are designed to be perceptible both for those with common types of
color vision deficiency and when printed in grayscale. We have increased the
size of the circles in Figure 3 of the revised manuscript (reproduced in Figure
\@ref(fig:fig3) of this response) so that the colors are clearer, as well as
truncated the x-axis as requested in EHP Request 1. Also, we show in Figures
\@ref(fig:fig3check1) and \@ref(fig:fig3check2) of this response how the revised
Figure 3 would look with three common types of color vision deficiency as well
as when printed in black and white. The gradient is clear when this figure is
printed in black and white.

```{r fig3check1, fig.cap="Reproduction of revised version of Figure 3 to check accessibility to readers with two types of color vision deficiency, deuteranopia (left) and protanopia (right).", out.width="100%"}
include_graphics("figures/windcomparison_check1.pdf")
```

```{r fig3check2, fig.cap="Reproduction of revised version of Figure 3 to check accessibility to readers with a third type of color vision deficiency, tritanopia (left) and for printing the figure in grayscale (right).", out.width="100%"}
include_graphics("figures/windcomparison_check2.pdf")
```

\begin{shaded}
\textbf{EHP Request 4:}
Figure 4: Even with nominally normal color vision and a large high-resolution
monitor, it is difficult for me to make out the color differences in the
symbols---almost all appear black or very dark blue, a dozen or so look yellow,
and a handful look dark grey. Is there any way to increase the contrast in these
colors? Would you consider binning into categories instead of using a
continuous color gradient?
\end{shaded}

**Response:** 

Thank you for these suggestions. 

For the original figure, most of the events resulted in 0% of flood gages
exceeding the flood threshold, especially for events that were not recorded as
floods based on NOAA Storm Events. Therefore, most of the points in the original
were indeed dark blue, representing 0%, but we can see that readers might have
questioned if this was the case or if the scale made it harder to see subtler
differences.

We have reproduced both the original and revised versions of Figure 4 as Figure
\@ref(fig:fig4) of this response. We have made several changes to make this
figure easier for readers to see and interpret. These changes include:

- Binning the values shown by the points fill, so that readers only need to 
be able to distinguish among four colors, rather than across a larger scale.
- Increasing the size of the points, so the fill in each point is easier to 
see. 
- Using a different algorithm to "jitter" the points, so there are no points that
overlap each other. 

\begin{shaded}
\textbf{EHP Request 5:}
Figures 5--6: Please check to see if the colors used can be distinguished if
printed in black and white, and if not, use a color-blind friendly palette if
possible. If this is not feasible, we can request and exemption from
accessibility requirements, but we try to do this only when alternatives  would
degrade the information content of  the figure.
\end{shaded}

**Response:** 

As we note in our response to EHP Request 2, we used colormaps for all figures
that are designed to be perceptible both for those with common types of color
vision deficiency and when printed in grayscale Figures \@ref(fig:fig5check1)
and \@ref(fig:fig5check1) show what Figure 5 would look like under three common
types of color vision deficiency and when printed in black and white. Figures
\@ref(fig:fig6check1) and \@ref(fig:fig6check2) show the same thing for Figure
6. Therefore, these figures should not require any exemption from accessibility
requirements, as they should satisfy these requirements.

```{r fig6check1, fig.cap="Reproduction of revised version of Figure 6 to check accessibility to readers with two types of color vision deficiency, deuteranopia (left) and protanopia (right).", fig.show = "hold", out.width="50%"}
include_graphics("figures/jaccard_heatmap_check1.pdf")

include_graphics("figures/jaccard_heatmap_check2.pdf")
```

```{r fig6check2, fig.cap="Reproduction of revised version of Figure 6 to check accessibility to readers with a third type of color vision deficiency, tritanopia (left) and for printing the figure in grayscale (right).", fig.show = "hold", out.width="50%"}
include_graphics("figures/jaccard_heatmap_check3.pdf")
include_graphics("figures/jaccard_heatmap_check4.pdf")
```

\begin{shaded}
\textbf{R2 Comment 6:}
Supplemental Material: Please provide your supplemental material file in Word
(.docx) format. For additional information, see:
\url{https://ehp.niehs.nih.gov/authors/supplemental-material}. \end{shaded}

**Response:** 

We have provided the Supplemental Material in the Word file format in our
revised submission.

# References for the response {-#references-for-the-response}
