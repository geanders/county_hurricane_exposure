---
title: "Response to reviewers' comments for *\"Assessing United States county-level exposure for research on tropical cyclones and human health\"*"
output: bookdown::pdf_document2
toc: false
bibliography: writing/hurr_exposure.bib
header-includes:
- \usepackage{xcolor}
- \usepackage{framed}
- \usepackage{bm}
- \usepackage{subcaption}
- \usepackage{gensymb}
- \renewcommand\familydefault{\sfdefault}
- \usepackage{sansmath}
- \usepackage{bm}
- \usepackage{soul}
- \sansmath
- \usepackage{booktabs}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{pdflscape}
- \usepackage{float}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{fullpage}
- \usepackage{pdflscape}
- \usepackage{tcolorbox}
- \tcbuselibrary{skins,breakable}
- \usepackage{amsmath}
- \usepackage{xtab}
- \usepackage{rotating}
- \allowdisplaybreaks
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r}
library(knitr)
```


# Overall comments {-#overall-comments}

\colorlet{shadecolor}{blue!8}
\begin{shaded}
\textbf{Associate Editor's Overview:}
Developing a consistent and comparable metric for exposure to tropical cyclones
would be a valuable addition to the literature. All reviewers had questions
about the exposure metric, including the challenges of using county-level data
where not everyone in a county would have been exposed and the difficulties of
going from country-level to individual -level risks. Further the comparison of
different storm hazards could be clarified. The reviewers identified several
issues where further explanation would increase the accessibility of the
manuscript.
\end{shaded}

Thank you for the opportunity to revise and resubmit this manuscript. We
appreciate the helpful suggestions from the reviewers for clarifying and
deepening the discussion in the paper.

Broadly, we have: 

1. Added discussion on the question of county-level versus individual-level
data. 
2. Added explanations for how our comparisons among different storm hazards
can help epidemiologists in designing studies and statistical analysis.
3. Added a small analysis of the correlation in rainfall metrics specifically
in cases of high rainfall ($\ge75$ mm of cumulative rainfall in the county
associated with the storm), to deepen the discussion of potential disagreement
in continuous measures of rainfall during extreme conditions. 
4. Changed labeling, axis range, and other presentation details for some
figures, as well as confirmed that the color scales will be accessible.
5. Corrected typos and improved wording throughout based on suggestions of the
reviewers.

# Reviewer 1: {-#reviewer-1:}

## Overall comments {-#overall-comments}
\colorlet{shadecolor}{blue!8}
\begin{shaded}
\textbf{Reviewer 1 Overview:}
I applaud the authors for this work, and their efforts to develop standardized
ways to measure exposure to tropical cyclones. As a disaster scientist, I very
much appreciate efforts that promote our collective ability to learn from and
across disasters to build cumulative science. 
\end{shaded}

**Response:** 

\begin{shaded}
\textbf{Reviewer 1 (R1) Comment 1:}
I very much appreciate the rationale for authors' decision to focus at the
county level, especially given the available health-related data. But, since
tropical cyclones don't necessarily have consistent impacts across an entire
county, I think the limitations of this decision are worthy of further
discussion in the discussion section.
\end{shaded}

**Response:** 

- Ecological fallacy vs individual fallacy, especially in the disaster context
- Spatial misalignment / ecological effects of aggregating data at the county
(or other geopolitical) level. 
- Could be particularly problematic in some high-risk areas, because of the 
"long and narrow" characteristics of island counties. Dare County, Key West. 

We think this is a very interesting question for disaster epidemiology, as
while there remains potential for ecological bias, the potential pathways for
health effects may also pass through damage in the individual's community beyond
their residence. For example, damage to major roads in the community might make
it harder for many residents to reach medical care in the aftermath of the
storm, even if their home did not experience extensive destruction. Similarly,
since power is provided over a network, conditions in an individual's community
can be important in determining risk of long-term outages (does Seth have
something on this?). As another example, if hospitals in the community are 
over capacity or have to evacuate, this could increase health risk for people in 
a fairly large "catchment" area for that hospital. 

Therefore, while we agree that individual-level data would in many cases be 
helpful for tropical cyclone epidemiology, the ideal might be to design studies 
that integrate both community-level and individual-level metrics of exposure. 
This could help in determining if there are risks introduced to individuals based
on storm-related hazards in their broader community, after controlling for the 
hazards experienced directly at their homes.

There is already some discussion on this topic in the Discussion [exposure 
measurement error / misclassification].

There are two interrelated mechanisms at play regarding this question. The
first is the potential for ecological bias. This bias results from inferring
individual-level associations from data that is available at an aggregated level. 
In the case of epidemiological research, these data include health outcomes, 
exposure, and covariates if the model is adjusting for confounding from them.
For example, in tropical cyclone epidemiology, an ecological study might 
compare county-wide rates of COPD hospitalizations to county-wide measures
of tropical cyclone exposure while controlling for county-level smoking 
rates and age distribution. The model in this case is fit at the county level, 
and so the relevant inference is at that level. If this county-level estimate
is inferred to represent the individual-level association between tropical 
cyclone exposure and risk of COPD hospitalization, controlled for smoking and
age, then the possibility of ecological bias arises. Given that this bias
results from inferring from a model with data at one level of aggregation
to another, this bias is also called cross-level bias. 

There are some subtleties that arise regarding this question for disaster
epidemiology. First, it has been argued that, for some ambient exposures
like weather and air pollution, contextual effects (that is, at the community
level) are helpful to estimate in their own right, not just as a potential 
surrogate for individual-level associations. This is because regulations
(in the case of pollutants), interventions, and planning often happen at
this level. 

Second, for a disaster, the relevant exposure might be not just at the
individual level (e.g., winds or flooding at the individual's residence), but
also throughout a broader area surrounding the individual. If storm damage
closes roads in a county, for example, or damages the power grid, then these
could create pathways for health risks for individuals throughout the county,
whether damage was high at their residence or not. The causal pathways for
tropical cyclones to affect human health differ from those for a dangerous
substance, like air pollutants, in which the substance itself must enter the
body to cause harm. While some health risk comes directly from the storm (e.g.,
deaths and injuries from trees falling on homes or drowning from flooding),
there are many more pathways that are indirect. These include pathways that go
through the way that the storm's damage affects community infrastructure and
access to medical care. Several papers have discussed the potential for 
"individualistic fallacy", as a counterpoint to "ecological fallacy", when 
such contextual-level exposure pathways are ignored. 

There are study designs that can be used to leverage ecological data while 
minimizing risk from ecological bias. For example, potential confounders
like age distribution and smoking rates vary much less within a county over
time than comparing between counties. The mechanism for ecological bias 
depends on the joint distribution between individual exposure, outcome, and 
covariates, if any are included in the model. Time series-style study designs, 
which compare a county to itself over time, allow for very similar covariate
distributions between exposure and non-exposure. Other studies add to this
design by stabilizing for temporal confounding through the addition of 
counties that were never exposed, allowing for a differences-in-differences
style approach to calibrate for seasonal or longer-term trends that might
otherwise create confounding. For example, many health outcomes have a strong
seasonal trend, with peak rates in the winter and lows in the summer. Since
the hurricane season stretches from summer into fall, a study design that compares
the rate of a health outcome in an exposed county to the rate two weeks before
the exposure might be biased away from the null, since baseline rates of the
health outcome will typically be moving up over most of the hurricane season.

Also, there may be confounders that are relevant at the contextual, rather than
individual level, as well as modifiers. Example: whether the county is coastal
could be a contextual-level confounder and effect modifier. This will influence
whether the county is exposed to that storm or not, since storms usually weaken
rapidly when the center is over land. In terms of counfounding pathways, coastal
communities might tend to have lower levels of air pollution, because sea
breezes clear the pollution regularly. They might also be wealthier on average,
since property on or near the beach is desirable. Finally, they might be better
prepared for or more hardened against tropical cyclones at the community-wide
level (e.g., through hardier power infrastructure, more rigorous building codes,
higher likelihood of evacuating in advance of a threatening storm) compared to
nearby inland counties. 

Other approaches have also been suggested to reduce ecological bias while 
leveraging ecological data, which might be available at a much larger scale---and
so provide more power---than is practical in collecting individual data. These
include multi-level approaches in which individual-level data from a sample
of individuals in each community is incorporated. 

The second issue is exposure measurement error/misclassification. When the 
exposure (e.g., binary exposure or continuous measure of intensity of exposure)
is only measured at the county level, all the individuals in that county are 
assigned that same exposure. However, the hazards included in this study will 
vary across each county. For some hazards, this variation will be more stark. 
For example, tornadoes can be very local, causing extreme damage to a row of 
homes and none to the homes across the street. Some types of floods can also 
be very localized, rather than creating widespread flooding throughout 
the county. In both cases, when a county-level exposure assessment is made
based on an event in the county in association with the storm, there may be
many individuals in the county who did not experience that hazard at their 
residence. The other hazards we included---storm-associated winds and rainfall---will
also have some variation across counties, but this will often not be as stark. 
The rainfields for tropical cyclones are very large, and while there are rainbands
within the storm that might have particularly high rates of precipitation, these
progess over the course of the storm, and it is unlikely that a county will have
one area that experienced very extreme precipitation while another experienced
very little. Winds might have more variation, especially in coastal counties and 
counties near the storm's central track, since winds decay quickly as you move
from the storm's center, and storms typically weaken rapidly once they make 
landfall and can no longer draw on warm ocean waters for energy. 


\begin{shaded}
\textbf{R1 Comment 2:}
Are there opportunities to expand this approach internationally? Some decisions
(e.g., county-level) data may restrict cross-country comparisons. Can the
authors discuss this? 
\end{shaded}

**Response:** 

- Differs by exposure metric. Easier for some (wind, rain) than for others (flood, 
tornado)
- For rain, we use a re-analysis product only available for the continental US (right?).
However, there are similar gridded re-analysis products available for other regions 
worldwide that could be used in a similar way.
- For tornadoes, there may be national databases in other spots similar to the tornado
database that we use, but as far as we're aware, no international one. 
- Same for floods. 
- For wind, the wind model could be generalizable with some tweaks. These include: 
  + More landmasks
  + Direction of storm movement for Northern vs Southern Hemispheres
  + Different wind averaging periods for the recorded best tracks data in different 
  storm basins.
  + Our wind model was derived with US data and so may need bias-correction or a shift
  to a West Pacific--based model

> "Tornadoes long have been recognized as a global phenomenon (e.g., Wegener 1917; 
Feuerstein et al. 2005), having been recorded in every continent except Antarctica. 
As such, numerous nationas share an interest in improving assessment of their 
damage. International research and involvement in tornado survey work and damage
and intensity scales is well underway." [@edwards2013tornado]

\begin{shaded}
\textbf{R1 Comment 3:}
In non-health fields, a county's inclusion in a FEMA major disaster declaration
or eligibility for public/individual assistance (all of which are somewhat
reflective of level of damage) is sometimes used as an "exposure" proxy. Have
you considered if/how your exposure assessments relate to inclusion in a FEMA
disaster declaration? In other words, does exposure to any of the hazards align
with the level of damage required for a county to be considered a "disaster
area" and/or worthy of federal assistance by current federal policy? Does this
matter?
\end{shaded}

**Response:** 

This is a great question, and we are aware of a number of studies on the
societal impacts of tropical cyclones that have used FEMA disaster declarations
to assess county-level exposure to tropical cyclones [refs]. 

However, evidence from prior tropical cyclone epidemiology that doing so is
problematic and should be avoided [@grabich2015measuring]. FEMA's disaster
declarations are issued to provide assistance, based on damage assessment, to
individuals or the entire public in certain locations where catastrophes
overwhelm the state or local government [@mccarthy2014fema], and any use of them
for exposure assessment is secondary. Due to the political nature of disaster
declaration process, these declarations are often subject to many political and
economic factors [@mccarthy2014fema; @logue1981research]. One epidemiological
study specifically focused on exposure assessment for tropical cyclone
epidemiology and compared use of FEMA declarations with other methods of
exposure assessment, including one based directly on the storm hazard of wind
[@grabich2015measuring]. They found that exposure assessment based on FEMA
declarations tended to overassign counties to be "exposed," resulting in false
positives [@grabich2015measuring]. A further concern is that, given the
political and economic nature of these declarations, there is likely variation
across time and geography in the likelihood of a given exposure resulting in a
disaster declaration. This is particularly worrisome for a study that seeks to
explore risk across multiple years and affected communities.

We have added some discussion of this point... 

- Future research could expand the work by [@grabich2015measuring] to determine
the extent of these issues with use of FEMA disaster declarations for
epidemiological exposure assessment. This would need to go beyond the comparison
with exposure assessment based on storm hazards, because sometimes the
characteristics of the affected community modifies the amount of disaster that
results from hazards of a certain severity. For example, a community that it
exposed often might be more "hardened" against damage from the storm (any work
from Seth on this) and so might experience less infrastructure damage from a
tropical cyclone with certain characteristics compared to a community that is
rarely exposed to tropical cyclones. One interesting direction would be to
investigate if there is evidence of differences in probablity of disaster
declarations at geopolitical boundaries, like when comparing counties on either
side of a state border.

There are some cases where damage reports are directly used to infer the intensity 
of the weather event. For example, damage surveying is used following a tornado 
to assign the tornado's class on the [enhanced] Fujita scale. However, this is not the
intent of FEMA damage reports, which instead are used to determine post-disaster
aid [?] and are influenced by a number of political factors. 

> "Because of the historic lack of direct measurements and remotely sensed tornado 
wind speeds at or near group level, damage surveying has remained the most common 
form for indicating tornado strength. ... The occurrence of a direct tornado strict 
upon a fixed, sufficiently sturdy, and well-calibrated wind measuring station is quite
rare. Only 31 direct in situ tornado observations are evident between 1894 and 2011."
[@edwards2013tornado]

\begin{shaded}
\textbf{R1 Comment 4:}
Line 95---wondering if there is a better word for "hits" here. Maybe "exposed?"

\textit{Lines 92--95 in the original manuscript:}

\begin{quotation}
\noindent
\textit{"In many cases, these studies analyze multi-year, multi-community data,
allowing them to estimate average associations over many disasters and to
explore how a disaster’s characteristics, or the characteristics of the
community it hits, modify associated health risks (e.g., Anderson and Bell 2010;
Son et al. 2012; Liu et al. 2017)."}
\end{quotation}
\end{shaded}

**Response:** 

Thank you for this suggestion. We have changed the wording in this sentence: 

> **Text in revised manuscript (relevant change in bold):**
"In many cases, these studies analyze multi-year, multi-community data, allowing
them to estimate average associations over many disasters and to explore how a
disaster’s characteristics, or the characteristics ofthe **affected
communities**, modify associated health risks (e.g., Anderson and Bell 2010; Son
et al. 2012; Liu et al. 2017)."

We also used the word "Hits per county per decade" in the legend for Figure 5 in
the main text and Figure S3 of the Supplemental Material. We have revised the
wording in these figures to "Exposures per county per decade".

```{r fig5, fig.cap="Reproduction of Figure 5 from the original manuscript (left) and revised version in the resubmitted manuscript (right). In the revised version, the figure legend was changed from '\\textbf{Hits} per county per decade' to '\\textbf{Exposures} per county per decade' (bold used to highlight change). Figure caption in the revised manuscript: \\textit{Figure caption.}", fig.show = "hold", out.width="40%", fig.align = "center"}
include_graphics("../figures/averageexposureonly.pdf")
include_graphics("figures/averageexposureonly.pdf")
```

\begin{shaded}
\textbf{R1 Comment 5:}
Lines 137--139, suggest breaking into two sentences

\textit{Lines 137--141 from original manuscript:}

\begin{quotation}
\noindent
\textit{"While other approaches have been developed to incorporate storm
hazards, particularly wind, into exposure assessment (e.g., Grabich et al.
2015a; Zandbergen 2009; Czajkowski et al. 2011), there is not yet a standard
approach, and when different studies use different datasets or storm hazards
when assessing storm exposure, it becomes difficult to compare and aggregate
findings."}
\end{quotation}
\end{shaded}

**Response:** 

This is a great suggestion. We have split the cited sentence into two sentences:

> **Text in revised manuscript:**
"While other approaches have been developed to incorporate storm
hazards, particularly wind, into exposure assessment (e.g., Grabich et al.
2015a; Zandbergen 2009; Czajkowski et al. 2011), there is not yet a standard
approach. When different studies use different datasets or storm hazards
when assessing storm exposure, it becomes difficult to compare and aggregate
findings."

\begin{shaded}
\textbf{R1 Comment 6:}
This is not a comment on the paper, but the authors may also want to consider
publishing their work in DesignSafe, which is "the web-based research platform
of the NHERI  [NSF-Funded Natural Hazards Engineering Research Infrastructure]
Network that provides the computational tools needed to manage, analyze, and
understand critical data for natural hazards research." It is the data
repository widely used by interdisciplinary hazards and disaster researchers.
\end{shaded}

**Response:** 

Great idea. We are investigating sharing this work in this repository. 

# Reviewer 2: {-#reviewer-2}

\begin{shaded}
\textbf{Reviewer 2 overview:}
Exposure assessment is essential to study health impacts from disasters, but it
is also a great source of biases due to a lack of a good and fine measure of
exposures during the chaos. Often, epidemiologists use existing data at large
population level such as county level weather data which provide no individual
level exposures but give average exposure at the population level. So it is very
challenging to draw a good causal inference to health outcomes that measured at
the individual level. This manuscript is a well-written report with generously
shared data and programs on US tropical cyclones. This will contribute
significantly to disaster epidemiology which is still a new area and suffering
from good exposure ascertainment.

While I enjoyed reading the manuscript very much, I have one question I could
not figure out clearly.

One objective is to investigate patterns and agreement between different
exposure measures. I do not clearly understand the value of studying agreement
between exposures, while each exposure should be measured separately, so both
individual and overall effects can be assessed.  I do understand using "distance
from the storm" as exposure is only proxy measure and highly sensitive to
misclassification, but because direct storm hazards such as rainfall, flood,
storm surge, and tornado are publicly accessible as authors indicated, authors
could just simply guide readers to use the best exposure data rather than
conducting a quite intense analysis. This may be due to my limited knowledge, so
it would be appreciated if the authors provide explicit explanations on the
purpose and benefit of the analysis.

\end{shaded}

Thank you for this suggestion, and we can see that we could have more clearly 
articulated in the original manuscript how our assessment of patterns in and 
among exposures to specific hazards can help epidemiologists to design their
studies and the statistical methods to analyze the resulting data. 

1. If exposure to the different hazards strongly agrees (i.e., when a county is 
exposed to one hazard, they are typically also exposed to a second), this would
have several implications for epidemiological research, especially for multi-year
studies: 
  + From a statistical modeling point of view, if you tried to include each 
  hazard as a separate independent variable, you would run into problems with 
  collinearity if fitting the study data with a generalized linear model or other
  regression model. One implication of this is that the confidence intervals on 
  effect estimates for the two variables would be very inflated, because the model
  would struggle to figure out which of the two variables the weight should be placed
  on, and so this uncertainty would be reflected in the size of the associated 
  confidence intervals.
  + If you see an effect, it would be very hard to try to determine if the causal 
  pathway goes through the first hazard or the second. To mitigate effects, it is 
  important to understand the pathway through which they happen, and it might be easier
  to get clues towards pathways if the hazards are better separated. (Analogy: if you
  were able to conduct a controlled experiment to look at the effects of each hazard, 
  jointly and in combination, you would design separation in the assignment of these
  treatments, so you could distinguish. We can't do that because we are limited to 
  an observational analysis, but the area of causal inference is doing a lot to 
  explore how we can design observational studies and analyze data to come closer to 
  what we might be able to see with a randomized control study, and which of those methods
  we might be able to use for tropical cyclone epidemiology will depend on the interplay of
  these patterns of exposures.)
2. These results will not be surprising to an atmospheric scientist / disaster researcher,
but there are environmental epidemiologists who have done research on other exposures and
are now starting to study tropical cyclones (session at ISEE, for example). It is useful 
for epidemiologists entering into tropical cyclone research to understand these facets of
tropical cyclone exposure, including the distinction between the very coastal wind exposures
and other hazards that tend to reach further inland. 
3. There are epidemiological studies that have used only one hazard for exposure assessment.
This has most often been the case for wind. If this exposure assessment is meant to 
capture "tropical cyclone exposure" in general, with all the hazards that are related to 
tropical cyclones, then there is the chance for exposure misclassification if this single
hazard is used. 
4. In the past, it was a very complex issue to try to pull together data on 
all these hazards. We agree that now that we have provided a dataset with all of them, 
epidemiologists should be thinking about multi-hazard analyses. However, there still 
will be some barriers to that. [Recent work on multi-pollutant exposures and the complexities
associated with that.] If one of the hazards dominates in explaining associated health 
risk, then in some cases it might be reasonable to focus on that hazard, but in that 
case it is critical, based on our results, to remember that the exposure assessment is
not capturing all hazards of the storms.

We have moved other suggestions that you sent in "Track Changes" of the Word 
document for the original manuscript and address each in detail below.

**Response:** 

\begin{shaded}
\textbf{Reviewer 2 (R2) Comment 1:}
Line 164: Isn’t it obvious to use better exposure measures than proxies? Wind,
rainfall, tornado, and flood are direct products of storms while distance is
only proxy of those exposures. Rather than calculating agreement among the
exposures, it would be important to note that these are independent hazards that
can come together or come with different intensity and at different time
windows.

\textit{Lines 164--166 from original manuscript:}

\begin{quotation}
\noindent
\textit{"They found important differences, concluding that a study may be prone
to bias from exposure misclassification if distance to the storm track is used
as a proxy for exposure (Grabich et al. 2015a)."}
\end{quotation}
\end{shaded}

**Response:** 

\begin{shaded}
\textbf{R2 Comment 2:}
Line 354: I am not sure why different exposures should be compared and measured
the agreement. I would just treat each exposure as single independent exposure
and give a summary score by summing all the exposure with some weighting for
multiple exposures.

I may not understand the importance of this approach. If so, adding the
explanation would help readers not to questioning.

\textit{Line 354 from original manuscript:}

\begin{quotation}
\noindent
\textit{"Finally, we investigated how well exposure assessment agreed across
these metrics."}
\end{quotation}
\end{shaded}

**Response:** 

As we note in our general response to your comments, we agree in general with your
instinct here. However, there are some subtle points to note. 

First, we understand the potential appeal of creating a single exposure 
summary score based on a summation of exposures. This simplifies some of the 
statistical modeling, for example, and also provides a single exposure estimate to 
provide as the key study conclusion. However, in many areas of tropical cyclone epidemiology, 
it is unlikely that exposure to each type of hazard should be given equal weight. For 
example, an analysis of respiratory health in the months after the storm might hypothesize
a strong connection with flooding, and smaller connections with rainfall and winds (through
the pathway of property damage). Use of a pre-defined summation of exposure to each hazard
would mask some of the potential association. 

While a summary statistic could be defined that adds a weight to each exposure, it would
often be unclear *a priori* what weight each hazard exposure should be given. A better 
method might be to use a regression framework, where each hazard exposure is included as
a separate explanatory variable, and the model uses the observed data to determine the 
appropriate weight for each hazard in terms of modifying risk to the outcome of interest. 
To explore the influence of multiple concurrent hazards, interaction terms could be added.

However, if our analysis had found that hazard exposures follow very similar patterns, in 
terms of the counties exposed during a storm, then this strong agreement would result in 
a number of problems in fitting and interpreting these types of models. First, strong
agreement in two or more of the explanatory variables in a regression model leads to 
collinearity, which among other implications often leads to a large inflation of confidence
intervals for the effect estimates of the correlated explanatory variables. Further, if 
the hazard exposures were in strong agreement, then it would be difficult or impossible to
disentagle the effects of the separate hazards, as a strong effect for one would be 
impossible to interpret with confidence, since the strong agreement in the data (and resulting
low co-variability in the variables in the data) could cause the model to mistakenly 
attribute the effect of one hazard to the other. Further, it may become impossible in this
case to estimate synergistic effects between the two, as an indicator of an interaction
between the two exposures would be almost collinear with the two main effects.

In our analysis, we find that this is usually not the case for the four tropical cyclone 
hazards that we consider. Instead, we find that for most storms, the hazards are fairly 
well-separated in terms of the counties they effect. There is a particularly strong pattern
where inland counties can be exposed to extreme rain and flooding, but not wind. This 
separation opens the door for some interesting study designs and statistical modeling. 
For example, these patterns suggest that a study could investigate whether storm-associated
rains alone create a health risk, as there are many exposures with only rain in inland 
counties, and so health associations could be explored here and contrasted with coastal 
areas that experienced both wind and extreme rain.


\begin{shaded}
\textbf{R2 Comment 3:}
Line 394: It looks like the correlation coefficients can be very low if measured
from 75mm or somewhere around.  This seems to be a significant issue for
analyzing storms with heavier rainfall using NLDAS-2 data.

\textit{Line 392--394 from original manuscript:}

\begin{quotation}
\noindent
\textit{"Within these counties, storm-related rainfall measurements were
well-correlated between the two data sources, with rank correlations (bottom
right of each graph in Figure 2) between 0.87 and 0.98. "}
\end{quotation}
\end{shaded}

**Response:** 

This is a great idea. In the original manuscript, we describe this lower correlation
at higher precipitation values through the use of examples from specific storms, and
discuss the potential reasons for it, but measuring the correlation specifically within
these higher-precipitation events would add more quantitative evidence to this discussion.

Here is the text where we discuss this point in the original manuscript:

> **Text in original manuscript:**
"There was some evidence that our primary rainfall metric may tend to
underestimate rainfall totals in storms with extremely high rainfall, based on
a few heavy-rainfall storms in Harris County, TX, Mobile County, AL, Charleston
County, SC, and Wake County, NC (Figure 2)."

> **Text in original manuscript:**
"The rainfall data are generally well-correlated with ground-based observations,
but may sometimes underestimate very high rainfall values (Figure 2). When
rainfall data is used to create binary exposure classifications, this
disagreement is unlikely to influence results, as both data sources agree in
identifying these as storms with high rainfall, but would be important to
consider for cases that include rainfall as a continuous measurement."

[Why we think this is happening... Re-analysis product uses a model to integrate
data from multiple sources and so might be likely to pull values back toward 
the "typical", and so oversmooth very extreme values.]

Here is the text and analysis we have added on this point in the revised manuscript:

\begin{shaded}
\textbf{R2 Comment 4:}
Figure 4: I would add Y-axis label “NOAA classification."
\end{shaded}

**Response:** 

\begin{shaded}
\textbf{R2 Comment 5:}
Table 2: This is another confusing table. Not sure what compared here. The
second column is a mean \# of exposed counties over years and the third column
seems like showing single storm with the max \# of exposed counties. Not sure
what info I should digest from this table.
\end{shaded}

> **Text from Results of original manuscript:**
"Across the four storm hazards considered, there was wide variation in the
average number of county exposures per year (Table 2). For tropical cyclone
tornadoes, there were on average about 40 county exposures per year within our
study. County exposures were more frequent for tropical cyclone wind exposures
(>160/year on average), even more frequent for tropical cyclone flood exposures
(>190/year on average), and most frequent for tropical cyclone rain exposure
(>290/year on average). For every hazard except tornadoes, we identified at
least one tropical cyclone that exposed over 250 counties (Table 2). However,
the largest-extent tropical cyclone varied across hazards: Frances in 2004
exposed the most counties based on rain, Michael in 2018 based on wind, and Ivan
in 2004 based on flooding and tornadoes (Table 2)."

**Response:** 

\begin{shaded}
\textbf{R2 Comment 6:}
Subsection of Results on \textit{Agreement across exposure metrics}: 
As stated below, storms bring different hazards to different locations with
different time. What would be new learning by comparing these different pairs of
exposure metrics. Somewhat apple and orange comparison. Maybe providing more
explanation can help what the important learning from this is. I may not catch
it. Similar comment was added earlier.
\end{shaded}

**Response:** 

\begin{shaded}
\textbf{R2 Comment 7:}
Lines 494--495: Why this agreement is important? Same questions added above
already, but still wonder what I missed. It seems like the authors try to
develop an exposure matrix that is common in occupational epidemiology, but it
is only valid method when the exposures are similar and lead to the same health
outcomes.  Rain, wind, flood, and tornado should be treated separately, maybe
except rain and flood. It is possible to be an extreme storm with only severe
wind without major impacts from other exposures. Tornado is a good example.

\textit{Line 491--495 from original manuscript:}

\begin{quotation}
\noindent
\textit{"For another set of tropical cyclones (e.g., Ernesto in 2006, and Bertha
in 1996, Isabel in 2003), there was moderate to good agreement for pairwise
combinations of distance, rain, and wind, but poor agreement for other
combinations of metrics, while for another set of storms (e.g., Matthew in 2004
and Katrina in 2005), there was moderate to good agreement between distance and
rain."}
\end{quotation}
\end{shaded}

**Response:** 

[Check: *exposure matrix* in occupational epidemiology...]

[New advances in multi-pollutant analysis.]

[Some of the hazards could create similar risks, if they converge on a common
pathway of risk. For example, if pathway is through stress from property damage,
individually and in the county, then several hazards could indeed lead to the
same health outcomes (e.g., PTSD, other psychological markers, risk of acute
cardiovascular outcomes, etc.). One example is extreme level of destruction both
from wind (Hurricane Andrew, Hurricane Hugo), from river flooding associated
with among of precipitation (Hurricane Floyd, Hurricane Florence), and from
flash flooding associated with the rate of precipitation (Virginia storms).]

[A better future direction might be through regression models with multiple
explanatory pathways. This allows the model to fit different weights to each. Other
models can also be explored, like regression trees, which might have an easier time
capturing non-linearity (if exposure is included as a continuous value, as with 
wind and rain) and interactions when there are co-exposures to two or more hazards.
Both of these are able (and will) either exclude or give a very low weight to an 
explanatory variable that does not help much in explaining variation in the health 
outcome.]

\begin{shaded}
\textbf{R2 Comment 8:}
Line 515: It would be informative to provide correlation coefficient for only
above 75 mm measures.

\textit{Line 514--515 from original manuscript:}

\begin{quotation}
\noindent
\textit{"The rainfall data are generally well-correlated with ground-based
observations, but may sometimes underestimate very high rainfall values (Figure
2)."}
\end{quotation}
\end{shaded}

**Response:** 

\begin{shaded}
\textbf{R2 Comment 9:}
Line 602: This is not a new finding, but how much misclassified would be a good
question to answer.

\textit{Line 600--602 from original manuscript:}

\begin{quotation}
\noindent
\textit{"Based on our results, the use of a distance-based metric to assess
exposure to any of these hazards, or the use of measurements from one hazard as
a proxy for exposure to any of the other hazards considered, would often
introduce exposure misclassification."}
\end{quotation}
\end{shaded}

**Response:** 

\begin{shaded}
\textbf{R2 Comment 10:}
Lines 626--627: It would still be beneficial to treat each exposure as a single
variable first and then consider overall impact. Only if each exposure data are
available.

\textit{Line 626--628 from original manuscript:}

\begin{quotation}
\noindent
\textit{"For these storms, it may be possible to assess exposure to multiple
hazards of the storm using a single metric, perhaps even a proxy like the
distance between the county and the storm’s track."}
\end{quotation}
\end{shaded}

**Response:** 

# Reviewer 3: {-#reviewer-3}

\begin{shaded}
\textbf{Reviewer 3 overview:}
This paper describes the development of a dataset and R package that can be used
to assess exposure to tropical cyclone-related hazards (e.g., wind,
precipitation, flooding) at the county level in the eastern United States, as
well as a descriptive analysis of county-level exposure to these hazards. This R
package is novel and I believe of high interest to researchers interested in the
health effects of tropical cyclones.  I have a few minor suggestions to further
improve the clarity of the manuscript.
\end{shaded}

**Response:** 

\begin{shaded}
\textbf{Reviewer 3 (R3) Comment 1:}
Starting on line 128, the authors write "Extreme winds are more common to the
track's right, where counterclockwise cyclonic winds move in concert with the
tropical cyclone's forward motion". I think this statement may be specific to
tropical cyclones in the Northern hemisphere (i.e., those relevant to exposure
in the US). Would be good to clarify this.
\end{shaded}

**Response:** 

You are right, the opposite would be true in the Southern hemisphere. This
difference is driven by the Coriolis effect on cyclonic rotation, in which the
rotation of the earth diverts winds as they move toward the low pressure center
of the cyclone. We have edited the text to specify that this statement is
specific to the Northern Hemisphere:

> **Text in revised manuscript (relevant addition in bold):**
"**In the Northern Hemisphere, cyclonic winds are counterclockwise,** so
extreme winds are more common to the track's right where cyclonic winds move in
concert with the tropical cyclone's forward motion."

\begin{shaded}
\textbf{R3 Comment 2:}
Line 186: What is meant by the phrase "synoptic times"?

\textit{Lines 185--187 from original manuscript:}

\begin{quotation}
\noindent
\textit{"We used tracking data from HURDAT2, which records the storm center’s
position at the synoptic times of 6:00 am, 12:00 pm, 6:00 pm, and 12:00 am
Coordinated Universal Time (UTC)."}
\end{quotation}
\end{shaded}

**Response:** 

"Synoptic meteorology" refers to ...
A key idea is that observations from a widespread geographical area can be
integrate to provide a picture of large-scale weather [features?], including
large areas of high or low pressure [?].

> "In meteorology, the term synoptic denotes simultaneous observations taken
globally, or at least over a large area." [@willoughby2007hurricane]

> "Nearly 20 years ago [from 1937] [Bjerknes] declared that numerous and 
important problems might be solved with the aid of observations already 
assembled in the archives of different bureaus, but that the difficulties
in making these observations serve a special purpose were unsurmountable
for the individual scholar. He added that, in particular, the synoptic 
charts representing the momentary states of the atmosphere over large
areas of the earth, in all the necessary details and exactitude, were 
excessively difficult to assemble. His proposal was that there be entered
at the central bureau of each country, on the appropriate maps, all the available
observations taken in that country and that there be employed, by the different
bureaus, maps that may be superimposed or juxtaposed." [@gregg1937international]

However, to integrate data from many sources to provide inputs for broadscale,
synoptic analysis, it is helpful to use some standards in collecting these data
at different locations. To facilitate numerical weather forecasting and other
synoptic meteorology, weather data are regularly collected at standardized
times, so that the data can be more easily integrated as an input to models.
This practice extends back over 100 years, when data were collected from many
[offices?] in the US by telegram [?] at regular times during the day and used to
create synoptic weather maps that captured major weather systems in the country.

> "In order to allow comparison of surface conditions at the same time throughout 
the world, the groups regulating the collection of hydrometeorological data have
established a standard time for taking observations. These observations will have
times observed within the 10 minutes preceding the UTC standard time. Hence 
surface observations for meteorological use have timestamps reflecting 0000, 
0300, 0600, 0900, 1200, 1500, 1800, 2100 UTC." [@usnwstime]

> "Since the end of World War II, observers have launched rawinsonde observation
worldwide at 00 and 12 UTC (coordinated universal time). High-threat situations, 
such as impending TC landfall, may dictate observations at 6-h or even 3-h intervals. 
Interpolating rawinsonde observations to the model's mesh and starting the calculation
at a synoptic time is the simplest way to prepare a model initial condition."
[@willoughby2007hurricane]

> "Because simple interpolation in space and time is a less-than-optimum way to 
use observations, nonsynoptic data require elaborate four-dimensional variational
data assimilation schemes." [@willoughby2007hurricane]

> "By 1941, charts for the 750, 500, and 250 mbar surfaces were being prepared daily
for 0400, 1200, and 2000 GMT." [@grahame2000development]

> "During the period considered here, NHC issued advisories 3 h after the standard
synoptic time (0300, 0900, 1500, and 2100 UTC)." [@torn2012uncertainty]

> "The operation data assimilation and forecast cycle interval is 6 h" [@aberson201010]

> "Dan Petersen asked whether a data deficiency really exists with all the 
observational sources in the Atlantic region, or are the data not being
properly used in the numerical models? ... Steve Lord emphasized the difficulty of the 
task because many of these observations are not obtained at the synoptic times..."
[@elsberry1992there]

> "In the modern era, forecasters rely on purely dynamical models that integrate the 
Navier-Stokes equations for atmospheric motions to represent both the storm itself and
its surroundings. Numerical models are structured on a computational grid with 
temperature, moisture, and wind tabulated in more-or-less rectangular cells." 
[@willoughby2007hurricane]

> "Predicting the weather required a widespread but highly coordinated team of 
observers and forecasters. Organization was key... They transmitted data from the 
field using forms and protocols adapted from those that Abbe had developed while 
forecasting the weather from Cincinnati, Ohio. The information arrived by telegraph
coded to maximize accuracy and minimize the word count and changes. The reports piled
up in a rush at the appointed hours." [@willis2006cleveland]

> "Three times daily the duty forecaster broadcast a synopsis of prevailing weather
conditions nationwide..." [@willis2006cleveland]

> "The requirement of synoptic data collection is easily met by the
'conventional' observing system now serving as the main source of meteorological 
data throughout the world, since it is based on human observations which could 
be scheduled at convenient synoptic times." [@morel1971initialization]

Since large-scale weather features are very larger, relevant data for a synoptic
map often comes from locations with different local times. The need for
synchronized weather data collection therefore actually played an important role
in establishing standardized time zones in the United States in [year]. Synoptic
weather times are typically set based on the Universal Time Constant, with times 
recorded in Coordinated Universal Time (i.e.,
Greenwich ...), and time stamps on weather maps and data based on this time zone
often is given a "Z" (for "Zulu", an earlier name for this timezone) after the
time.

> "Accuracy in forecasting depended on the accurate timing of observations. At
first weather observers used local time because no system of standard time
existed, either in the United States or abroad. Local time often meant railroad
time, and that could vary as much as 20 minutes from the time proper to the
local meridian. Abbe called for change, emphasizing the need for simultaneous
readings by Signal Service observers in order to construct accurate charts and
weather maps. In 1875, he recommended to the president of the American
Meteorological Society the establishment of a committee on standard time. ...
Abbe's report in 1879 recommended the system of meridians that is now in general
use ... a system of time meridians one hour apart across the country, anchored
on the Greenwich prime meridian." [@willis2006cleveland]

> "From Abbe's perspective, however, the full potential for dynamic weather
prediction would not be achieved without standard time worldwide."
[@willis2006cleveland]

> "The time in all hydrometeorological products is expressed according to 
a single standard, which is the Universal Coordinated Time (UTC) 
(formerly known as Greenwich Mean Time [GMT] or Zulu (zero) Time [Z])."
[@usnwstime]

> "The U.S. National Weather Service base all data and product times on the 
UTC standard. ... A common practice is to include a time of the observation 
or event denoting the time with a following capital letter 'Z' to indicate the 
time as UTC." [@usnwstime]

> "The extent and the hour of the observations changed over time. Originally the
observers took the readings at 0735, 1635, and 2335, Washington time, but the
last reading was soon changed to 2300 so that the information could be included
in the morning newspapers. Before the introduction of standard time and time
zones within the United States, a confusing multiplicity of local times existed.
In 1870 there were over 100 such regional times. For the purposes of the
meteorological observations, observers used Washington time until 1885.
Thereafter the observers took their readings according to eastern time, or that
at the 75th meridian west of Greenwich, England. Observers also made local-time
readings from 1876 to 1881.[30]" [@raines1996getting]

> "Once the observers had gathered the weather data, the means of reporting and
disseminating it became most important. Like the Smithsonian, the chief signal
officer made arrangements with the leading commercial telegraph companies to
carry the tri-daily reports. Civilian telegraph experts established special
circuits routed to the Signal Office. The initial arrangement with Western Union
regarding transmission was only temporary, and at the end of the trial period
the company refused to continue service. The House Appropriations Committee held
hearings over the dispute and ruled that the company had a mandate to transmit
the weather information as government business. The Signal Corps compensated the
company, however, at rates determined by the postmaster general.[34]" [@raines1996getting]

> "When making the daily telegraphic reports, the weather observers used special
codes to reduce their length to twenty words in the morning and ten in each of
the other two reports, thereby saving the government both time and money.[35]
Regular transmission of the reports began at 0735 on 1 November 1870 from
twenty-four stations stretching from Boston, Massachusetts, south to Key West,
Florida, and west to Cheyenne in the Wyoming Territory. In addition to the
station atop Mount Washington (opened in December 1870), the Signal Corps soon
reached new heights in weather reporting with the station on Pikes Peak that
began reporting in November 1873.[36]" [@raines1996getting]

> "To provide a picture of weather conditions across the country, the observers
made their reports as nearly simultaneous as possible. The weather service did
not initially make forecasts, and the enabling legislation did not specifically
call for it to do so. Eventually general forecasts, referred to as
probabilities, emanated from the Signal Office in Washington. Locally, the
observers posted bulletins and maps in the offices of boards of trade and
chambers of commerce to provide weather information to the public. Post offices
also displayed daily bulletins, and observers supplied local newspapers with
data. Some communities appointed meteorological committees to confer with the
chief signal officer and to serve as a check upon the operations of the local
weather station. On the national level, the Signal Office in Washington issued
daily weather maps compiled from the reports received from all the stations. It
also published the Daily Weather Bulletin, Weekly Weather Chronicle, and the
Monthly Weather Review. All were available for sale to the public. Myer
estimated that through these various means at least one third of American
households received the Signal Corps' weather information in some form. A
railway bulletin service, initiated in 1879, enabled stations along many major
railroads to display weather information.[37]" [@raines1996getting]

> "The Signal Corps' telegraph network soon expanded beyond the eastern
seaboard. In 1874 Congress enacted legislation directing the War Department to
build lines to connect military posts and protect frontier settlements in Texas
against Indians and Mexicans. Other acts authorized lines in Arizona and New
Mexico and, somewhat later, the Northwest. These lines were intended to serve
sparsely settled areas where commercial lines were not yet available. For the
most part, soldiers maintained and operated the lines, but the Corps employed
some civilians. As the telegraph extended its reach, the weather system also
grew, because the operators doubled as weather observers." [@raines1996getting]

> "Until 1934 the Weather Bureau offices operated 12--15 hours a day with two
basic observations taken at 8 a.m. and 8 p.m. The observations were transmitted
via telegraph. There were no satellite images and few upper air observations."
\url{https://www.weather.gov/dvn/armistice_day_blizzard}


We have added text to clarify the meaning of "synoptic times" in the text:

> **Text in revised manuscript (relevant change in bold):**
"We used tracking data from HURDAT2, which records the storm center’s position
at **four standardized times for weather data collection (synoptic times),**
6:00 am, 12:00 pm, 6:00 pm, and 12:00 am Coordinated Universal Time (UTC)."

\begin{shaded}
\textbf{R3 Comment 3:}
Several of the exposures are calculated for the population mean center of each
county. From the reference list, it looks like the authors consistently used
population centers from 2010 throughout the years included in the dataset/R
package. If so, I suggest clarifying this in the text. 
\end{shaded}

**Response:** 

This is correct---the population centers from the US 2010 Decennial Census were 
used throughout. We have added text to the manuscript to clarify this: 

> **Text in revised manuscript (relevant addition in bold):**
"At each 15- interval, we measured the distance between the storm's
center and each county's population mean center, **as of the 2010 US Decennial
Census** (US Census Bureau 2020)."

\begin{shaded}
\textbf{R3 Comment 4:}
In the methods section starting on line 276, the authors describe the flooding
and tornado data from the NOAA storm events database. I'd suggest providing some
information about where the events in this database come from (e.g., that they
are reported events) here in addition to covering it in the discussion.

\textit{Lines 276--281 from original manuscript:}

\begin{quotation}
\noindent
\textit{"To identify flood- and tornado-based tropical cyclone exposures in US
counties, we matched storm tracks with event listings from the National Oceanic
and Atmospheric Administration (NOAA)’s Storm Event Database (NOAA NCEI 2020).
While this database has recorded storm data, particularly tornadoes, since 1950,
its coverage changed substantially in 1996 to cover more types of storm events,
including flood events (NOAA NCEI 2020). We therefore only considered flood
metrics of tropical cyclone exposure for storms in 1996 and later."}
\end{quotation}
\end{shaded}

**Response:** 

\begin{shaded}
\textbf{R3 Comment 5:}
Line 294: What is meant by the phrase "traditional tornado event database"?

\textit{Lines 294--295 from original manuscript:}

\begin{quotation}
\noindent
\textit{"The tornado observations from this dataset form a traditional tornado
event database for the US, and so we did not further validate the tornado event
data."}
\end{quotation}
\end{shaded}

**Response:** 

The NOAA Storm Events database originated as a database for recording tornadoes
[? anything else] in the US in 195[x], and was originally called ... . The
database has gone through a number of expansions to cover more events, and it
now includes reports of other types of [hydrometeorological?] disaster events,
including floods, extreme heat and cold, wildfires, frost, hail, ... . However,
it has maintained its status as the database of record [?] for tornadoes in the
United States.

Examples of research papers that leverage this database as a record of tornado
events, or the version of it shared by the [Severe Storm ...] through their
website [ref], include ... .

[Is this database used to validate tornado forecasts / warnings?]

This database has evolved through several stages but has, since its earliest
iteration in the 1950s, served as the National Weather Service's [?] data of
record on tornado events. While there is also a database maintained by the 
[Severe Storm ...], the two databases have different names but almost 
identical information once data are aggregated to a daily, county-level 
measure of whether there was a tornado recorded in that county on that date. 
[Difference between the two and why there are two.]

There is no other tornado base at the same temporal and spatial scale that
we could use for validation.

This database serves as the basis for much of the large-scale (e.g., assessing
patterns over the US over long time periods) tornado-based research for the US. 
It does have some well-documented limitations. One is a notable increase over 
time in the number of tornadoes reported, particularly for the weakest, F0 [?]
tornadoes. [This stabilizes some in the age of radar?]

> "Weather events listed in the publication Storm Data are considered to be
the official database for tornadoes by the National Weather Service." 
[written by someone at the NWS Storm Prediction Center] [@mccarthy2003nws]

The US National Weather Service's Storm Prediction Center has a tornado database
called the "National Tornado Database" [@center2020storm]. This uses the NOAA
Storm Events database as its primary source [@center2020storm]. They note on their
website: 

> "The tables below provide the links to comma separated values (.csv) files for
tornadoes, hail, and damaging winds, as compiled from *NWS Storm Data*. Tornado 
reports exist back to 1950 while hail and damaging wind events date from 1955.

The NOAA Storm Events database, or the Storm Prediction Center's version of the
tornado database have been used in a number of studies, including in a number of
studies of tornado climatology [@tippett2016more; @brooks2003climatological;
@strader2015climatology].

> "The dataset we will use is the so-called smooth log of severe-weather reports
collected by the SPC and archived in the National Oceanic and Atmospheric 
Administration publication *Storm Data*." [@brooks2003climatological]

> "Data such as tornado magnitude, path length, path width, and so on are recorded
by the National Climatic Data Center (NCDC) as a public service and for use
in meteorological, climatological, and engineering studies (Edwards et al. 2013)."
[@strader2015climatology]

Sometimes used in conjunction with other NWS data products: 

> "Initially, tornado cases available in the NWS's Damage Assessment Toolkit
(NOAA, 2014) were employed, which is a GIS-based framework for collecting, storing, 
and retrieving damage survey data (Camp et al., 2014). This toolkit provides a 
variety of tornado event filtering (tornado survey point, track, footprint, and/or
swath) and download options [key mark-up language (.kml) or shapefile (.shp)], supplying
an initial sample of georeferenced damage assessments. In this study, a tornado 
footprint is defined as the maximum areal extent of tornado intensity inferred by 
the damage, wind speed measured directly by mobile Doppler radar, or assessed
theoretically as the recorded length multiplied with the maximum width as reported in 
Storm Data." [@strader2015climatology]

> "To serve the public interest and the National Climatic Data Center (NCDC) storm 
data record, the National Weather Service (NWS) documents the path length, width, 
and maximum damage rating for every tornado county segment (NOAA 2007).[Footnote
in manuscript: County segments of tornado paths are then combined at the NWS Storm
Prediction Center to yield a unified one-tornado (ONETOR) dataset of whole-tornado 
records (Schaefer and Edwards 1999).] Such data are used in meteorological and 
climatological research, as well as in determining construction standard for 
critical infrastructure such as high-tension electric lines and nuclear power plants
(e.g., Ramsdell et al. 2007)." [@edwards2013tornado]

Sometimes used in conjunction with other datasets: 

> "The contiguous U.S. tornado fatality dataset utilized in this study was 
transcribed and compiled from two primary sources: (1) a long-term study of 
U.S. tornados by Grazulis (1993, 1997, hereafter Grazulis dataset) and 
(2) the National Climatic Data Center's Storm Data (NCDC 1959--2005) and 
'Storm Events' datavase. The Grazulis dataset included 'significant' tornado
events, including all events that are known to have produced a fatality, 
from 1680 to 1995. Storm Data reports from 1959 to 2005 were utilized to 
supplement the existing record of killer tornado events documented by 
Frazulis." [in a study of tornado fatalities] [@Ashley2007]

History: 

> "During the early 1950s, the US Weather Bureau began a concerted effort to 
count all US tornadoes. In 1950, a list of tornadoes was provided in the 
*Climatological Data National Summary*, but it was not until 1953, the first 
full year of the issuance of Weather Bureau tornado watches, that the agency 
began to formally count all tornadoes. The *Climaticalogical Data National Summary*
document evolved into *Storm Data* by 1959, which, in addition to tornado 
data, included information on other storm perils, such as severe hail, high 
winds, and floods (Grazulis 1993). Over the years, the tornado dataset 
has been formatted and adjusted by the National Severe Storms Forecast 
Center and Storm Prediction Center (SPC), and currently the National Tornado 
Database is administered by the NWS Headquarters, SPC, and NCDC 
(McCarthy 2003)." [@Ashley2007]

\begin{shaded}
\textbf{R3 Comment 6:}
Table 1: I suggest providing the rationale for picking the thresholds for
classifying continuous exposures into binary ones within the table. 
\end{shaded}

**Response:** 

Wind: gale force?

Precipitation: 

Distance: 

\begin{shaded}
\textbf{R3 Comment 7:}
Figure 3: The x-axis refers to one of the two wind data sources as "Extended
Best Tracks." Is this the same thing as the wind radii dataset described in the
text? Is so, I suggest clarifying this in the figure label.
\end{shaded}

**Response:** 

We have revised the x-axis on the figure to clarify that the comparison is based
on the wind radii dataset described in the text, as requested. The original and
revised versions of this paper are reproduced in this response document as
Figure \@ref(fig:fig3).

[Also revise figure legend?]

```{r fig3, fig.cap="Reproduction of Figure 3 from the original manuscript (left) and revised version in the resubmitted manuscript (right). In the revised version, the x-axis has been labelled to clarify that this axis is showing results based on the wind radii dataset described in the text, in response to Reviewer 3's Comment 7. The revised version also uses a more focused range for the x axis, as requested in EHP's Request 1. Figure caption in the revised manuscript: \\textit{Figure caption.}", fig.show = "hold", out.width="50%"}
include_graphics("../figures/windcomparison.pdf")
include_graphics("figures/windcomparison.pdf")
```

# Requests from EHP: {-#requests-from-ehp}

\begin{shaded}
\textbf{EHP Request 1:}
Figure 3: Please truncate x-axis scale as you do for Figure S7. Since smallest
value is $\sim75\%$, this would make the data in the relevant range much easier to
appreciate.
\end{shaded}

**Response:** 

[Typo here? I don't think there's a Figure S7.]

We have revised this figure to show an x-axis truncated at the minimum observed 
value ($\sim75\%$), as requested. The original and revised versions of this paper 
are reproduced in this response document as Figure \@ref(fig:fig3).

\begin{shaded}
\textbf{EHP Request 2:}
Main text figures (general)
To ensure that figures are accessible to readers with impaired color vision, do not use color as the sole means of conveying information in a figure unless absolutely necessary. Use different symbols, shading/textures, and line patterns instead of (or in addition to) color to distinguish among different data points. Use contrasting colors that can be easily distinguished from each other when the figure is printed in black and white. For details, see: \url{https://ehp.niehs.nih.gov/authors/figures}.
\end{shaded}

**Response:** 

In all these figures, we have used colormaps that are both accessible to readers
with several forms of color vision deficiency, including the most common type
(deuteranomaly, a type of red-green color vision deficiency), and can be easily
distinguished when the figure is printed in black and white [@viridis;
@van2015mpl].

For these figures, we selected colormaps that were created to meet both these
criteria. These colormaps are all multi-hue sequential maps that avoid red-green
contrasts, while maximizing dynamic range in comparison to something
single-hued, like grayscale [@nunez2018optimizing; @viridis]. They are all
perceptually uniform across the scale for those with normal color vision
[@liu2018somewhere] and are close to perceptually uniform for those with common
forms of color deficiency [@nunez2018optimizing]. They reproduce their original
sequential gradient when printed in grayscale and so are perceptable when
printed on a black-and-white printer [@van2015mpl; @nunez2018optimizing].
Previous research has found that colormaps in this family allow viewers to more
quickly and accurately judge relative distances in scientific figures
[@liu2018somewhere]. The family of colormaps we used in the figures is currently
considered the gold standard for scientific figures [@nunez2018optimizing].

For example, in Figures \@ref(fig:fig5check1) and \@ref(fig:fig5check2) (left) of this
response document, we have reproduced the current version of Figure 5 as it
would appear to someone with three common types of color vision deficiencies:
deuteranomaly (defective green cone cells, the most common type), as well as
protanopia (defective red cone cells) and tritanopia (defective blue cone
cells). We have also shown how the Figure would appear in grayscale in
\@ref(fig:fig5check2) (right). We have included similar versions of other 
figures from the manuscript in response to later requests from EHP in this response.

```{r fig5check1, fig.cap="Reproduction of revised version of Figure 5 to check accessibility to readers with two types of color vision deficiency, deuteranopia (left) and protanopia (right).", out.width="90%", fig.align = "center"}
include_graphics("figures/averageexposureonly_check1.pdf")
```

```{r fig5check2, fig.cap="Reproduction of revised version of Figure 5 to check accessibility to readers with a third type of color vision deficiency, tritanopia (left) and for printing the figure in grayscale (right).", out.width="90%", fig.align = "center"}
include_graphics("figures/averageexposureonly_check2.pdf")
```


\begin{shaded}
\textbf{EHP Request 3:}
Figure 3: Please check the contrast between the colors used to indicate numbers
of counties. If you can see the gradient when printed in black and white it
should be ok, but some of the differences are very subtle. Truncating the x-axis
might help with this (if possible.)
\end{shaded}

**Response:** 

As we note in our response to EHP Request 2, we used colormaps for all
figures that are designed to be perceptible both for those with common types of
color vision deficiency and when printed in grayscale. We have increased the
size of the circles in Figure 3 of the revised manuscript (reproduced in Figure
\@ref(fig:fig3) of this response) so that the colors are clearer, as well as
truncated the x-axis as requested in EHP Request 1. Also, we show in Figures
\@ref(fig:fig3check1) and \@ref(fig:fig3check2) of this response how the revised
Figure 3 would look with three common types of color vision deficiency as well
as when printed in black and white. The gradient is clear when this figure is
printed in black and white.

```{r fig3check1, fig.cap="Reproduction of revised version of Figure 3 to check accessibility to readers with two types of color vision deficiency, deuteranopia (left) and protanopia (right).", out.width="100%"}
include_graphics("figures/windcomparison_check1.pdf")
```

```{r fig3check2, fig.cap="Reproduction of revised version of Figure 3 to check accessibility to readers with a third type of color vision deficiency, tritanopia (left) and for printing the figure in grayscale (right).", out.width="100%"}
include_graphics("figures/windcomparison_check2.pdf")
```

\begin{shaded}
\textbf{EHP Request 4:}
Figure 4: Even with nominally normal color vision and a large high-resolution
monitor, it is difficult for me to make out the color differences in the
symbols-- almost all appear black or very dark blue, a dozen or so look yellow,
and a handful look dark grey. Is there any way to increase the contrast in these
colors? Would you consider binning into categories instead of using a
continuous color gradient?
\end{shaded}

**Response:** 

\begin{shaded}
\textbf{EHP Request 5:}
Figures 5--6: Please check to see if the colors used can be distinguished if
printed in black and white, and if not, use a “color-blind friendly” palette if
possible. If this is not feasible, we can request and exemption from
accessibility requirements, but we try to do this only when alternatives  would
degrade the information content of  the figure.
\end{shaded}

**Response:** 

As we note in our response to EHP Request 2, we used colormaps for all figures
that are designed to be perceptible both for those with common types of color
vision deficiency and when printed in grayscale Figures \@ref(fig:fig5check1)
and \@ref(fig:fig5check1) show what Figure 5 would look like under three common
types of color vision deficiency and when printed in black and white. Figures
\@ref(fig:fig6check1) and \@ref(fig:fig6check2) show the same thing for Figure
6. Therefore, these figures should not require any exemption from accessibility
requirements, as they should satisfy these requirements.

```{r fig6check1, fig.cap="Reproduction of revised version of Figure 6 to check accessibility to readers with two types of color vision deficiency, deuteranopia (left) and protanopia (right).", fig.show = "hold", out.width="50%"}
include_graphics("figures/jaccard_heatmap_check1.pdf")

include_graphics("figures/jaccard_heatmap_check2.pdf")
```

```{r fig6check2, fig.cap="Reproduction of revised version of Figure 6 to check accessibility to readers with a third type of color vision deficiency, tritanopia (left) and for printing the figure in grayscale (right).", fig.show = "hold", out.width="50%"}
include_graphics("figures/jaccard_heatmap_check3.pdf")
include_graphics("figures/jaccard_heatmap_check4.pdf")
```

\begin{shaded}
\textbf{R2 Comment 6:}
Supplemental Material: Please provide your supplemental material file in Word
(.docx) format. For additional information, see:
\url{https://ehp.niehs.nih.gov/authors/supplemental-material}. \end{shaded}

**Response:** 

We have provided the Supplemental Material in the Word file format in our
revised submission.

# References for the response {-#references-for-the-response}
