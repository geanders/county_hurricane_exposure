---
title: "Response to reviewers' comments for *\"Assessing United States county-level exposure for research on tropical cyclones and human health\"*"
output: bookdown::pdf_document2
toc: false
bibliography: writing/hurr_exposure.bib
header-includes:
- \usepackage{xcolor}
- \usepackage{framed}
- \usepackage{bm}
- \usepackage{subcaption}
- \usepackage{gensymb}
- \renewcommand\familydefault{\sfdefault}
- \usepackage{sansmath}
- \usepackage{bm}
- \usepackage{soul}
- \sansmath
- \usepackage{booktabs}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{pdflscape}
- \usepackage{float}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{fullpage}
- \usepackage{pdflscape}
- \usepackage{tcolorbox}
- \tcbuselibrary{skins,breakable}
- \usepackage{amsmath}
- \usepackage{xtab}
- \usepackage{rotating}
- \allowdisplaybreaks
- \usepackage[nomarkers]{endfloat}
- \pagenumbering{gobble}
- \newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r}
library(knitr)
```


# Overview {-#overview}

\colorlet{shadecolor}{blue!8}
\begin{shaded}
\textbf{Associate Editor's Overview:}
Developing a consistent and comparable metric for exposure to tropical cyclones
would be a valuable addition to the literature. All reviewers had questions
about the exposure metric, including the challenges of using county-level data
where not everyone in a county would have been exposed and the difficulties of
going from country-level to individual-level risks. Further the comparison of
different storm hazards could be clarified. The reviewers identified several
issues where further explanation would increase the accessibility of the
manuscript.
\end{shaded}

Thank you for the opportunity to revise and resubmit this manuscript. We
appreciate the helpful suggestions from the reviewers for clarifying and
deepening the discussion in the paper. 

Broadly, we have: 

1. Added discussion on the question of county-level versus individual-level
data. 
2. Added explanations for how our comparisons among different storm hazards
can help epidemiologists in designing studies and statistical analysis.
3. Added a small analysis of the correlation in rainfall metrics specifically
in cases of high rainfall ($\ge75$ mm of cumulative rainfall in the county
associated with the storm), to deepen the discussion of potential disagreement
in continuous measures of rainfall during extreme conditions. 
4. Changed labeling, axis range, and other presentation details for some
figures, as well as confirmed that the color scales will be accessible.
5. Corrected typos and improved wording throughout based on suggestions of the
reviewers.

For figures and tables that were changed in the revision, we have reproduced them 
at the end of this response, as well as some figures showing how figures will be
perceived for those who are colorblind and when printed in grayscale.

\medskip

# Reviewer 1: {-#reviewer-1:}

## Overall comments {-#overall-comments}
\colorlet{shadecolor}{blue!8}
\begin{shaded}
\textbf{Reviewer 1 Overview:}
I applaud the authors for this work, and their efforts to develop standardized
ways to measure exposure to tropical cyclones. As a disaster scientist, I very
much appreciate efforts that promote our collective ability to learn from and
across disasters to build cumulative science. 
\end{shaded}

**Response:** Thank you for your helpful suggestions. We have responded to 
each in detail below.

\medskip

\begin{shaded}
\textbf{Reviewer 1 (R1) Comment 1:}
I very much appreciate the rationale for authors' decision to focus at the
county level, especially given the available health-related data. But, since
tropical cyclones don't necessarily have consistent impacts across an entire
county, I think the limitations of this decision are worthy of further
discussion in the discussion section.
\end{shaded}

**Response:** 

This is an excellent point. We have added text in the Limitations section of the
Discussion on the potential limitations of using aggregated, county-level
exposure data in a research study:

> **Text added to Discussion (added text in bold):** "Second, these data are
aggregated to the county level. **This spatial scale allows for easy integration
with health outcome data aggregated at the county level. Such data is often used
for disaster epidemiology, as aggregated data may be easier to access than
individual-level data, especially at a scale that covers many locations and a
long time period and so allows higher statistical power and a broader range of
exposure levels within the study [@wakefield2008overcoming].**

> "**These ecological exposure estimates, however, set a common exposure level
throughout the county, ignoring within-county variability, even though such
variability often exists. For some hazards, this within-county variation in
exposure level could be stark. For example, tornadoes cause very localized
damage, directly along the tornado's path---a tornado can destroy homes on one
side of a street while leaving those on the opposite side untouched. Levels of
other hazards, like storm-associated winds and rain, will also vary within a
county, but typically with smoother variation. In particular, it will be
unlikely that a county will have one area that is exposed to extremes of these
hazards from a tropical cyclone while other parts of the county are completely
unexposed, as both the wind fields and rain fields of tropical cyclones tend to
be large in comparison to the size of a county.**

> "**Aggregated data can be used to infer contextual level associations---for
example, the association between county-level exposure to a storm hazard and
county-wide rates of a health outcome. However, ecological data is also
sometimes used to infer individual-level associations (e.g., the association
between personal exposure to a storm hazard and personal risk of  experiencing
the health outcome). Individual-level inference from ecological/aggregated data
is susceptible to ecological bias [@greenland1994invited; @portnov2007ecological;
@idrovo2011three]. Researchers who use the data provided here for ecological
studies---with the aim of making individual-level inferences---should be aware
of this potential and could explore approaches for minimizing risk of ecological
bias (e.g., @wakefield2008overcoming).**"

\medskip

\begin{shaded}
\textbf{R1 Comment 2:}
Are there opportunities to expand this approach internationally? Some decisions
(e.g., county-level) data may restrict cross-country comparisons. Can the
authors discuss this? 
\end{shaded}

**Response:** 

While there would be some limitations in comparisons based on differences in the
scale of county-equivalents, many countries affected by tropical cyclones do
have geopolitical areas that are fairly comparable to US counties, like
municipalities in Mexico, districts in India. There would be a few challenges,
however, in extending the exposure dataset for the hazards that we present in
this paper. We have added text to the paper's Discussion on opportunities and
barriers to expanding this approach internationally:

> Text added to the Discussion (added text in bold): 
"**This dataset is limited to the contiguous US. Some exposure estimates would
be fairly straightforward to extend internationally. The precipitation data is
extracted and aggregated to the county level from a re-analysis data product.
While the re-analysis product used here (NLDAS-2) only covers the contiguous US,
other similar re-analysis products, as well as other types of precipitation
datasets, have global coverage [@sun2018review]. The wind data are generated
based on a model that is currently US-focused [@stormwindmodel], but could be
extended to other areas, although this would require adding new land/sea masks
within the associated software, as well as accounting for differences across
storm basins in wind averaging periods [@harper2010guidelines] and in the
direction of cyclonic winds in the Northern versus Southern Hemisphere. Further,
since the core of the wind model was developed based on data from Atlantic-basin
storms [@willoughby2006parametric], an extension to other areas should include
separate validation and calibration to ensure it performs appropriately in those
settings. Alternatively, other wind field modeling software is available that
provides a global coverage, like Geoscience Australia's Tropical Cyclone Risk
Model (http://geoscienceaustralia.github.io/tcrm/). For tornado and flood
events, the data described in this paper drew on a US-focused storm events
database, and so international extension of data on these hazards would require
access to similar databases covering other countries. Finally, the relevant
geopolitical boundaries to use for aggregation would vary by country (e.g.,
municipalities in Mexico, districts in India).**"

\medskip

\begin{shaded}
\textbf{R1 Comment 3:}
In non-health fields, a county's inclusion in a FEMA major disaster declaration
or eligibility for public/individual assistance (all of which are somewhat
reflective of level of damage) is sometimes used as an "exposure" proxy. Have
you considered if/how your exposure assessments relate to inclusion in a FEMA
disaster declaration? In other words, does exposure to any of the hazards align
with the level of damage required for a county to be considered a "disaster
area" and/or worthy of federal assistance by current federal policy? Does this
matter?
\end{shaded}

**Response:** 

This is a great question. For tropical cyclones, some health impacts will come
directly from physical exposures like wind, rain, and flooding. However, many of
the impacts might come through indirect pathways, which start from physical
hazards but move through pathways related to property damage, infrastructure
damage, access to typical medical care, mold growth, and a number of other
intermediates. Ultimately, it would be useful to have large-scale databases of
these secondary exposure pathways to use for more complex studies of the
pathways between the physical hazards of these storms and how they affect human
health. In this sense, something like the FEMA declarations could be considered
not as a proxy for assessing exposure to physical hazards, but rather as a proxy
of damage caused by the storm, and so a measurement informative for one of these
indirect pathways from physical hazards of the storm to health impacts, through
something like a mediation analysis.

However, there are some limitations to the FEMA disaster declarations in terms
of using them as a proxy for the amount of damage a storm caused in a county.
FEMA's disaster declarations are issued to provide assistance, based on damage
assessment, to individuals or the entire public in certain locations where
catastrophes overwhelm the state or local government [@mccarthy2014fema], and
any use of them for exposure assessment is secondary. Due to the political
nature of disaster declaration process, these declarations are often subject to
many political and economic factors [@mccarthy2014fema; @logue1981research].
Given the political and economic nature of these declarations, there is likely
variation across time and geography in the likelihood of a given exposure
resulting in a disaster declaration. This would be particularly worrisome for a
study that seeks to explore risk across multiple years and affected communities.

Other sources of data may therefore be better suited to use as a marker of
damage to assess that pathway of indirect health impacts from a tropical
cyclone. For example, data on storm impacts, including property damage or
insurance claims data, are sometimes available through storm databases or
publications (e.g., NOAA's Storm Events data, tropical cyclone reports published
in the *Monthly Weather Review*). While such data could potentially be used to
create an exposure metric, tropical storm damage data requires some
normalization, to incorporate both changes in dollar value over time and also
changes in development in at-risk areas, to be comparable over extended time
periods [@pielke1998].

We have added text discussing this point to the Discussion:

> **Text in revised manuscript (added text in bold):**
"**The dataset we present focuses on the physical hazards of a tropical cyclone.
However, health impacts will often some through indirect pathways, including
through damage to property and infrastructure. In future work, it would be
useful to expand this dataset to add data related to these pathways, to allow
research exploring the role of indirect pathways from tropical cyclone phyiscal
hazards to health risk. This expansion could include adding data on normalized
storm-associated damages, or proxy measurements of such damages, from sources
like the US NOAA's Storm Events database and the US Federal Emergency Management
Agency's county-level disaster declarations.**"

\medskip

\begin{shaded}
\textbf{R1 Comment 4:}
Line 95---wondering if there is a better word for "hits" here. Maybe "exposed?"

\textit{Lines 92--95 in the original manuscript:}

\begin{quotation}
\noindent
\textit{"In many cases, these studies analyze multi-year, multi-community data,
allowing them to estimate average associations over many disasters and to
explore how a disaster's characteristics, or the characteristics of the
community it hits, modify associated health risks (e.g., Anderson and Bell 2010;
Son et al. 2012; Liu et al. 2017)."}
\end{quotation}
\end{shaded}

**Response:** 

Thank you for this suggestion. We have changed the wording in this sentence: 

> **Text in revised manuscript (relevant change in bold):**
"In many cases, these studies analyze multi-year, multi-community data, allowing
them to estimate average associations over many disasters and to explore how a
disaster's characteristics, or the characteristics of the **affected
communities**, modify associated health risks (e.g., Anderson and Bell 2010; Son
et al. 2012; Liu et al. 2017)."

We also used the word "Hits per county per decade" in the legend for Figure 5 in
the main text (reproduced in this response document as Figure \@ref(fig:fig5))
and Figure S3 of the Supplemental Material. We have revised the wording in these
figures to "Exposures per county per decade".

```{r fig5, fig.cap="Reproduction of Figure 5 from the original manuscript (left) and revised version in the resubmitted manuscript (right). In the revised version, the figure legend was changed from '\\textbf{Hits} per county per decade' to '\\textbf{Exposures} per county per decade' (bold used to highlight change). Figure caption in the revised manuscript: \\textit{Figure caption.}", fig.show = "hold", out.width="40%", fig.align = "center"}
include_graphics("../figures/averageexposureonly.pdf")
include_graphics("figures/averageexposureonly.pdf")
```

\medskip

\begin{shaded}
\textbf{R1 Comment 5:}
Lines 137--139, suggest breaking into two sentences

\textit{Lines 137--141 from original manuscript:}

\begin{quotation}
\noindent
\textit{"While other approaches have been developed to incorporate storm
hazards, particularly wind, into exposure assessment (e.g., Grabich et al.
2015a; Zandbergen 2009; Czajkowski et al. 2011), there is not yet a standard
approach, and when different studies use different datasets or storm hazards
when assessing storm exposure, it becomes difficult to compare and aggregate
findings."}
\end{quotation}
\end{shaded}

**Response:** 

This is a great suggestion. We have split the cited sentence into two sentences:

> **Text in revised manuscript:**
"While other approaches have been developed to incorporate storm
hazards, particularly wind, into exposure assessment (e.g., Grabich et al.
2015a; Zandbergen 2009; Czajkowski et al. 2011), there is not yet a standard
approach. When different studies use different datasets or storm hazards
when assessing storm exposure, it becomes difficult to compare and aggregate
findings."

\medskip

\begin{shaded}
\textbf{R1 Comment 6:}
This is not a comment on the paper, but the authors may also want to consider
publishing their work in DesignSafe, which is "the web-based research platform
of the NHERI  [NSF-Funded Natural Hazards Engineering Research Infrastructure]
Network that provides the computational tools needed to manage, analyze, and
understand critical data for natural hazards research." It is the data
repository widely used by interdisciplinary hazards and disaster researchers.
\end{shaded}

**Response:** 

It turns out that the data we present should already be accessible to use on the
DesignSafe platform, because we have shared the data as an R package.

DesignSafe is an online platform sponsered by the National Science Foundation as
part of the Natural Hazards Engineering Research Infrastructure
[@rathje2017designsafe]. This platform can be used to store, share, and publish
citable data related to natural hazards through its Data Depot. It goes beyond a
data repository, however, and also allows researchers to conduct data
integration and analysis in the cloud through its Discovery Workspace, while
drawing on data stored in the Data Depot and while using scientific programming
tools. As part of its platform, DesignSafe allows users to work in a number of
programming languages, including R (through Jupyter Notebooks)
[@rathje2017designsafe]. Therefore, DesignSafe users already have access to any
data shared through an R package, including the data we present in this
manuscript, without the data needing to be separately loaded and published
through DesignSafe's Data Depot.

This is great, because it might otherwise be difficult to try to maintain copies
of the dataset in different repositories (i.e., one copy as an R package and
another as a DesignSafe dataset), and there could be confusion about things like
the equivalence of the two copies. R packages are citable through a standard
format that gives the R package version, while data publicly shared on
DesignSafe is assigned a digital object identifiers (DOI)
[@rathje2017designsafe], and so different citations would be used for the same
dataset depending on how the user accessed it. If updates of one copy were not
immediately updated for the other copy, the copies could get out of sync, and
maintaining two synced copies would add would add an extra layer of work with
each update to the R package (we have been updating several hazards as new data
becomes available). DesignSafe's interface with R avoids this problem by
allowing its users direct access to our package and its data through that path,
as it allows for a single, citable, licensed version of the data stored and
shared from a single location, with no question of syncing separate versions of
the data or clarifying licensing and citation practices across two storage
locations.

We have added a note in the manuscript to let readers know that, because the
data is shared through an R package, and because DesignSafe's Discovery
Workspace allows users to work in R, the data can be fully accessed and used for
those working on the DesignSafe platform by using the same code in a DesignSafe
Jupyter notebook that would otherwise be used on a local computer.

> **Text added to the Methods of the revised manuscript (added text in bold):**
"**By sharing this data as an R package, it is also accessible through 
cloud-based computing platforms that incorporate Jupyter notebooks, including
the National Science Foundations's DesignSafe platform for natural hazards
engineering research [@rathje2017designsafe].**"

\medskip

# Reviewer 2: {-#reviewer-2}

\begin{shaded}
\textbf{Reviewer 2 overview:}
Exposure assessment is essential to study health impacts from disasters, but it
is also a great source of biases due to a lack of a good and fine measure of
exposures during the chaos. Often, epidemiologists use existing data at large
population level such as county level weather data which provide no individual
level exposures but give average exposure at the population level. So it is very
challenging to draw a good causal inference to health outcomes that measured at
the individual level. This manuscript is a well-written report with generously
shared data and programs on US tropical cyclones. This will contribute
significantly to disaster epidemiology which is still a new area and suffering
from good exposure ascertainment.

While I enjoyed reading the manuscript very much, I have one question I could
not figure out clearly.

One objective is to investigate patterns and agreement between different
exposure measures. I do not clearly understand the value of studying agreement
between exposures, while each exposure should be measured separately, so both
individual and overall effects can be assessed.  I do understand using "distance
from the storm" as exposure is only proxy measure and highly sensitive to
misclassification, but because direct storm hazards such as rainfall, flood,
storm surge, and tornado are publicly accessible as authors indicated, authors
could just simply guide readers to use the best exposure data rather than
conducting a quite intense analysis. This may be due to my limited knowledge, so
it would be appreciated if the authors provide explicit explanations on the
purpose and benefit of the analysis.

\end{shaded}

**Response:** 

Thank you for this suggestion, and we can see that we could have more clearly 
articulated in the original manuscript how our assessment of patterns in and 
among exposures to specific hazards can help epidemiologists to design their
studies and the statistical methods to analyze the resulting data. We provide
a detailed response in our response below to Comment 1 from this reviewer.

We have moved other suggestions that the reviewer sent in "Track Changes" of the
Word document for the original manuscript and address each in detail below. When
there were several comments on a related topic, we have grouped them together to
provide a more cohesive response to the point.

\medskip

\begin{shaded}
\textbf{Reviewer 2 (R2) Comment 1:}

Several of the comments added by the reviewer in the Word document focused on the
purpose of calculating agreement among hazard-based metrics. These were:

\begin{itemize}
\item Line 164: Isn't it obvious to use better exposure measures than proxies?
Wind, rainfall, tornado, and flood are direct products of storms while distance
is only proxy of those exposures. Rather than calculating agreement among the
exposures, it would be important to note that these are independent hazards that
can come together or come with different intensity and at different time
windows.
\item Line 354: I am not sure why different exposures should be compared and
measured the agreement. I would just treat each exposure as single independent
exposure and give a summary score by summing all the exposure with some
weighting for multiple exposures. I may not understand the importance of this
approach. If so, adding the explanation would help readers not to questioning.
\item Subsection of Results on \textit{Agreement across exposure metrics}: 
As stated below, storms bring different hazards to different locations with
different time. What would be new learning by comparing these different pairs of
exposure metrics. Somewhat apple and orange comparison. Maybe providing more
explanation can help what the important learning from this is. I may not catch
it. Similar comment was added earlier.
\item Lines 494--495: Why this agreement is important? Same questions added above
already, but still wonder what I missed. It seems like the authors try to
develop an exposure matrix that is common in occupational epidemiology, but it
is only valid method when the exposures are similar and lead to the same health
outcomes.  Rain, wind, flood, and tornado should be treated separately, maybe
except rain and flood. It is possible to be an extreme storm with only severe
wind without major impacts from other exposures. Tornado is a good example.
\end{itemize}

The text in the manuscript for comments with line numbers are reproduced below: 

\textit{Lines 164--166 from original manuscript:}

\begin{quotation}
\noindent
\textit{"They found important differences, concluding that a study may be prone
to bias from exposure misclassification if distance to the storm track is used
as a proxy for exposure (Grabich et al. 2015a)."}
\end{quotation}

\textit{Line 354 from original manuscript:}

\begin{quotation}
\noindent
\textit{"Finally, we investigated how well exposure assessment agreed across
these metrics."}
\end{quotation}

\textit{Line 491--495 from original manuscript:}

\begin{quotation}
\noindent
\textit{"For another set of tropical cyclones (e.g., Ernesto in 2006, and Bertha
in 1996, Isabel in 2003), there was moderate to good agreement for pairwise
combinations of distance, rain, and wind, but poor agreement for other
combinations of metrics, while for another set of storms (e.g., Matthew in 2004
and Katrina in 2005), there was moderate to good agreement between distance and
rain."}
\end{quotation}

\end{shaded}

**Response:** 

The reviewer makes a good point that it is important for us to clarify our
motivation for measuring agreement between the hazard-based metrics, as well as
to show readers how our results from these measures can be used to help in
designing studies and planning statistical analysis for tropical cyclone
epidemiology.

A tropical cyclone brings a number of physical hazards, including the four 
included in our study---wind, rain, flooding, and tornadoes. These separate 
hazards may each cause health impacts and in some cases might act together 
in synergy in elevating health risks. For example, severe wind and rain 
together might create a higher probability of power outages, since the rain 
could soften the ground and make it more likely that the wind can uproot 
trees. These physical hazards tend to follow different patterns, and this is
something that's intuitively understood by atmospheric scientists who study 
the storms. Storm winds tend to decrease rapidly once a storm's center is 
over land, for example, because the storm loses its main energy source---warm
water. Rainfall can persist, and might be particularly severe when the storm 
hits landscape that is not smooth, like the Appalachian Mountains. Tornadoes
can be generated in outer bands of the storm, far from the storm's center, 
but this tends to only happen in the southern half of the US. Rain and flooding
will sometimes align spatially, but you can also have severe flooding downstream
from the area that receives the most severe rain, particularly in coastal areas
with large networks of waterways.

None of these patterns would be particularly surprising to an atmospheric scientist, 
but many epidemiologists might not be aware of them, or of how they play into
exposure assessment for tropical cyclone epidemiology. Many environmental 
epidemiologists have a training that was focused more on epidemiology and 
biostatistics and rely on collaborations with experts in engineering,
atmospheric science, or environmental health to ensure that they understand
and are appropriately applying exposure assessment. In the case of tropical 
cyclones, it is clear that they generate a mixture of physical hazards. 
There has been a lot of methodological development and thought recently in 
environmental epidemiology about how to study mixtures of chemicals---for example, 
the mixture of air pollutants that a person might be exposed to, rather than 
studying the individual effects of single air pollutants. 
These mixture methods require an understanding of how the different components
are associated with each other. In the case of binary, rather than continuous,
exposure, this will be expressed as agreement among the different exposures.

First, if exposure to a pair of different hazards strongly agrees (i.e., when a
county is exposed to one hazard, they are typically also exposed to a second),
this would have several implications for epidemiological research, especially
for multi-year studies:

- From a statistical modeling point of view, if you tried to include each hazard
as a separate independent variable, you would run into problems with
collinearity if fitting the study data with a generalized linear model or other
regression model. One implication of this is that the confidence intervals on
effect estimates for the two variables would be inflated, potentially a lot,
because the model would struggle to figure out which of the two variables the
weight should be placed on, and so this uncertainty would be reflected in the
size of the associated confidence intervals.
- If you see an effect, it would be very hard to try to determine if the causal
pathway goes through the first hazard or the second. To mitigate effects, it is
important to understand the pathway through which they happen, and it might be
easier to get clues towards pathways if the hazards are better separated. By
analogy, if you were able to conduct a controlled experiment to look at the
effects of each hazard, jointly and in combination, you would design separation
in the assignment of these treatments, so you could distinguish between the two
factors. For tropical cyclone epidemiology, we are limited to an observational
analysis, but the area of causal inference is doing a lot to explore how we can
design observational studies and analyze data to come closer to what we might be
able to see with a randomized control study. To determine which of those methods
could be used for tropical cyclone epidemiology, it is important to understand
the interplay of these patterns of exposures.
- If this is the case, and a study is conducted on a single hazard of the storm, 
then there is the risk that results have been confounded by a different hazard
of the storm. 
- On the positive side, in this case the researcher may be able to fit a simpler
statistical model to estimate the joint effects of exposure to the storm as a
whole. Statistical models of mixtures can be complex to lay out, and their 
results can be hard to interpret and explain to others. If all hazards of a 
tropical cyclone follow very similar spatial patterns, then it would be 
reasonable to model tropical cyclone exposure based on one of the hazards
(and it agreement is strong enough, it wouldn't make much difference which 
of the hazards was used for this). This would allow for the use of very 
straightforward statistical modeling, drawing on well-developed models currently
used in environmental epidemiology to study things like the health risk associated
with exposure to a single pollutant or a single physical hazard like outdoor 
temperature. 

Second, if a pair of hazards tend to have little spatial overlap among 
counties, this also brings some implications for epidemiological study design
and statistical analysis: 

- In this case, a single-hazard analysis could miss a lot of the risk created
by the storm as a whole. This is a concern because there have been some cases
of studies that have assessed exposure based on a single storm, typically wind.
[Grabich example, Darren Sun example]. We are aware of one other paper 
currently under review that takes this same approach of focusing on the wind
hazard of these storms. .... In interpreting these papers, it is helpful to
know if this hazard can stand as a reasonable proxy to the collection of 
physical hazards of the storm. If not, the paper must be interpreted as 
investigating

In the past, much of tropical cyclone epidemiology focused on cases studies of
single storms. Multi-year studies are becoming more common. Both types of
studies are important in exploring both typical and unusual health risks that
can be caused by these storms. Therefore, it's important to understand the
patterns between these different hazards both for single storms and across many
storms. In our analysis, we find that these hazards typically are not in strong
agreement across most storms, suggesting that mixture methods could be
meaningfully applied in most cases, and that there may often be the chance to
separate the role of different hazards through such models. However, we also
find that there are a few storms for which the hazards follow very similar
spatial patterns (Hurricane Floyd in 1999, for example), and in these cases
there may be problems of multi-collinearity and non-separability of different
hazard effects if a researcher tries to fit a model that incorporates each
separate hazard.



Issues: 

1. **Interpretation** Effect of one hazard, or storm as a whole?


2. **Confounding**


3. **Multi-collinearity**


4. **Disentangling role of different hazards**


5. **Statistical power** (to separate effects of different hazards)



------------------------------------------------------------------------------

  
2. These results will not be surprising to an atmospheric scientist / disaster
researcher, but there are environmental epidemiologists who have done research
on other exposures and are now starting to study tropical cyclones (session at
ISEE, for example). It is useful for epidemiologists entering into tropical
cyclone research to understand these facets of tropical cyclone exposure,
including the distinction between the very coastal wind exposures and other
hazards that tend to reach further inland.
3. There are epidemiological studies that have used only one hazard for exposure
assessment. This has most often been the case for wind. If this exposure
assessment is meant to capture "tropical cyclone exposure" in general, with all
the hazards that are related to tropical cyclones, then there is the chance for
exposure misclassification if this single hazard is used.
4. In the past, it was a very complex issue to try to pull together data on all
these hazards. We agree that now that we have provided a dataset with all of
them, epidemiologists should be thinking about multi-hazard analyses. However,
there still will be some barriers to that. [Recent work on multi-pollutant
exposures and the complexities associated with that.] If one of the hazards
dominates in explaining associated health risk, then in some cases it might be
reasonable to focus on that hazard, but in that case it is critical, based on
our results, to remember that the exposure assessment is not capturing all
hazards of the storms.


The largest-scale county-level exposure study is likely that of @zandbergen2009,
which estimated exposure in US counties to all US landfalling Atlantic basin
tropical storms between 1851 and 2003, using both distance and an exposure
metric that incorporated distance and windspeed. They used this exposure
evaluation to create maps of total exposure to tropical storms within US
counties, as well as to explore associations between a county's long-term
exposure to tropical storms and its location, distance from the coast, size, and
shape [@zandbergen2009]. @kruk2010 explored exposure to hurricane-related winds
in the United States, including inland areas, for 1900-2008.

Geographical patterns can differ for these different
storm hazards, and so exposure assessment based on one hazard could create
exposure misclassification if the pathway for health risks is through a
different storm hazard.   

A tropical cyclone's high winds can bring health risks and property damage
through structural damage of houses and other buildings, falling trees, and
wind-borne debris [@rappaport2000] and cause power
outages [@liu2005; han2009], which introduce a number of threats to
human and ecological health, including water quality risks if the outage affects
wastewater treatment plants [@mallin2006].  Other risks can exist
without severe wind; for example, one study found that most of the direct
hurricane-related deaths in the US between 1970 and 1999 occurred in cases
when wind was below hurricane strength, including for Tropical Storms Charley
in 1998 and Alberto in 1994 [@rappaport2000].  Tropical cyclones can
produce excessive rain, especially in certain topographies (e.g., near
mountains), so counties well inland sometimes experience more extreme rain than
coastal counties. Flood risks from tropical cyclones can result from this rain,
although the two risks are not perfectly correlated [@chen2015]. In the
US, over half of hurricane-related direct deaths from 1970 to 1999 from
Atlantic basin storms were a result of freshwater
flooding [@rappaport2000]. Flooding can also degrade water
quality [@mallin2006], which can threaten both human and ecological
health.

If a study misclassifies exposure to the hazard or hazards that cause the
health risk being studied, the study will generate biased estimates of tropical
cyclone risks and impacts. Further, when different studies use different
methods to assess exposure to tropical cyclones, their results are difficult to
meaningfully compare and aggregate. If different methods identify
similar sets of communities as ``exposed'',  these concerns are less serious.
However, if different methods differ substantially in which communities they
identify as ``exposed'', it makes it very important that epidemiological
studies are thoughtful in how they assess exposure.

These analyses can also help researchers compare and interpret results from
previous epidemiological studies that have assessed tropical cyclone exposure in
different ways, helping to [synthesize] previous epidemiologic results to form a
better picture of how these storms can affect human health.

However, these frequency maps, together with evidence from
specific tropical cyclones (Figures \ref{fig:ivanexposure}
and \ref{fig:jaccard}),  do illustrate the potential for strong differences in
spatial patterns in tropical cyclone exposures, depending on which tropical
cyclone hazards are considered.  A few previous studies have sought to
determine county-level exposure to tropical cyclones over multi-year periods,
including @zandbergen2009, which estimated exposure in US
counties to all US landfalling Atlantic-basin tropical cyclones
between 1851 and 2003, using both a distance-based metric and a metric that
combined distance and windspeed, and [@kruk2010], which explored
exposure to hurricane-related winds in the US, including inland areas,
for 1900--2008.  Our results suggest that such exposure assessments may
perform well in capturing some tropical cyclone hazards (e.g., wind), but
likely miss other potentially dangerous tropical cyclone exposures, especially
for hazards that repeatedly threaten northern or inland counties (e.g., rain,
flooding).

Therefore, use of distance to assess tropical cyclone exposure for impact
studies could result in problematic exposure misclassification, which could mask
true associations, even strong associations, between tropical cyclone exposure
and outcomes of interest in impact studies [@savitz2016interpreting;
armstrong1998effect]. The use of a single hazard-based metric (e.g., wind) could
cause similar problems if the impact is driven, at least in part, by a different
hazard or by multiple hazards of the tropical cyclone.

If measurements of one storm hazard are used as a proxy to capture exposure to
a different hazard, or a non-hazard proxy like distance to the storm track is
used to assess exposure to storm hazards, the resulting exposure
misclassification could be differential (i.e., associated with the outcome of
interest or with factors associated with risk of the outcome of interest). 

Therefore for most tropical cyclones, since exposure assessments often differ
across storm hazards, as well as between each storm hazard and a distance-based
proxy measurement, exposure misclassification is a potential risk.

Further, we investigated agreement in exposure assessment across these metrics
when applied individually. We found large differences in which counties are
exposed to different hazards of tropical cyclones and that distance is, at
best, a moderate, and often a very poor, surrogate for exposure to the specific
tropical cyclone hazards of high wind, extreme rainfall, flooding, and
tornadoes. Use of distance as a surrogate for any of these hazards, or exposure
assessment based on one hazard when the pathway for health impacts is in part
or full through another storm hazard, could lead to exposure misclassification.
In the case of tropical cyclone risk and impact studies, including
epidemiological studies, this would result in biased estimates.  Our findings
highlight the importance of clarifying the potential pathway from tropical
cyclone hazards to health impacts when conducting tropical cyclone
epidemiological studies, and then basing exposure assessment on these hazards.

---------------------------------------------------------------------------

It is obvious that it is typically better, but in cases where the proxy is much
more practical to measure, it may need to be more than just a bit better, but
instead substantially better. Also, there could be some cases where the proxy
might actually be better---for example, if the proxy can be measured with very
low level, while the direct exposure measure might only be measurable with high
error. In that case, the proxy could be the better metric and might provide a
more precise estimate of the association with health risk.

[Env. Epi. book---advantages and disadvantages of different types of measures]

We agree that it is helpful to clarify for readers that these independent
hazards can come together in a storm event at different intensities and at
different time windows. We have added some text on this:

[Added text]

However, we disagree that this should be down as an alternative to calculating
agreement. Epidemiologists need to understand how these exposure measurements
agree to help in planning studies and statistical approaches to interpreting the
resulting data. In this sense, "agreement" is providing a measure similar to
correlation for continuous variables; our choice of agreement with the binary
exposure classifications reflects the more common use of binary classifications
for most tropical cyclone epidemiology to date.

Epidemiological studies might focus on tropical cyclone exposures at two levels.
First, they might wish to focus on a specific hazard. For example, a study might
hypothesize that mold growth following flooding from a tropical storm might
increase risk of respiratory health outcomes in the months after a storm. In
this case, the clear causal pathway recommends a focus on one of the storm
hazards, rather than all storm hazards. However, other storm hazards could
confound the association between flood exposure and respiratory health risk if
the other hazards are ignored *and* if they are associated with both the
exposure of interest (storm-associated flooding) and the health outcome. For
example, if wind exposure assessments are in high agreement with flood exposure
assessments for storms, and if wind affects risk of respiratory outcomes by
causing extensive property damage and creating extreme psychological stress,
which can have repercussions on respiratory health, then the wind hazard could
confound the estimated association between storm-related flood exposure and the
health outcome.

This bias would be higher when the confounder and exposure of interest are more
strongly correlated (for continuous variables) or in higher agreement (for
categorical variables). Conversely, if the exposure and the potential confounder
are, in practice, only weakly associated, then the potential for confounding is
low. The Jaccard index is one measure of similarities between categorical
(including binary) coefficients.

Another consideration is collinearity. If one hazard is the exposure of interest
and another hazard is a potential confounder, then the model should adjust the
confounder or it will be misspecified and be prone to bias. However, if the
exposure of interest and the potential confounder are very strongly
correlated/in agreement, then including both as independent variables in a
regression model often causes numerical problems in fitting the regression
model, including instability in the estimated coefficients and inflated
variance. In very extreme cases, the statistical software may not be able to
invert the matrix [? only for linear regression?].

Therefore, it is helpful for epidemiologists to understand if these independent
storm-associated hazards tend to be strongly associated (in high agreement),
both within specific storms (for single-storm studies) and on average across
most large storms (for multi-storm studies). This knowledge will help them in
identifying potential confounders if they are interested in studying the effects
of a single hazard of the storm and also in determining if control for these
potential confounders among other storm hazards might cause numerical problems
or other collinearity-associated problems when fitting a regression model.

If a researcher wishes to study the storm as a whole, then the researcher 
could either seek a single measure to capture exposure to the storm as a whole
or investigate more complex models that model the influence of the storm through
pathways of several different hazards. 

If a researcher wants a single measure for the storm as a whole, then it is
helpful to know how well exposure assessments based on the hazard components of
the storm agree with each other. If there is strong agreement, then any of those
hazards could be used as a primary marker of exposure assessment. This is
conceptually similar to checking for observer / rater agreement.

> "When the row and column variable srepresent different observers' rating the
same subjects or objects, interest is focused on *observer agreement* rather
than mere association. In this case, measures and tests of agreement provide a
method of assessing the reliability of a subjective classification or assessment
procedure." [@friendly2015discrete]

> "In assessing the strength of *agreement* we usually have a more stringent
criterion than in measuring the strength of *association*, because observers
ratings can be strongly associated without strong agreement. For example, one
rater could use a more stringent criterion and thus consistently rate subjects
one category lower (on an ordinal scale) than another rater. More generally,
measures of agreement must take account of the marginal frequencies with which
two raters use the categories. If observers tend to use the categories with
different frequency, this will affect measures of agreement."
[@friendly2015discrete]

When you have an array of two or more exposures that are strongly correlated,
including them together in a regression model can cause problems from
collinearity [@schisterman2017collinearity].

> "Environmental exposures ... often consist of an array of related individual
factors that may be highly correlated with each other, causing concern about the
impact of collinearity when attempting to identify individual effects."
[@schisterman2017collinearity]

**Commonly have multiple factors of interest, correlated**

In some areas of epidemiology, researchers have moved toward the idea of a 
"web of causality": 

> "'Multiple causation' is the canon of contemporary epidemiology, and its
metaphor and model is the 'web of causation'. Expressed through the notion
of 'multifactorial etiology' and embedded in the statistical techniques
of 'multivariate analysis', the belief that population patterns of health 
and disease can be explained by a complex web of numerous interconnected 
risk and protective factors has become one of this discipline's central 
concepts. Equally entrenched is the corrolary that epidemiology's power
to improve the public's health rests upon its ability to identify---and predict
the results of breaking---selected strands of this causal web." [@krieger1994epidemiology]

This is in contrast to focusing on single factors: 

> "Expressly challenging the still-pervasive tendency of epidemiologists to
think in terms of single 'agents' causing discrete diseases, the provocative
metaphor and model of the 'web' invited epidemiologists to embrace a more
sophisticated view of causality." [@krieger1994epidemiology]

In this framework, epidemiology helps by identifying where it would help to
break strands of the web: 

> "Using this model, MacMahon et al. drew several important inferences about
prevention and research that remain part of epidemiologic thinking to this day.
Arguing that 'to effect preventative measures, it is not necessary to understand
causal mechanisms in their entirity', they stated that 'even knowledge of one
small component may allow some degree of prevention' since 'wherever the chain
is broken the disease will be prevented'." [@krieger1994epidemiology]

In other words, if you can identify *necessary* causes, you can craft 
*practical* interventions. 

In some fields of epidemiology (e.g., nutritional epidemiology), it is common 
to study cases where there are multiple potential risk factors, and these 
factors are often strongly correlated [@schisterman2017collinearity].

> "The dynamics of many important ecological and evolutionary processes are 
often influenced by multiple interacting factors, and attempting to understand 
the dynamics of such systems presents difficult technical and philosophical 
problems." [@petraitis1996inferring]

> "Often in practice, investigators are faced with decisions of how to handle
highly correlated variables." [@schisterman2017collinearity]

**Methods to tackle multiple causality**

When the aim is to explore the influences of multiple associated factors, there
are some different strategies that can be used. These include multiple
regression and path analysis:

> "Evolutionary ecologists have recently turned to path analysis, multiple
regression, and related techniques to analyse systems of multiple causality.
While these techniques are often seen as competitors, they are, in fact,
related, and as a result the problems of these techniques are similar."
[@petraitis1996inferring]

**Implications of collinearity**

> "Two variables are defined as collinear if one can be expressed as an exact
or near linear combination of the other. ... In general, collinearity between
variables is described by the magnitude of their correlation." 
[@schisterman2017collinearity]

It can complicate inference of model coefficients. This is always a concern for 
inferential models. For predictive models, it can be a problem if you later use
the model to predict in a case where the correlation structure is different than
in the training data. 

> "The dependence of regression and path coefficients on the correlation
structure is often glossed over. Yet this dependence means that inferences about
the strengths of path coefficients are conditional upon the correlational
structure among the predictor variables. If the correlation structure of the
sample does not match the correlational structure of the population then
regression and path coefficients will not estimate relative strengths
accurately. This can occur if sampling is not random or if analysis is based on
data from experiments with factorial designs, which break the correlational
structure amnog the predictor variables." [@petraitis1996inferring]

These implications can depend on whether the modeling goal is predictive or 
inferential. 

> "When the goal is to choose covariates based on their predictive value, 
concerns about collinearity stem from the desire to improve parameter estimates'
precision, which can be inflated when highly correlated covariates are included
in the model." [@schisterman2017collinearity]

> "In a causal framework, on the other hand, interest is often centered on a
specific effect from a correctly specified causal model, even in the presence of
highly correlated data, despite a potential loss of statistical efficiency.
Under such a viewpoint, bias due to misspecification of the causal associations
is a more devastating result than reduced precision of parameter estimates
correctly estimated. Furthermore, a precisely but incorrectly estimated
parameter may lead to invalid inferences. ... Relying on conventional
variable-selection algorithms and standard analyses can ignore important
confounders and even produce extremely imprecise confidence intervals."
[@schisterman2017collinearity]

The amount of bias in the unadjusted model (in terms of bias from an unadjusted
confounder) depends on the strength of association between the exposure of
interest and the potential confounder [@schisterman2017collinearity].

> "This is especially important for the confounding variable scenario, where 
correctly specifying the model may result in adjusting for a nearly 
collinear variable." [@schisterman2017collinearity]

The degree of agreement will influence the degree of confounding in an 
unadjusted model, for either one or two confounders: 

> "In this confounding scenario, increasing correlation exacerbates the bias
due to misspecification, similar to results for a single confounder."
[@schisterman2017collinearity]

Extreme collinearity can create numerical problems
[@schisterman2017collinearity].

> "Under the extremely unlikely scenario of extreme collinearity [(abs. rho of
0.999 or higher)], the numerical matrix inversion required for estimation fails,
resulting in unstable and biased predictors." [@schisterman2017collinearity]

> "Only for extreme values of rho cloes to 1 or -1 is beta-squareed
nonidentifiable due to numerical instability; otherwise, the correctly specified
model produces the most desirable (e.g., unbiased) estimates of the total effect
of the exposure on the outcome." [@schisterman2017collinearity]

Collinearity can cause imprecision in coefficient estimates, even if those
estimates are unbiased [@schisterman2017collinearity].

> "Multicollinearity: A term that refers to correlation among the independent
variables in a multiple regression model; it is usually invoked when some 
correlations are 'large', but an actual magnitude test is not well defined.[1]"
[@gunasekara2008glossary]

> "Collinearity occurs in multiple regression models when two (or
more---multicollinearity) exposure variables are included in the model but are
so similar to each other that they are essentially measuring at least part of
the same thing. Collinearity creates problems with interpreting the analysis by
affecting the standard errors of the variables (as it increases variance)[24]
and by causing biased estimates for one or both of the collinear terms
(sometimes dramatically so) [25]. If there is perfect collinearity between two
variables then one should be dropped from the model. However, dropping exposure
variables to reduce multicollinearity may lead to bias in the model from
dropping useful information." [@gunasekara2008glossary]

> "It might be argued in some cases that it is appropriate to include
(collinear) variables in a model even when they are highly correlated, because
the theoretical basis for including the variables is strong and the results of
the model are consistent with expectations [10]. In such cases, models with and
without the variables would be tested and compared. Such consideraion of
alternative models tends to be described as an issue of (mis)-specification in
econometrics. However, in epidemiology this tends to be described in terms of
mediating and *intermediary variables*. Thus, an epidemiologist might argue for
including an intermediate variable in a model (and testing it against a model
without the variable) because including that variable might elucidate direct and
indirect pathways between the exposure and outcome variables. An econometrician
might do the same thing but describe this in terms of finding the correct model
specification." [@gunasekara2008glossary]

**Techniques to address collinearity**

There are study designs that might help to separate different effects. For
example, some matching designs might help in creating a subset of data in which
the association that exists in the full dataset is broken (e.g.,
@leal2012multicollinearity).

> "Matching is typically employed to reduce model dependence and estimate 
associations in a more empirical way than would be necessary without 
matching. In line with this practice, matching was employed as a diagnostic
tool to verify whether the effects of environmental variables that are highly 
correlated with each other could be disentangled." [@leal2012multicollinearity]

You could also explore techniques of dimension reduction, to create a smaller
subset of independent variables for which the correlation is broken. For
example, you could use PCA [@leal2012multicollinearity].

There are other techniques that allow some bias in estimates in an attempt to
reduce problems from collinearity, like ridge regression
[@petraitis1996inferring].

> "Several biased estimation techniquest ahve been proposed as a way to combat
collinearity (Myers 1990). These are controversial methods. Ridge regression,
for example, biases the regression coefficients in order to improve the model's
ability to predict the criterion variable. The estimates of the individual
regression coefficients may be very biased even though when taken together they
provide a very good prediction of the criterion variable."
[@petraitis1996inferring]

> "When correct specification of the models still leads to 
problems for conventional regression methods, one can apply modern techniques
such as Bayesian hierarchical models with shrinkage estimators."
[@schisterman2017collinearity]

**Are effects of different factors 'separable'?**

Epidemiology often aims to inform policy decisions. In this case, it can be
important to characterize the separate effects of different associated factors
that contribute to the health risk [@leal2012multicollinearity].

> "To develop efficient public health interventions addressing the obesity 
epidemic, it is important to identify exactly which aspects of the
environment influence obesity risk. For example, demonstrating that the density 
of fast-food restaurants was associated with obesity risk and demnstrating that
the density of sports facilities was associated with obesity risk would lead to 
different interventions." [@leal2012multicollinearity]

However, it can be very difficult to separate the effects of different factors
if those factors are strongly correlated [@leal2012multicollinearity]: 

> "However, many neighborhood characteristics, especially those related to the
densities of physical features and services, are strongly correlated with each
other. Therefore, it is not clear whether it is even possible to disentangle the
effects of these different environmental dimensions, even if they are
hypothesized to influence obesity risk through distinct causal pathways."
[@leal2012multicollinearity]

-----------------------------------------------------------------------------

As we note in our general response to your comments, we agree in general with
your instinct here. However, there are some subtle points to note.

First, we understand the potential appeal of creating a single exposure summary
score based on a summation of exposures. This simplifies some of the statistical
modeling, for example, and also provides a single exposure estimate to provide
as the key study conclusion. However, in many areas of tropical cyclone
epidemiology, it is unlikely that exposure to each type of hazard should be
given equal weight. For example, an analysis of respiratory health in the months
after the storm might hypothesize a strong connection with flooding, and smaller
connections with rainfall and winds (through the pathway of property damage).
Use of a pre-defined summation of exposure to each hazard would mask some of the
potential association.

While a summary statistic could be defined that adds a weight to each exposure,
it would often be unclear *a priori* what weight each hazard exposure should be
given. A better method might be to use a regression framework, where each hazard
exposure is included as a separate explanatory variable, and the model uses the
observed data to determine the appropriate weight for each hazard in terms of
modifying risk to the outcome of interest. To explore the influence of multiple
concurrent hazards, interaction terms could be added.

However, if our analysis had found that hazard exposures follow very similar
patterns, in terms of the counties exposed during a storm, then this strong
agreement would result in a number of problems in fitting and interpreting these
types of models. First, strong agreement in two or more of the explanatory
variables in a regression model leads to collinearity, which among other
implications often leads to a large inflation of confidence intervals for the
effect estimates of the correlated explanatory variables. Further, if the hazard
exposures were in strong agreement, then it would be difficult or impossible to
disentagle the effects of the separate hazards, as a strong effect for one would
be impossible to interpret with confidence, since the strong agreement in the
data (and resulting low co-variability in the variables in the data) could cause
the model to mistakenly attribute the effect of one hazard to the other.
Further, it may become impossible in this case to estimate synergistic effects
between the two, as an indicator of an interaction between the two exposures
would be almost collinear with the two main effects.

In our analysis, we find that this is usually not the case for the four tropical
cyclone hazards that we consider. Instead, we find that for most storms, the
hazards are fairly well-separated in terms of the counties they effect. There is
a particularly strong pattern where inland counties can be exposed to extreme
rain and flooding, but not wind. This separation opens the door for some
interesting study designs and statistical modeling. For example, these patterns
suggest that a study could investigate whether storm-associated rains alone
create a health risk, as there are many exposures with only rain in inland
counties, and so health associations could be explored here and contrasted with
coastal areas that experienced both wind and extreme rain.

-------------------------------------------------------------------------------

> "A job exposure matrix (JEM) may be defined as a cross classification of jobs
and occupational exposures. Some matrices are based on tasks, instead of jobs. 
... Usually there is a group of experts who build the matrix based on their 
own knowledge and experience on occupational exopsures. The experts should 
assess exposure to an open or fixed list of occupational exposures (that can 
include chemical, physical, biological, and/or psychosocial agents) for an
open or fixed list of jobs (or tasks) usually coded according to some established
national or international classification system. Some JEMs also include 
information for different calendar time periods." [@garcia2003glossary]

[New advances in multi-pollutant analysis.]

[Some of the hazards could create similar risks, if they converge on a common
pathway of risk. For example, if pathway is through stress from property damage,
individually and in the county, then several hazards could indeed lead to the
same health outcomes (e.g., PTSD, other psychological markers, risk of acute
cardiovascular outcomes, etc.). One example is extreme level of destruction both
from wind (Hurricane Andrew, Hurricane Hugo), from river flooding associated
with among of precipitation (Hurricane Floyd, Hurricane Florence), and from
flash flooding associated with the rate of precipitation (Virginia storms).]

[A better future direction might be through regression models with multiple
explanatory pathways. This allows the model to fit different weights to each.
Other models can also be explored, like regression trees, which might have an
easier time capturing non-linearity (if exposure is included as a continuous
value, as with wind and rain) and interactions when there are co-exposures to
two or more hazards. Both of these are able (and will) either exclude or give a
very low weight to an explanatory variable that does not help much in explaining
variation in the health outcome.]

\medskip

\begin{shaded}
\textbf{R2 Comment 2:}

Other comments were related to correlations estimated in the validation 
analysis for the precipitation data:

\begin{itemize}
\item Line 394: It looks like the correlation coefficients can be very low if measured
from 75mm or somewhere around.  This seems to be a significant issue for
analyzing storms with heavier rainfall using NLDAS-2 data.
\item Line 515: It would be informative to provide correlation coefficient for only
above 75 mm measures.
\end{itemize}

The text from the referenced lines are reproduced below:

\textit{Line 392--394 from original manuscript:}

\begin{quotation}
\noindent
\textit{"Within these counties, storm-related rainfall measurements were
well-correlated between the two data sources, with rank correlations (bottom
right of each graph in Figure 2) between 0.87 and 0.98. "}
\end{quotation}

\textit{Line 514--515 from original manuscript:}

\begin{quotation}
\noindent
\textit{"The rainfall data are generally well-correlated with ground-based
observations, but may sometimes underestimate very high rainfall values (Figure
2)."}
\end{quotation}
\end{shaded}

**Response:** 

This is a great suggestion. In the original manuscript, we describe this lower
correlation at higher precipitation values through the use of examples from
specific storms, and discuss the potential reasons for it. Measuring the
correlation specifically within these higher-precipitation events would add more
quantitative evidence to this discussion.

We have added estimates of these correlations specifically for
high-precipitation events in a new table in the Supplemental Material (Table S2
of the manuscript, reproduced as Table \@ref(tab:highprecipcorr) of this
response document).

\input{tables/precip_high_corr.tex}

In several cases, the correlation was much weaker when limiting analysis to
these severe rainfall events. For example, in Miami-Dade County, FL, the
Spearman correlation coefficient was 0.94 for all 64 tropical cyclones that came
near the county over the analysis period, while it was only 0.49 among the 18
storms with cumulative precipitation of 75 mm or more. There was a similar
reduction in Mobile County, AL. However, for some counties, the correlation
remained high (e.g., Harris County, TX; Orleans Parish, LA), although in all
cases there are small numbers of extreme precipitation events (5--20 across
these sample counties), and so there is likely substantial random variation in
these correlation estimates, since they are based on small numbers of 
observations.

We have added text to mention this point and to direct readers to the added
supplemental table:

> **Text in revised manuscript (relevant addition in bold):**
"The rainfall data are generally well-correlated with ground-based
observations, but may sometimes underestimate very high rainfall values (Figure
2), **and in some counties the correlation was substantially lower when 
considering only tropical cyclones with cumulative local rainfall of 75 mm
or more (Supplemental Table 1)**."

\medskip

\begin{shaded}
\textbf{R2 Comment 3:}
Figure 4: I would add Y-axis label "NOAA classification."
\end{shaded}

**Response:** 

This is a great suggestion. We have made this change, as well as several changes
in response to EHP's Request 4 later in this response.

The original and revised versions of Figure 4 of the manuscript are reproduced in
Figure \@ref(fig:fig4) of this response.

```{r fig4, fig.cap="Reproduction of Figure 4 from the original manuscript (top) and revised version in the resubmitted manuscript (bottom). In the revised version, we have added a title to the y-axis ('Classification based on NOAA Storm Events Data'), binned the values shown by each point's fill, so these colors are easier to distinguish, increased the size of the points, and changed the algorithm for jittering, so none of the points overlap.", fig.show = "hold", fig.align = "center", out.width="100%"}
include_graphics("../figures/floodcomparison.pdf")
include_graphics("figures/floodcomparison.pdf")
```

\medskip

\begin{shaded}
\textbf{R2 Comment 4:}
Table 2: This is another confusing table. Not sure what compared here. The
second column is a mean \# of exposed counties over years and the third column
seems like showing single storm with the max \# of exposed counties. Not sure
what info I should digest from this table.
\end{shaded}

> **Text from Results of original manuscript:**
"Across the four storm hazards considered, there was wide variation in the
average number of county exposures per year (Table 2). For tropical cyclone
tornadoes, there were on average about 40 county exposures per year within our
study. County exposures were more frequent for tropical cyclone wind exposures
(>160/year on average), even more frequent for tropical cyclone flood exposures
(>190/year on average), and most frequent for tropical cyclone rain exposure
(>290/year on average). For every hazard except tornadoes, we identified at
least one tropical cyclone that exposed over 250 counties (Table 2). However,
the largest-extent tropical cyclone varied across hazards: Frances in 2004
exposed the most counties based on rain, Michael in 2018 based on wind, and Ivan
in 2004 based on flooding and tornadoes (Table 2)."

**Response:** 

We hope that these results can help epidemiologists who are planning new
multi-year studies of tropical cyclones and associated health risks. For 
planning a multi-year study, it is helpful to know how many exposures the 
study might incorporate, as this can help in giving a general idea of whether
the study might have adequate statistical power to investigate a certain 
research question. This table provides some basic summaries of the extent
of exposure to different tropical cyclone hazards, both on average for the
storms in the study and also for those storms that were most extensive. 
Further, as with other results in the study, it provides evidence that 
patterns in different hazards can vary substantially, both because some 
hazards are much less likely to expose counties (e.g., torndaoes are a fairly 
rare exposure, based on this table) and also because there is variation in 
the most extensive storms across the hazards considered.

We have added text to help the readers interpret this table ...

\medskip

\begin{shaded}
\textbf{R2 Comment 5:}
Line 602: This is not a new finding, but how much misclassified would be a good
question to answer.

\textit{Line 600--602 from original manuscript:}

\begin{quotation}
\noindent
\textit{"Based on our results, the use of a distance-based metric to assess
exposure to any of these hazards, or the use of measurements from one hazard as
a proxy for exposure to any of the other hazards considered, would often
introduce exposure misclassification."}
\end{quotation}
\end{shaded}

**Response:** 

Figure 7 of the main text is meant to help illustrate the potential for exposure
misclassification, including when using a distance-based metric as a proxy. We
used the Jaccard index because we are using data for all eastern US counties.
For any storm, however, there will be large parts of this area that are
unquestionably unaffected, because they are so far from the storm. For example,
during Hurricane Floyd in 1999, the storm made landfall in North Carolina and
moved northward along the Eastern Seaboard. While there will be questions in
some case about whether counties in the Mid-Atlantic and New England were
exposed to this storm, counties in Texas, Louisiana, and other states in the
west of the study area were unquestionably unexposed to this storm. If we
measured misclassification using a metric that includes these counties in the
denominator, it would be overly optimistic because of the strong agreement in
counties far from the storm, like Texas counties during Hurricane Floyd, and
wouldn't help to pinpoint the potential for disagreement in areas nearer the
storm path.

However, one downside of this metric is that it does not help readers understand
the direction that disagreement is going. For example, it does not provide 
information about how many counties were classified as "exposed" based on a 
distance proxy but "unexposed" by a hazard-based proxy. This could be useful in 
interpreting our results in Figure 7 of the main table. 

\input{tables/wind_misclass.tex}

\input{tables/rain_misclass.tex}

\input{tables/flood_misclass.tex}

\input{tables/tornado_misclass.tex}

We have added four new tables in the Supplemental Material, one for each of the
hazard-based metrics we considered. We have reproduced these tables in this
response document as Tables \@ref(tab:misclasswind)--\@ref(tab:misclassflood)
Each breaks down agreement and disagreement between the distance-based proxy
metric and that hazard-based metric within several storms in our study period.
These tables focus on storms with at least 250 counties exposed by at least one
of the metrics considered. These tables allow readers both to investigate
general patterns in disagreement and exposure misclassification across these
storms and also to see cases of unusual storms. For example, for most storms,
disagreement between the distance proxy metric and the wind-based metric
resulted mainly from mis-classification of counties as exposed based on distance
while they did not experience gale-force winds. However, there were a few
storms, like Hurricane Bertha in 1996, where the inverse was the case, and a
distance-based metric would have missed a large number of counties that
experienced gale-force winds from the storm (misclassified them as unexposed),
but not misclassified many counties as exposed when they in fact did not
experience winds at this level.

We have added a reference to these new tables in the main text of the manuscript: 

> **Text in the revised manuscript (relevant addition in bold):** 
"We drew similar conclusions when we investigated all 46 tropical cyclones
between 1996 and 2011 (when data for all five metrics were available) for which
100 or more counties were exposed based on at least one metric (Figure 7;
**Tables S3--S6 provide underlying numbers for the most extensive of
these, the storms for which 250 of more counties were exposed based on at least
one metric)**."

> **Text in the revised manuscript (relevant addition in bold):**
"Based on our results, the use of a distance-based metric to assess exposure to
any of these hazards, or the use of measurements from one hazard as a proxy for
exposure to any of the other hazards considered, would often introduce exposure
misclassification **(Tables S3--S6)**."

\medskip

\begin{shaded}
\textbf{R2 Comment 6:}
Lines 626--627: It would still be beneficial to treat each exposure as a single
variable first and then consider overall impact. Only if each exposure data are
available.

\textit{Line 626--628 from original manuscript:}

\begin{quotation}
\noindent
\textit{"For these storms, it may be possible to assess exposure to multiple
hazards of the storm using a single metric, perhaps even a proxy like the
distance between the county and the storm’s track."}
\end{quotation}
\end{shaded}

**Response:** 
We agree. This type of approach has not always been easy in the past, but can
be easily implemented with the dataset we publish here. We have added to the
text on this point: 

> Text in revised manuscript (relevant addition in bold):
"For these storms, it may be possible to assess exposure to multiple
hazards of the storm using a single metric, perhaps even a proxy like the
distance between the county and the storm’s track. **With the dataset we 
describe in this paper, however, there is little need to limit analysis
based on exposure to a single hazard or proxy, although multi-hazard studies
of storms with high agreement among hazard exposures should look out for 
modeling issues from multicollinearity.**"

\medskip

# Reviewer 3: {-#reviewer-3}

\begin{shaded}
\textbf{Reviewer 3 overview:}
This paper describes the development of a dataset and R package that can be used
to assess exposure to tropical cyclone-related hazards (e.g., wind,
precipitation, flooding) at the county level in the eastern United States, as
well as a descriptive analysis of county-level exposure to these hazards. This R
package is novel and I believe of high interest to researchers interested in the
health effects of tropical cyclones.  I have a few minor suggestions to further
improve the clarity of the manuscript.
\end{shaded}

**Response:** 

Thank you for the helpful suggestions and recommendations. We have responded in 
detail to each comment or question below.

\medskip

\begin{shaded}
\textbf{Reviewer 3 (R3) Comment 1:}
Starting on line 128, the authors write "Extreme winds are more common to the
track's right, where counterclockwise cyclonic winds move in concert with the
tropical cyclone's forward motion". I think this statement may be specific to
tropical cyclones in the Northern hemisphere (i.e., those relevant to exposure
in the US). Would be good to clarify this.
\end{shaded}

**Response:** 

You are right, the opposite would be true in the Southern hemisphere. This
difference is driven by the Coriolis effect on cyclonic rotation, in which the
rotation of the earth diverts winds as they move toward the low pressure center
of the cyclone. We have edited the text to specify that this statement is
specific to the Northern Hemisphere:

> **Text in revised manuscript (relevant addition in bold):**
"**In the Northern Hemisphere, cyclonic winds are counterclockwise,** so
extreme winds are more common to the track's right where cyclonic winds move in
concert with the tropical cyclone's forward motion."

\medskip

\begin{shaded}
\textbf{R3 Comment 2:}
Line 186: What is meant by the phrase "synoptic times"?

\textit{Lines 185--187 from original manuscript:}

\begin{quotation}
\noindent
\textit{"We used tracking data from HURDAT2, which records the storm center’s
position at the synoptic times of 6:00 am, 12:00 pm, 6:00 pm, and 12:00 am
Coordinated Universal Time (UTC)."}
\end{quotation}
\end{shaded}

**Response:** 

Some weather data are collected at standardized times, so that observations from
different locations can be meaningfully integrated to provide a view of
large-scale (synoptic) weather systems and patterns [@usnwstime;
@willoughby2007hurricane; @willis2006cleveland; @raines1996getting]. This
practice extends back over 100 years, when weather data for the US were
collected by local weather offices and sent by telegram at regular times each
day into a central office, which used this information to create synoptic
weather maps that captured major weather systems in the county and then
sent back forecasts to local weather offices, also at standardized times
[@willis2006cleveland; @raines1996getting]. Synoptic weather times are typically
set based on the Universal Time Constant, with times recorded in Coordinated
Universal Time (i.e., Greenwich Mean Time), and time stamps on weather maps and
data based on this time zone often is given a "Z" (for "Zulu", an earlier name
for this timezone) after the time [@usnwstime;
@morris2008time].

We have added text to clarify the meaning of "synoptic times" in the text:

> **Text in revised manuscript (relevant change in bold):**
"We used tracking data from HURDAT2, which records the storm center’s position
at **four standardized times for weather data collection (synoptic times),**
6:00 am, 12:00 pm, 6:00 pm, and 12:00 am Coordinated Universal Time (UTC)."

\medskip

\begin{shaded}
\textbf{R3 Comment 3:}
Several of the exposures are calculated for the population mean center of each
county. From the reference list, it looks like the authors consistently used
population centers from 2010 throughout the years included in the dataset/R
package. If so, I suggest clarifying this in the text. 
\end{shaded}

**Response:** 

This is correct---the population centers from the US 2010 Decennial Census were 
used throughout. We have added text to the manuscript to clarify this: 

> **Text in revised manuscript (relevant addition in bold):**
"At each 15-min interval, we measured the distance between the storm's
center and each county's population mean center, **as of the 2010 US Decennial
Census** (US Census Bureau 2020)."

\medskip

\begin{shaded}
\textbf{R3 Comment 4:}
In the methods section starting on line 276, the authors describe the flooding
and tornado data from the NOAA storm events database. I'd suggest providing some
information about where the events in this database come from (e.g., that they
are reported events) here in addition to covering it in the discussion.

\textit{Lines 276--281 from original manuscript:}

\begin{quotation}
\noindent
\textit{"To identify flood- and tornado-based tropical cyclone exposures in US
counties, we matched storm tracks with event listings from the National Oceanic
and Atmospheric Administration (NOAA)’s Storm Event Database (NOAA NCEI 2020).
While this database has recorded storm data, particularly tornadoes, since 1950,
its coverage changed substantially in 1996 to cover more types of storm events,
including flood events (NOAA NCEI 2020). We therefore only considered flood
metrics of tropical cyclone exposure for storms in 1996 and later."}
\end{quotation}
\end{shaded}

**Response:** 

As suggested, we have added that these events are based on reports in the
Methods, in addition to our previous discussion of the point in the Discussion:

> **Revised text (relevant addition in bold):**
To identify flood- and tornado-based tropical cyclone exposures in US counties,
we matched storm tracks with event listings from the National Oceanic and
Atmospheric Administration (NOAA)’s Storm Event Database (NOAA NCEI 2020).
**Events are included in this database based on reports from National Weather
Service personnel and other sources.** While this database has recorded storm
data, particularly tornadoes, since 1950, its coverage changed substantially in
1996 to cover more types of storm events, including flood events (NOAA NCEI
2020). We therefore only considered flood metrics of tropical cyclone exposure
for storms in 1996 and later."

\medskip

\begin{shaded}
\textbf{R3 Comment 5:}
Line 294: What is meant by the phrase "traditional tornado event database"?

\textit{Lines 294--295 from original manuscript:}

\begin{quotation}
\noindent
\textit{"The tornado observations from this dataset form a traditional tornado
event database for the US, and so we did not further validate the tornado event
data."}
\end{quotation}
\end{shaded}

**Response:** 

This database is NOAA's official database on tornado events in the United States
[@mccarthy2003nws]. It is the original source for the only other national
tornado database available for the country (the Storm Prediction Center [SPC]'s
National Tornado Database [@center2020storm]), which provides a version of the
same data in which tornado events are joined into a single record in cases where
they cross county lines. There is no other comparable source of data on tornado
occurrences that could be used for a comparison as validation.

The NOAA Storm Events database originated as a database for recording tornadoes
in the US in 1953, and was originally called the Climatological Data National
Summary [@Ashley2007]. The database has gone through a number of expansions to
cover more events, and it now includes reports of other types of
hydrometeorological disaster events, including floods, extreme heat and cold,
wildfires, frost, and hail. However, it has maintained its status as the
database of record for tornadoes in the United States.

We have changed the text in the manuscript to make this clearer, changing the
wording to clarify that this is the official NOAA data on tornado events in the
US and that there are no other data sources of comparable scope that could be
used for validation:

> **Text added to the revised manuscript (relevant additions in bold):**
"The tornado observations from this dataset---**along with the derived version
of the data available through the Storm Prediction Center's National Tornado
Database [@center2020storm]---are the official tornado event data** for the US.
**There are no other collections of tornado data comparable in temporal or
geographical scope,** and so we did not further validate the tornado event
data."

\medskip

\begin{shaded}
\textbf{R3 Comment 6:}
Table 1: I suggest providing the rationale for picking the thresholds for
classifying continuous exposures into binary ones within the table. 
\end{shaded}

**Response:** 

For all outcomes, there are various reasonable choices that can be picked for
the threshold in defining exposure. There is not room to go into these details
within Table 1, so instead we added a separate table to the Supplemental
Material that provides both some reasoning behind the thresholds selected in
this study and also other reasonable thresholds that could be considered.
This is Table S1 of the revised manuscript and has been reproduced as 
Table \@ref(tab:thresholds) at the end of this response document.

\input{tables/thresholds_table.tex}

Ultimately, this choice will depend on what a researcher considers as plausible
causal pathways for the outcome he or she is studying. For example, if power
outages form a plausible step in the pathway, then the threshold for gale-force
or strong gale-force winds might be reasonable, while if the pathway is more
likely to be through larger-scale building destruction, a higher threshold would
be more reasonable. Some studies have done sensitivity analyses to consider how
results changed using different exposure metrics. For example, @czajkowski2011
performed a sensitivity analysis using different assumptions about wind decay
away from the center of a storm, while @currie2013, who used a distance-based
exposure metric, considered different buffer distances as a sensitivity
analysis.

We have added text to introduce this supplemental table in the revised manuscript, 
both in the Methods and in the Discussion: 

> **Text in the revised Methods (added text in bold)**:
"For other exposure metrics, each county was
classified as exposed to a tropical cyclone based on whether the exposure
metric exceeded a certain threshold (Table~\ref{tab:exposuremetrics}). We
picked reasonable thresholds (e.g., the threshold for gale-force wind for wind
exposure; **Table S1**), but others could be used with the open-source data and its
associated software."

> **Text in the revised Discussion (added text in bold)**:
"Finally, to assess patterns and agreement for binary exposure classifications,
we have chosen one set of sensible thresholds for binary classifications based
on continuous metrics (rainfall, maximum sustained surface wind, and distance
from the storm's track), **but other thresholds would be reasonable
depending on hypothesized pathways for a given epidemiological study (Table
S1)**."

\medskip

\begin{shaded}
\textbf{R3 Comment 7:}
Figure 3: The x-axis refers to one of the two wind data sources as "Extended
Best Tracks." Is this the same thing as the wind radii dataset described in the
text? Is so, I suggest clarifying this in the figure label.
\end{shaded}

**Response:** 

Yes, it is the same. We have revised the x-axis on the figure to clarify that
the comparison is based on the wind radii dataset described in the text, as
requested. The original and revised versions of Figure 3 of the manuscript are
reproduced in this response document as Figure \@ref(fig:fig3).

```{r fig3, fig.cap="Reproduction of Figure 3 from the original manuscript (left) and revised version in the resubmitted manuscript (right). In the revised version, the x-axis has been labelled to clarify that this axis is showing results based on the wind radii dataset described in the text, in response to Reviewer 3's Comment 7. The revised version also uses a more focused range for the x axis, as requested in EHP's Request 1. Figure caption in the revised manuscript: \\textit{Comparison of two sources of wind exposure estimates: (1) modeled peak sustained surface wind and (2) estimates based on HURDAT2's wind speed radii. Each point represents a storm, with the x-axis giving the percent of counties classified in the same category of peak sustained surface wind (< 34 kt; 34--49.9 kt; 50--63.9 kt; $\\ge$64 kt) by both sources of data. The color of each point gives the number of study counties that were exposed to peak sustained surface wind of at least 34 kt (based on modeled wind). Estimates are shown for study storms since 2004, the earliest year for which post-storm reanalysis wind speed radii are routinely available in HURDAT2, and for which at least one study county had a peak sustained wind of $\\ge$34 kt based on the post-storm wind radii.}", fig.show = "hold", out.width="50%"}
include_graphics("../figures/windcomparison.pdf")
include_graphics("figures/windcomparison.pdf")
```

\medskip

# Requests from EHP: {-#requests-from-ehp}

\begin{shaded}
\textbf{EHP Request 1:}
Figure 3: Please truncate x-axis scale as you do for Figure S7. Since smallest
value is $\sim75\%$, this would make the data in the relevant range much easier to
appreciate.
\end{shaded}

**Response:** 

We have revised this figure to show an x-axis truncated at the minimum observed
value ($\sim75\%$), as requested. The original and revised versions of this
paper are reproduced in this response document as Figure \@ref(fig:fig3).

\medskip

\begin{shaded}
\textbf{EHP Request 2:}
Main text figures (general)
To ensure that figures are accessible to readers with impaired color vision, do not use color as the sole means of conveying information in a figure unless absolutely necessary. Use different symbols, shading/textures, and line patterns instead of (or in addition to) color to distinguish among different data points. Use contrasting colors that can be easily distinguished from each other when the figure is printed in black and white. For details, see: \url{https://ehp.niehs.nih.gov/authors/figures}.
\end{shaded}

**Response:** 

In all these figures, we have used colormaps that are both accessible to readers
with several forms of color vision deficiency, including the most common type
(deuteranomaly, a type of red-green color vision deficiency), and can be easily
distinguished when the figure is printed in black and white [@viridis;
@van2015mpl]. The colormaps we used are all multi-hue sequential maps that avoid
red-green contrasts, while maximizing dynamic range in comparison to something
single-hued, like grayscale [@nunez2018optimizing; @viridis]. They are all
perceptually uniform across the scale for those with normal color vision
[@liu2018somewhere] and are close to perceptually uniform for those with common
forms of color deficiency [@nunez2018optimizing]. They reproduce their original
sequential gradient when printed in grayscale and so are perceptable when
printed on a black-and-white printer [@van2015mpl; @nunez2018optimizing].
Previous research has found that colormaps in this family allow viewers to more
quickly and accurately judge relative distances in scientific figures
[@liu2018somewhere]. The family of colormaps we used in the figures is currently
considered the gold standard for scientific figures [@nunez2018optimizing].

To help illustrate, in Figures \@ref(fig:fig5check1) and \@ref(fig:fig5check2)
of this response document, we have reproduced the current version of Figure 5 as
it would appear to someone with three common types of color vision deficiencies:
deuteranomaly (defective green cone cells, the most common type), as well as
protanopia (defective red cone cells) and tritanopia (defective blue cone
cells). We have also shown how the Figure would appear in grayscale in Figure
\@ref(fig:fig5check2) (right). We have included similar versions of other
figures from the manuscript in response to later requests from EHP in this
response.

```{r fig5check1, fig.cap="Reproduction of revised version of Figure 5 to check accessibility to readers with two types of color vision deficiency, deuteranopia (left) and protanopia (right).", out.width="90%", fig.align = "center"}
include_graphics("figures/averageexposureonly_check1.pdf")
```

```{r fig5check2, fig.cap="Reproduction of revised version of Figure 5 to check accessibility to readers with a third type of color vision deficiency, tritanopia (left) and for printing the figure in grayscale (right).", out.width="90%", fig.align = "center"}
include_graphics("figures/averageexposureonly_check2.pdf")
```

\medskip

\begin{shaded}
\textbf{EHP Request 3:}
Figure 3: Please check the contrast between the colors used to indicate numbers
of counties. If you can see the gradient when printed in black and white it
should be ok, but some of the differences are very subtle. Truncating the x-axis
might help with this (if possible.)
\end{shaded}

**Response:** 

As we note in our response to EHP Request 2, we used colormaps for all
figures that are designed to be perceptible both for those with common types of
color vision deficiency and when printed in grayscale. We have increased the
size of the circles in Figure 3 of the revised manuscript (reproduced in Figure
\@ref(fig:fig3) of this response) so that the colors are clearer, as well as
truncated the x-axis as requested in EHP Request 1. Also, we show in Figures
\@ref(fig:fig3check1) and \@ref(fig:fig3check2) of this response how the revised
Figure 3 would look with three common types of color vision deficiency as well
as when printed in black and white. The gradient is clear when this figure is
printed in black and white.

```{r fig3check1, fig.cap="Reproduction of revised version of Figure 3 to check accessibility to readers with two types of color vision deficiency, deuteranopia (left) and protanopia (right).", out.width="100%"}
include_graphics("figures/windcomparison_check1.pdf")
```

```{r fig3check2, fig.cap="Reproduction of revised version of Figure 3 to check accessibility to readers with a third type of color vision deficiency, tritanopia (left) and for printing the figure in grayscale (right).", out.width="100%"}
include_graphics("figures/windcomparison_check2.pdf")
```

\medskip

\begin{shaded}
\textbf{EHP Request 4:}
Figure 4: Even with nominally normal color vision and a large high-resolution
monitor, it is difficult for me to make out the color differences in the
symbols---almost all appear black or very dark blue, a dozen or so look yellow,
and a handful look dark grey. Is there any way to increase the contrast in these
colors? Would you consider binning into categories instead of using a
continuous color gradient?
\end{shaded}

**Response:** 

Thank you for these suggestions. 

For the original figure, most of the events resulted in 0% of flood gages
exceeding the flood threshold, especially for events that were not recorded as
floods based on NOAA Storm Events. Therefore, most of the points in the original
were indeed dark blue, representing 0%, but we can see that readers might have
questioned if this was the case or if the scale made it harder to see subtler
differences.

We have made several changes to make this figure easier for readers to see and
interpret. These changes include:

- Binning the values shown by the points fill, so that readers only need to 
be able to distinguish among four colors, rather than across a larger scale.
- Increasing the size of the points, so the fill in each point is easier to 
see. 
- Using a different algorithm to "jitter" the points, so there are no points that
overlap each other. 

We have reproduced both the original and revised versions of Figure 4 as Figure
\@ref(fig:fig4) of this response.

\medskip

\begin{shaded}
\textbf{EHP Request 5:}
Figures 5--6: Please check to see if the colors used can be distinguished if
printed in black and white, and if not, use a “color-blind friendly” palette if
possible. If this is not feasible, we can request and exemption from
accessibility requirements, but we try to do this only when alternatives  would
degrade the information content of  the figure.
\end{shaded}

**Response:** 

As we note in our response to EHP Request 2, we used colormaps for all figures
that are designed to be perceptible both for those with common types of color
vision deficiency and when printed in grayscale Figures \@ref(fig:fig5check1)
and \@ref(fig:fig5check2) at the end of this response show what Figure 5 of the
main text would look like under three common types of color vision deficiency
and when printed in black and white. Figures \@ref(fig:fig6check1) and
\@ref(fig:fig6check2) at the end of this response show the same thing for Figure
6 of the main text.

For Figure 6 of the main text, for some types of color balance, it could be
unclear which of the two color legends pairs with which part of the graph. We
have therefore added a note to the figure legend to clarify: 

> **Figure legend for Figure 6 in revised manuscript (added text shown in bold)**: 
"Agreement between exposure classifications based on different single-hazard
exposure metrics for all storms between~1996 and~2011 for which at least~100
counties were exposed based on at least one metric. Each row shows one storm,
and the color of each cell shows the measured Jaccard index for each pair of
exposure metrics (proportion of counties classified as exposed by both metrics
out of counties classified as exposed by either metric). For Grace in 2003 and
Ida in 2009, there were no county exposures for either the tornado-based metric
or the wind-based metric (indicated by gray squares). Colors to the right of the
heatmap show the number of exposed counties based on any of the metrics, **and
this panel is linked with the color scale labeled '# of counties exposed by
any metric'.** Storms are displayed within clusters that have similar patterns
based on hierarchical clustering."

These figures should therefore not require any exemption from accessibility
requirements, as they should satisfy these requirements.

```{r fig6check1, fig.cap="Reproduction of revised version of Figure 6 to check accessibility to readers with two types of color vision deficiency, deuteranopia (left) and protanopia (right).", fig.show = "hold", out.width="50%"}
include_graphics("figures/jaccard_heatmap_check1.pdf")

include_graphics("figures/jaccard_heatmap_check2.pdf")
```

```{r fig6check2, fig.cap="Reproduction of revised version of Figure 6 to check accessibility to readers with a third type of color vision deficiency, tritanopia (left) and for printing the figure in grayscale (right).", fig.show = "hold", out.width="50%"}
include_graphics("figures/jaccard_heatmap_check3.pdf")
include_graphics("figures/jaccard_heatmap_check4.pdf")
```

\medskip

\begin{shaded}
\textbf{R2 Comment 6:}
Supplemental Material: Please provide your supplemental material file in Word
(.docx) format. For additional information, see:
\url{https://ehp.niehs.nih.gov/authors/supplemental-material}. \end{shaded}

**Response:** 

We have provided the Supplemental Material in the Word file format in our
revised submission.

\medskip

# References for the response {-#references-for-the-response}
